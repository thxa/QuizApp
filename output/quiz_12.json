[{"_id": 668, "question": "668# A developer has created a data collection application that uses Amazon API Gateway, AWS Lambda, and Amazon S3. The application\u2019s users periodically upload data files and wait for the validation status to be reflected on a processing dashboard. The validation process is complex and time- consuming for large files. Some users are uploading dozens of large files and have to wait and refresh the processing dashboard to see if the files have been validated. The developer must refactor the application to immediately update the validation result on the user\u2019s dashboard without reloading the full dashboard. What is the MOST operationally efficient solution that meets these requirements?", "options": ["A. Integrate the client with an API Gateway WebSocket API. Save the user-uploaded files with the WebSocket connection ID. Push the validation status to the connection ID when the processing is complete to initiate an update of the user interface.", "B. Launch an Amazon EC2 micro instance, and set up a WebSocket server. Send the user-uploaded file and user detail to the EC2 instance after the user uploads the file. Use the WebSocket server to send updates to the user interface when the uploaded file is processed.", "C. Save the user\u2019s email address along with the user-uploaded file. When the validation process is complete, send an email notification through Amazon Simple Notification Service (Amazon SNS) to the user who uploaded the file.", "D. Save the user-uploaded file and user detail to Amazon DynamoDB. Use Amazon DynamoDB Streams with Amazon Simple Notification Service (Amazon SNS) push notifications to send updates to the browser to update the user interface. Selected Answer: A"], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248686774606&usg=AOvVaw0_mCYDVHB6ybjbn896USBo"]}, {"_id": 669, "question": "669# A company\u2019s developer is creating an application that uses Amazon API Gateway. The company wants to ensure that only users in the Sales department can use the application. The users authenticate to the application by using federated credentials from a third-party identity provider (IdP) through Amazon Cognito. The developer has set up an attribute mapping to map an attribute that is named Department and to pass the attribute to a custom AWS Lambda authorizer. To test the access limitation, the developer sets their department to Engineering in the IdP and attempts to log in to the application. The developer is denied access. The developer then updates their department to Sales in the IdP and attempts to log in. Again, the developer is denied access. The developer checks the logs and discovers that access is being denied because the developer\u2019s access token has a department value of Engineering. Which of the following is a possible reason that the developer\u2019s department is still being reported as Engineering instead of Sales?", "options": ["A. Authorization caching is enabled in the custom Lambda authorizer.", "B. Authorization caching is enabled on the Amazon Cognito user pool.", "C. The IAM role for the custom Lambda authorizer does not have a Department tag.", "D. The IAM role for the Amazon Cognito user pool does not have a Department tag."], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248687297931&usg=AOvVaw0hxxe1i8KyypkSb4LM2QMz"]}, {"_id": 670, "question": "670# A company has migrated an application to Amazon EC2 instances. Automatic scaling is working well for the application user interface. However, the process to deliver shipping requests to the company\u2019s warehouse staff is encountering issues. Duplicate shipping requests are arriving, and some requests are lost or arrive out of order. The company must avoid duplicate shipping requests and must process the requests in the order that the requests arrive. Requests are never more than 250 KB in size and take 5-10 minutes to process. A developer needs to rearchitect the application to improve the reliability of the delivery and processing of the requests. What should the developer do to meet these requirements?", "options": ["A. Create an Amazon Kinesis Data Firehose delivery stream to process the requests. Create an Amazon Kinesis data stream. Modify the application to write the requests to the Kinesis data stream.", "B. Create an AWS Lambda function to process the requests. Create an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the Lambda function to the SNS topic. Modify the application to write the requests to the SNS topic.", "https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248687907267&usg=AOvVaw3dXCJ7OS9XL6hSBNCyDEIi 324", "C. Create an AWS Lambda function to process the requests. Create an Amazon Simple Queue Service (Amazon SQS) standard queue. Set the SQS queue as an event source for the Lambda function. Modify the application to write the requests to the SQS queue."], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248687907267&usg=AOvVaw3dXCJ7OS9XL6hSBNCyDEIi"]}, {"_id": 671, "question": "671# A developer is creating a machine learning (ML) pipeline in AWS Step Functions that contains AWS Lambda functions. The developer has configured an Amazon Simple Queue Service (Amazon SQS) queue to deliver ML model parameters to the ML pipeline to train ML models. The developer uploads the trained models are uploaded to an Amazon S3 bucket. The developer needs a solution that can locally test the ML pipeline without making service integration calls to Amazon SQS and Amazon S3. Which solution will meet these requirements?", "options": ["A. Use the Amazon CodeGuru Profiler to analyze the Lambda functions used in the AWS Step Functions pipeline.", "https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248688497138&usg=AOvVaw04eQprzV8Q0Kivwdoq6vV_ 325", "B. Use the AWS Step Functions Local Docker Image to run and locally test the Lambda functions.", "C. Use the AWS Serverless Application Model (AWS SAM) CLI to run and locally test the Lambda functions."], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248688497138&usg=AOvVaw04eQprzV8Q0Kivwdoq6vV_", "https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248694703755&usg=AOvVaw3DSR702RRQHs1MVXG4iy-E"]}, {"_id": 600, "question": "600# A company is deploying an application that processes large quantities of data in parallel. The company plans to use Amazon EC2 instances for the workload. The network architecture must be configurable to prevent groups of nodes from sharing the same underlying hardware. Which networking solution meets these requirements?", "options": ["A. Run the EC2 instances in a spread placement group.", "B. Group the EC2 instances in separate accounts.", "C. Configure the EC2 instances with dedicated tenancy.", "D. Configure the EC2 instances with shared tenancy. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 600, "question": "600# A company is deploying an application that processes large quantities of data in parallel. The company plans to use Amazon EC2 instances for the workload. The network architecture must be configurable to prevent groups of nodes from sharing the same underlying hardware. Which networking solution meets these requirements?", "options": ["A. Run the EC2 instances in a spread placement group.", "B. Group the EC2 instances in separate accounts.", "C. Configure the EC2 instances with dedicated tenancy.", "D. Configure the EC2 instances with shared tenancy. 326 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 601, "question": "601# A solutions architect is designing a disaster recovery (DR) strategy to provide Amazon EC2 capacity in a failover AWS Region. Business requirements state that the DR strategy must meet capacity in the failover Region. Which solution will meet these requirements?", "options": ["A. Purchase On-Demand Instances in the failover Region.", "B. Purchase an EC2 Savings Plan in the failover Region.", "C. Purchase regional Reserved Instances in the failover Region.", "D. Purchase a Capacity Reservation in the failover Region. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 601, "question": "601# A solutions architect is designing a disaster recovery (DR) strategy to provide Amazon EC2 capacity in a failover AWS Region. Business requirements state that the DR strategy must meet capacity in the failover Region. Which solution will meet these requirements?", "options": ["A. Purchase On-Demand Instances in the failover Region.", "B. Purchase an EC2 Savings Plan in the failover Region.", "C. Purchase regional Reserved Instances in the failover Region.", "D. Purchase a Capacity Reservation in the failover Region. 327 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 602, "question": "602# A company has five organizational units (OUs) as part of its organization in AWS Organizations. Each OU correlates to the five businesses that the company owns. The company's research and development (R&D) business is separating from the company and will need its own organization. A solutions architect creates a separate new management account for this purpose. What should the solutions architect do next in the new management account?", "options": ["A. Have the R&D AWS account be part of both organizations during the transition.", "B. Invite the R&D AWS account to be part of the new organization after the R&D AWS account has left the prior organization.", "C. Create a new R&D AWS account in the new organization. Migrate resources from the prior R&D AWS account to the new R&D AWS account.", "D. Have the R&D AWS account join the new organization. Make the new management account a member of the prior organization. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 602, "question": "602# A company has five organizational units (OUs) as part of its organization in AWS Organizations. Each OU correlates to the five businesses that the company owns. The company's research and development (R&D) business is separating from the company and will need its own organization. A solutions architect creates a separate new management account for this purpose. What should the solutions architect do next in the new management account?", "options": ["A. Have the R&D AWS account be part of both organizations during the transition.", "B. Invite the R&D AWS account to be part of the new organization after the R&D AWS account has left the prior organization.", "C. Create a new R&D AWS account in the new organization. Migrate resources from the prior R&D AWS account to the new R&D AWS account.", "D. Have the R&D AWS account join the new organization. Make the new management account a member of the prior organization. 328 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 603, "question": "603# A company is designing a solution to capture customer activity in different web applications to process analytics and make predictions. Customer activity in the web applications is unpredictable and can increase suddenly. The company requires a solution that integrates with other web applications. The solution must include an authorization step for security purposes. Which solution will meet these requirements?", "options": ["A. Configure a Gateway Load Balancer (GWLB) in front of an Amazon Elastic Container Service (Amazon ECS) container instance that stores the information that the company receives in an Amazon Elastic File System (Amazon EFS) file system. Authorization is resolved at the GWLB.", "B. Configure an Amazon API Gateway endpoint in front of an Amazon Kinesis data stream that stores the information that the company receives in an Amazon S3 bucket. Use an AWS Lambda function to resolve authorization.", "C. Configure an Amazon API Gateway endpoint in front of an Amazon Kinesis Data Firehose that stores the information that the company receives in an Amazon S3 bucket. Use an API Gateway Lambda authorizer to resolve authorization.", "D. Configure a Gateway Load Balancer (GWLB) in front of an Amazon Elastic Container Service (Amazon ECS) container instance that stores the information that the company receives on an Amazon Elastic File System (Amazon EFS) file system. Use an AWS Lambda function to resolve authorization. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 603, "question": "603# A company is designing a solution to capture customer activity in different web applications to process analytics and make predictions. Customer activity in the web applications is unpredictable and can increase suddenly. The company requires a solution that integrates with other web applications. The solution must include an authorization step for security purposes. Which solution will meet these requirements?", "options": [], "explain": "", "answers": [], "resources": []}, {"_id": 603, "question": "603# A company is designing a solution to capture customer activity in different web applications to process analytics and make predictions. Customer activity in the web applications is unpredictable and can increase suddenly. The company requires a solution that integrates with other web applications. The solution must include an authorization step for security purposes. Which solution will meet these requirements? A. Configure a Gateway Load Balancer (GWLB) in front of an Amazon Elastic Container Service (Amazon ECS) container instance that stores the information that the company receives in an Amazon Elastic File System (Amazon EFS) file system. Authorization is resolved at the GWLB. B. Configure an Amazon API Gateway endpoint in front of an Amazon Kinesis data stream that stores the information that the company receives in an Amazon S3 bucket. Use an AWS Lambda function to resolve authorization. C. Configure an Amazon API Gateway endpoint in front of an Amazon Kinesis Data Firehose that stores the information that the company receives in an Amazon S3 bucket. Use an API Gateway Lambda authorizer to resolve authorization. D. Configure a Gateway Load Balancer (GWLB) in front of an Amazon Elastic Container Service (Amazon ECS) container instance that stores the information that the company receives on an Amazon Elastic File System (Amazon EFS) file system. Use an AWS Lambda function to resolve authorization. 329 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com 604# An ecommerce company wants a disaster recovery solution for its Amazon RDS DB instances that run Microsoft SQL Server Enterprise Edition. The company's current recovery point objective (RPO) and recovery time objective (RTO) are 24 hours. Which solution will meet these requirements MOST cost-effectively?", "options": [], "explain": "", "answers": [], "resources": []}, {"_id": 603, "question": "603# A company is designing a solution to capture customer activity in different web applications to process analytics and make predictions. Customer activity in the web applications is unpredictable and can increase suddenly. The company requires a solution that integrates with other web applications. The solution must include an authorization step for security purposes. Which solution will meet these requirements? A. Configure a Gateway Load Balancer (GWLB) in front of an Amazon Elastic Container Service (Amazon ECS) container instance that stores the information that the company receives in an Amazon Elastic File System (Amazon EFS) file system. Authorization is resolved at the GWLB. B. Configure an Amazon API Gateway endpoint in front of an Amazon Kinesis data stream that stores the information that the company receives in an Amazon S3 bucket. Use an AWS Lambda function to resolve authorization. C. Configure an Amazon API Gateway endpoint in front of an Amazon Kinesis Data Firehose that stores the information that the company receives in an Amazon S3 bucket. Use an API Gateway Lambda authorizer to resolve authorization. D. Configure a Gateway Load Balancer (GWLB) in front of an Amazon Elastic Container Service (Amazon ECS) container instance that stores the information that the company receives on an Amazon Elastic File System (Amazon EFS) file system. Use an AWS Lambda function to resolve authorization. 329 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com 604# An ecommerce company wants a disaster recovery solution for its Amazon RDS DB instances that run Microsoft SQL Server Enterprise Edition. The company's current recovery point objective (RPO) and recovery time objective (RTO) are 24 hours. Which solution will meet these requirements MOST cost-effectively? A. Create a cross-Region read replica and promote the read replica to the primary instance. B. Use AWS Database Migration Service (AWS DMS) to create RDS cross-Region replication. C. Use cross-Region replication every 24 hours to copy native backups to an Amazon S3 bucket. D. Copy automatic snapshots to another Region every 24 hours. sthithapragnasya@gmail.com 604# An ecommerce company wants a disaster recovery solution for its Amazon RDS DB instances that run Microsoft SQL Server Enterprise Edition. The company's current recovery point objective (RPO) and recovery time objective (RTO) are 24 hours. Which solution will meet these requirements MOST cost-effectively?", "options": ["A. Configure a Gateway Load Balancer (GWLB) in front of an Amazon Elastic Container Service (Amazon ECS) container instance that stores the information that the company receives in an Amazon Elastic File System (Amazon EFS) file system. Authorization is resolved at the GWLB.", "B. Configure an Amazon API Gateway endpoint in front of an Amazon Kinesis data stream that stores the information that the company receives in an Amazon S3 bucket. Use an AWS Lambda function to resolve authorization.", "C. Configure an Amazon API Gateway endpoint in front of an Amazon Kinesis Data Firehose that stores the information that the company receives in an Amazon S3 bucket. Use an API Gateway Lambda authorizer to resolve authorization.", "A. Create a cross-Region read replica and promote the read replica to the primary instance.", "B. Use AWS Database Migration Service (AWS DMS) to create RDS cross-Region replication.", "C. Use cross-Region replication every 24 hours to copy native backups to an Amazon S3 bucket.", "A. Create a cross-Region read replica and promote the read replica to the primary instance.", "B. Use AWS Database Migration Service (AWS DMS) to create RDS cross-Region replication.", "C. Use cross-Region replication every 24 hours to copy native backups to an Amazon S3 bucket.", "D. Copy automatic snapshots to another Region every 24 hours. 330 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 605, "question": "605# A company runs a web application on Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer that has sticky sessions enabled. The web server currently hosts the user session state. The company wants to ensure high availability and avoid user session state loss in the event of a web server outage. Which solution will meet these requirements?", "options": ["A. Use an Amazon ElastiCache for Memcached instance to store the session data. Update the application to use ElastiCache for Memcached to store the session state.", "B. Use Amazon ElastiCache for Redis to store the session state. Update the application to use ElastiCache for Redis to store the session state.", "C. Use an AWS Storage Gateway cached volume to store session data. Update the application to use AWS Storage Gateway cached volume to store the session state.", "D. Use Amazon RDS to store the session state. Update the application to use Amazon RDS to store the session state. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 605, "question": "605# A company runs a web application on Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer that has sticky sessions enabled. The web server currently hosts the user session state. The company wants to ensure high availability and avoid user session state loss in the event of a web server outage. Which solution will meet these requirements?", "options": ["A. Use an Amazon ElastiCache for Memcached instance to store the session data. Update the application to use ElastiCache for Memcached to store the session state.", "B. Use Amazon ElastiCache for Redis to store the session state. Update the application to use ElastiCache for Redis to store the session state.", "C. Use an AWS Storage Gateway cached volume to store session data. Update the application to use AWS Storage Gateway cached volume to store the session state.", "D. Use Amazon RDS to store the session state. Update the application to use Amazon RDS to store the session state. 331 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 606, "question": "606# A company migrated a MySQL database from the company's on- premises data center to an Amazon RDS for MySQL DB instance. The company sized the RDS DB instance to meet the company's average daily workload. Once a month, the database performs slowly when the company runs queries for a report. The company wants to have the ability to run reports and maintain the performance of the daily workloads. Which solution will meet these requirements?", "options": ["A. Create a read replica of the database. Direct the queries to the read replica.", "B. Create a backup of the database. Restore the backup to another DB instance. Direct the queries to the new database.", "C. Export the data to Amazon S3. Use Amazon Athena to query the S3 bucket.", "D. Resize the DB instance to accommodate the additional workload. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 606, "question": "606# A company migrated a MySQL database from the company's on- premises data center to an Amazon RDS for MySQL DB instance. The company sized the RDS DB instance to meet the company's average daily workload. Once a month, the database performs slowly when the company runs queries for a report. The company wants to have the ability to run reports and maintain the performance of the daily workloads. Which solution will meet these requirements?", "options": ["A. Create a read replica of the database. Direct the queries to the read replica.", "B. Create a backup of the database. Restore the backup to another DB instance. Direct the queries to the new database.", "C. Export the data to Amazon S3. Use Amazon Athena to query the S3 bucket.", "D. Resize the DB instance to accommodate the additional workload. 332 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 607, "question": "607# A company runs a container application by using Amazon Elastic Kubernetes Service (Amazon EKS). The application includes microservices that manage customers and place orders. The company needs to route incoming requests to the appropriate microservices. Which solution will meet this requirement MOST cost-effectively?", "options": ["A. Use the AWS Load Balancer Controller to provision a Network Load Balancer.", "B. Use the AWS Load Balancer Controller to provision an Application Load Balancer.", "C. Use an AWS Lambda function to connect the requests to Amazon EKS.", "D. Use Amazon API Gateway to connect the requests to Amazon EKS. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 607, "question": "607# A company runs a container application by using Amazon Elastic Kubernetes Service (Amazon EKS). The application includes microservices that manage customers and place orders. The company needs to route incoming requests to the appropriate microservices. Which solution will meet this requirement MOST cost-effectively?", "options": ["A. Use the AWS Load Balancer Controller to provision a Network Load Balancer.", "B. Use the AWS Load Balancer Controller to provision an Application Load Balancer.", "C. Use an AWS Lambda function to connect the requests to Amazon EKS.", "D. Use Amazon API Gateway to connect the requests to Amazon EKS. 333 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 608, "question": "608# A company uses AWS and sells access to copyrighted images. The company\u2019s global customer base needs to be able to access these images quickly. The company must deny access to users from specific countries. The company wants to minimize costs as much as possible. Which solution will meet these requirements?", "options": ["A. Use Amazon S3 to store the images. Turn on multi-factor authentication (MFA) and public bucket access. Provide customers with a link to the S3 bucket.", "B. Use Amazon S3 to store the images. Create an IAM user for each customer. Add the users to a group that has permission to access the S3 bucket.", "C. Use Amazon EC2 instances that are behind Application Load Balancers (ALBs) to store the images. Deploy the instances only in the countries the company services. Provide customers with links to the ALBs for their specific country's instances.", "D. Use Amazon S3 to store the images. Use Amazon CloudFront to distribute the images with geographic restrictions. Provide a signed URL for each customer to access the data in CloudFront. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 608, "question": "608# A company uses AWS and sells access to copyrighted images. The company\u2019s global customer base needs to be able to access these images quickly. The company must deny access to users from specific countries. The company wants to minimize costs as much as possible. Which solution will meet these requirements?", "options": ["A. Use Amazon S3 to store the images. Turn on multi-factor authentication (MFA) and public bucket access. Provide customers with a link to the S3 bucket.", "B. Use Amazon S3 to store the images. Create an IAM user for each customer. Add the users to a group that has permission to access the S3 bucket.", "C. Use Amazon EC2 instances that are behind Application Load Balancers (ALBs) to store the images. Deploy the instances only in the countries the company services. Provide customers with links to the ALBs for their specific country's instances.", "D. Use Amazon S3 to store the images. Use Amazon CloudFront to distribute the images with geographic restrictions. Provide a signed URL for each customer to access the data in CloudFront. 334 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 609, "question": "609# A solutions architect is designing a highly available Amazon ElastiCache for Redis based solution. The solutions architect needs to ensure that failures do not result in performance degradation or loss of data locally and within an AWS Region. The solution needs to provide high availability at the node level and at the Region level. Which solution will meet these requirements?", "options": ["A. Use Multi-AZ Redis replication groups with shards that contain multiple nodes.", "B. Use Redis shards that contain multiple nodes with Redis append only files (AOF) turned on.", "C. Use a Multi-AZ Redis cluster with more than one read replica in the replication group.", "D. Use Redis shards that contain multiple nodes with Auto Scaling turned on. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 609, "question": "609# A solutions architect is designing a highly available Amazon ElastiCache for Redis based solution. The solutions architect needs to ensure that failures do not result in performance degradation or loss of data locally and within an AWS Region. The solution needs to provide high availability at the node level and at the Region level. Which solution will meet these requirements?", "options": ["A. Use Multi-AZ Redis replication groups with shards that contain multiple nodes.", "B. Use Redis shards that contain multiple nodes with Redis append only files (AOF) turned on.", "C. Use a Multi-AZ Redis cluster with more than one read replica in the replication group.", "D. Use Redis shards that contain multiple nodes with Auto Scaling turned on. 335 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 610, "question": "610# A company plans to migrate to AWS and use Amazon EC2 On-Demand Instances for its application. During the migration testing phase, a technical team observes that the application takes a long time to launch and load memory to become fully productive. Which solution will reduce the launch time of the application during the next testing phase?", "options": ["A. Launch two or more EC2 On-Demand Instances. Turn on auto scaling features and make the EC2 On-Demand Instances available during the next testing phase.", "B. Launch EC2 Spot Instances to support the application and to scale the application so it is available during the next testing phase.", "C. Launch the EC2 On-Demand Instances with hibernation turned on. Configure EC2 Auto Scaling warm pools during the next testing phase.", "D. Launch EC2 On-Demand Instances with Capacity Reservations. Start additional EC2 instances during the next testing phase. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 610, "question": "610# A company plans to migrate to AWS and use Amazon EC2 On-Demand Instances for its application. During the migration testing phase, a technical team observes that the application takes a long time to launch and load memory to become fully productive. Which solution will reduce the launch time of the application during the next testing phase?", "options": ["A. Launch two or more EC2 On-Demand Instances. Turn on auto scaling features and make the EC2 On-Demand Instances available during the next testing phase.", "B. Launch EC2 Spot Instances to support the application and to scale the application so it is available during the next testing phase.", "C. Launch the EC2 On-Demand Instances with hibernation turned on. Configure EC2 Auto Scaling warm pools during the next testing phase.", "D. Launch EC2 On-Demand Instances with Capacity Reservations. Start additional EC2 instances during the next testing phase. 336 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 611, "question": "611# A company's applications run on Amazon EC2 instances in Auto Scaling groups. The company notices that its applications experience sudden traffic increases on random days of the week. The company wants to maintain application performance during sudden traffic increases. Which solution will meet these requirements MOST cost-effectively?", "options": ["A. Use manual scaling to change the size of the Auto Scaling group.", "B. Use predictive scaling to change the size of the Auto Scaling group.", "C. Use dynamic scaling to change the size of the Auto Scaling group.", "D. Use schedule scaling to change the size of the Auto Scaling group. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 611, "question": "611# A company's applications run on Amazon EC2 instances in Auto Scaling groups. The company notices that its applications experience sudden traffic increases on random days of the week. The company wants to maintain application performance during sudden traffic increases. Which solution will meet these requirements MOST cost-effectively?", "options": [], "explain": "", "answers": [], "resources": []}, {"_id": 611, "question": "611# A company's applications run on Amazon EC2 instances in Auto Scaling groups. The company notices that its applications experience sudden traffic increases on random days of the week. The company wants to maintain application performance during sudden traffic increases. Which solution will meet these requirements MOST cost-effectively? A. Use manual scaling to change the size of the Auto Scaling group. B. Use predictive scaling to change the size of the Auto Scaling group. C. Use dynamic scaling to change the size of the Auto Scaling group. D. Use schedule scaling to change the size of the Auto Scaling group. 337 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com 612# An ecommerce application uses a PostgreSQL database that runs on an Amazon EC2 instance. During a monthly sales event, database usage increases and causes database connection issues for the application. The traffic is unpredictable for subsequent monthly sales events, which impacts the sales forecast. The company needs to maintain performance when there is an unpredictable increase in traffic. Which solution resolves this issue in the MOST cost-effective way?", "options": [], "explain": "", "answers": [], "resources": []}, {"_id": 611, "question": "611# A company's applications run on Amazon EC2 instances in Auto Scaling groups. The company notices that its applications experience sudden traffic increases on random days of the week. The company wants to maintain application performance during sudden traffic increases. Which solution will meet these requirements MOST cost-effectively? A. Use manual scaling to change the size of the Auto Scaling group. B. Use predictive scaling to change the size of the Auto Scaling group. C. Use dynamic scaling to change the size of the Auto Scaling group. D. Use schedule scaling to change the size of the Auto Scaling group. 337 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com 612# An ecommerce application uses a PostgreSQL database that runs on an Amazon EC2 instance. During a monthly sales event, database usage increases and causes database connection issues for the application. The traffic is unpredictable for subsequent monthly sales events, which impacts the sales forecast. The company needs to maintain performance when there is an unpredictable increase in traffic. Which solution resolves this issue in the MOST cost-effective way? A. Migrate the PostgreSQL database to Amazon Aurora Serverless v2. B. Enable auto scaling for the PostgreSQL database on the EC2 instance to accommodate increased usage. C. Migrate the PostgreSQL database to Amazon RDS for PostgreSQL with a larger instance type. D. Migrate the PostgreSQL database to Amazon Redshift to accommodate increased usage. sthithapragnasya@gmail.com 612# An ecommerce application uses a PostgreSQL database that runs on an Amazon EC2 instance. During a monthly sales event, database usage increases and causes database connection issues for the application. The traffic is unpredictable for subsequent monthly sales events, which impacts the sales forecast. The company needs to maintain performance when there is an unpredictable increase in traffic. Which solution resolves this issue in the MOST cost-effective way?", "options": ["A. Use manual scaling to change the size of the Auto Scaling group.", "B. Use predictive scaling to change the size of the Auto Scaling group.", "C. Use dynamic scaling to change the size of the Auto Scaling group.", "A. Migrate the PostgreSQL database to Amazon Aurora Serverless v2.", "B. Enable auto scaling for the PostgreSQL database on the EC2 instance to accommodate increased usage.", "C. Migrate the PostgreSQL database to Amazon RDS for PostgreSQL with a larger instance type.", "A. Migrate the PostgreSQL database to Amazon Aurora Serverless v2.", "B. Enable auto scaling for the PostgreSQL database on the EC2 instance to accommodate increased usage.", "C. Migrate the PostgreSQL database to Amazon RDS for PostgreSQL with a larger instance type.", "D. Migrate the PostgreSQL database to Amazon Redshift to accommodate increased usage. 338 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 613, "question": "613# A company hosts an internal serverless application on AWS by using Amazon API Gateway and AWS Lambda. The company\u2019s employees report issues with high latency when they begin using the application each day. The company wants to reduce latency. Which solution will meet these requirements?", "options": ["A. Increase the API Gateway throttling limit.", "B. Set up a scheduled scaling to increase Lambda provisioned concurrency before employees begin to use the application each day.", "C. Create an Amazon CloudWatch alarm to initiate a Lambda function as a target for the alarm at the beginning of each day.", "D. Increase the Lambda function memory. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 613, "question": "613# A company hosts an internal serverless application on AWS by using Amazon API Gateway and AWS Lambda. The company\u2019s employees report issues with high latency when they begin using the application each day. The company wants to reduce latency. Which solution will meet these requirements?", "options": ["A. Increase the API Gateway throttling limit.", "B. Set up a scheduled scaling to increase Lambda provisioned concurrency before employees begin to use the application each day.", "C. Create an Amazon CloudWatch alarm to initiate a Lambda function as a target for the alarm at the beginning of each day.", "D. Increase the Lambda function memory. 339 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 614, "question": "614# A research company uses on-premises devices to generate data for analysis. The company wants to use the AWS Cloud to analyze the data. The devices generate .csv files and support writing the data to an SMB file share. Company analysts must be able to use SQL commands to query the data. The analysts will run queries periodically throughout the day. Which combination of steps will meet these requirements MOST cost-effectively? (Choose three.)", "options": ["A. Deploy an AWS Storage Gateway on premises in Amazon S3 File Gateway mode.", "B. Deploy an AWS Storage Gateway on premises in Amazon FSx File Gateway made.", "C. Set up an AWS Glue crawler to create a table based on the data that is in Amazon S3.", "D. Set up an Amazon EMR cluster with EMR File System (EMRFS) to query the data that is in Amazon S3. Provide access to analysts.", "E. Set up an Amazon Redshift cluster to query the data that is in Amazon S3. Provide access to analysts.", "F. Setup Amazon Athena to query the data that is in Amazon S3. Provide access to analysts. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 614, "question": "614# A research company uses on-premises devices to generate data for analysis. The company wants to use the AWS Cloud to analyze the data. The devices generate .csv files and support writing the data to an SMB file share. Company analysts must be able to use SQL commands to query the data. The analysts will run queries periodically throughout the day. Which combination of steps will meet these requirements MOST cost-effectively? (Choose three.)", "options": ["A. Deploy an AWS Storage Gateway on premises in Amazon S3 File Gateway mode.", "B. Deploy an AWS Storage Gateway on premises in Amazon FSx File Gateway made.", "C. Set up an AWS Glue crawler to create a table based on the data that is in Amazon S3.", "D. Set up an Amazon EMR cluster with EMR File System (EMRFS) to query the data that is in Amazon S3. Provide access to analysts.", "E. Set up an Amazon Redshift cluster to query the data that is in Amazon S3. Provide access to analysts.", "F. Setup Amazon Athena to query the data that is in Amazon S3. Provide access to analysts. 340 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 615, "question": "615# A company wants to use Amazon Elastic Container Service (Amazon ECS) clusters and Amazon RDS DB instances to build and run a payment processing application. The company will run the application in its on- premises data center for compliance purposes. A solutions architect wants to use AWS Outposts as part of the solution. The solutions architect is working with the company's operational team to build the application. Which activities are the responsibility of the company's operational team? (Choose three.)", "options": ["A. Providing resilient power and network connectivity to the Outposts racks", "B. Managing the virtualization hypervisor, storage systems, and the AWS services that run on Outposts", "C. Physical security and access controls of the data center environment", "D. Availability of the Outposts infrastructure including the power supplies, servers, and networking equipment within the Outposts racks", "E. Physical maintenance of Outposts components", "F. Providing extra capacity for Amazon ECS clusters to mitigate server failures and maintenance events sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 615, "question": "615# A company wants to use Amazon Elastic Container Service (Amazon ECS) clusters and Amazon RDS DB instances to build and run a payment processing application. The company will run the application in its on- premises data center for compliance purposes. A solutions architect wants to use AWS Outposts as part of the solution. The solutions architect is working with the company's operational team to build the application. Which activities are the responsibility of the company's operational team? (Choose three.)", "options": ["A. Providing resilient power and network connectivity to the Outposts racks", "B. Managing the virtualization hypervisor, storage systems, and the AWS services that run on Outposts", "C. Physical security and access controls of the data center environment", "D. Availability of the Outposts infrastructure including the power supplies, servers, and networking equipment within the Outposts racks", "E. Physical maintenance of Outposts components", "F. Providing extra capacity for Amazon ECS clusters to mitigate server failures and maintenance events 341 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 616, "question": "616# A company is planning to migrate a TCP-based application into the company's VPC. The application is publicly accessible on a nonstandard TCP port through a hardware appliance in the company's data center. This public endpoint can process up to 3 million requests per second with low latency. The company requires the same level of performance for the new public endpoint in AWS. What should a solutions architect recommend to meet this requirement?", "options": ["A. Deploy a Network Load Balancer (NLB). Configure the NLB to be publicly accessible over the TCP port that the application requires.", "B. Deploy an Application Load Balancer (ALB). Configure the ALB to be publicly accessible over the TCP port that the application requires.", "C. Deploy an Amazon CloudFront distribution that listens on the TCP port that the application requires. Use an Application Load Balancer as the origin.", "D. Deploy an Amazon API Gateway API that is configured with the TCP port that the application requires. Configure AWS Lambda functions with provisioned concurrency to process the requests. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 616, "question": "616# A company is planning to migrate a TCP-based application into the company's VPC. The application is publicly accessible on a nonstandard TCP port through a hardware appliance in the company's data center. This public endpoint can process up to 3 million requests per second with low latency. The company requires the same level of performance for the new public endpoint in AWS. What should a solutions architect recommend to meet this requirement?", "options": ["A. Deploy a Network Load Balancer (NLB). Configure the NLB to be publicly accessible over the TCP port that the application requires.", "B. Deploy an Application Load Balancer (ALB). Configure the ALB to be publicly accessible over the TCP port that the application requires.", "C. Deploy an Amazon CloudFront distribution that listens on the TCP port that the application requires. Use an Application Load Balancer as the origin.", "D. Deploy an Amazon API Gateway API that is configured with the TCP port that the application requires. Configure AWS Lambda functions with provisioned concurrency to process the requests. 342 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 617, "question": "617# A company runs its critical database on an Amazon RDS for PostgreSQL DB instance. The company wants to migrate to Amazon Aurora PostgreSQL with minimal downtime and data loss. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Create a DB snapshot of the RDS for PostgreSQL DB instance to populate a new Aurora PostgreSQL DB cluster.", "B. Create an Aurora read replica of the RDS for PostgreSQL DB instance. Promote the Aurora read replicate to a new Aurora PostgreSQL DB cluster.", "C. Use data import from Amazon S3 to migrate the database to an Aurora PostgreSQL DB cluster.", "D. Use the pg_dump utility to back up the RDS for PostgreSQL database. Restore the backup to a new Aurora PostgreSQL DB cluster. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 617, "question": "617# A company runs its critical database on an Amazon RDS for PostgreSQL DB instance. The company wants to migrate to Amazon Aurora PostgreSQL with minimal downtime and data loss. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Create a DB snapshot of the RDS for PostgreSQL DB instance to populate a new Aurora PostgreSQL DB cluster.", "B. Create an Aurora read replica of the RDS for PostgreSQL DB instance. Promote the Aurora read replicate to a new Aurora PostgreSQL DB cluster.", "C. Use data import from Amazon S3 to migrate the database to an Aurora PostgreSQL DB cluster.", "D. Use the pg_dump utility to back up the RDS for PostgreSQL database. Restore the backup to a new Aurora PostgreSQL DB cluster. 343 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 618, "question": "618# A company's infrastructure consists of hundreds of Amazon EC2 instances that use Amazon Elastic Block Store (Amazon EBS) storage. A solutions architect must ensure that every EC2 instance can be recovered after a disaster. What should the solutions architect do to meet this requirement with the LEAST amount of effort?", "options": ["A. Take a snapshot of the EBS storage that is attached to each EC2 instance. Create an AWS CloudFormation template to launch new EC2 instances from the EBS storage.", "B. Take a snapshot of the EBS storage that is attached to each EC2 instance. Use AWS Elastic Beanstalk to set the environment based on the EC2 template and attach the EBS storage.", "C. Use AWS Backup to set up a backup plan for the entire group of EC2 instances. Use the AWS Backup API or the AWS CLI to speed up the restore process for multiple EC2 instances.", "D. Create an AWS Lambda function to take a snapshot of the EBS storage that is attached to each EC2 instance and copy the Amazon Machine Images (AMIs). Create another Lambda function to perform the restores with the copied AMIs and attach the EBS storage. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 618, "question": "618# A company's infrastructure consists of hundreds of Amazon EC2 instances that use Amazon Elastic Block Store (Amazon EBS) storage. A solutions architect must ensure that every EC2 instance can be recovered after a disaster. What should the solutions architect do to meet this requirement with the LEAST amount of effort?", "options": ["A. Take a snapshot of the EBS storage that is attached to each EC2 instance. Create an AWS CloudFormation template to launch new EC2 instances from the EBS storage.", "B. Take a snapshot of the EBS storage that is attached to each EC2 instance. Use AWS Elastic Beanstalk to set the environment based on the EC2 template and attach the EBS storage.", "C. Use AWS Backup to set up a backup plan for the entire group of EC2 instances. Use the AWS Backup API or the AWS CLI to speed up the restore process for multiple EC2 instances.", "D. Create an AWS Lambda function to take a snapshot of the EBS storage that is attached to each EC2 instance and copy the Amazon Machine Images (AMIs). Create another Lambda function to perform the restores with the copied AMIs and attach the EBS storage. 344 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 619, "question": "619# A company recently migrated to the AWS Cloud. The company wants a serverless solution for large-scale parallel on-demand processing of a semistructured dataset. The data consists of logs, media files, sales transactions, and IoT sensor data that is stored in Amazon S3. The company wants the solution to process thousands of items in the dataset in parallel. Which solution will meet these requirements with the MOST operational efficiency?", "options": ["A. Use the AWS Step Functions Map state in Inline mode to process the data in parallel.", "B. Use the AWS Step Functions Map state in Distributed mode to process the data in parallel.", "C. Use AWS Glue to process the data in parallel.", "D. Use several AWS Lambda functions to process the data in parallel. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 619, "question": "619# A company recently migrated to the AWS Cloud. The company wants a serverless solution for large-scale parallel on-demand processing of a semistructured dataset. The data consists of logs, media files, sales transactions, and IoT sensor data that is stored in Amazon S3. The company wants the solution to process thousands of items in the dataset in parallel. Which solution will meet these requirements with the MOST operational efficiency?", "options": ["A. Use the AWS Step Functions Map state in Inline mode to process the data in parallel.", "B. Use the AWS Step Functions Map state in Distributed mode to process the data in parallel.", "C. Use AWS Glue to process the data in parallel.", "D. Use several AWS Lambda functions to process the data in parallel. 345 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 620, "question": "620# A company will migrate 10 PB of data to Amazon S3 in 6 weeks. The current data center has a 500 Mbps uplink to the internet. Other on-premises applications share the uplink. The company can use 80% of the internet bandwidth for this one-time migration task. Which solution will meet these requirements?", "options": ["A. Configure AWS DataSync to migrate the data to Amazon S3 and to automatically verify the data.", "B. Use rsync to transfer the data directly to Amazon S3.", "C. Use the AWS CLI and multiple copy processes to send the data directly to Amazon S3.", "D. Order multiple AWS Snowball devices. Copy the data to the devices. Send the devices to AWS to copy the data to Amazon S3. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 620, "question": "620# A company will migrate 10 PB of data to Amazon S3 in 6 weeks. The current data center has a 500 Mbps uplink to the internet. Other on-premises applications share the uplink. The company can use 80% of the internet bandwidth for this one-time migration task. Which solution will meet these requirements?", "options": ["A. Configure AWS DataSync to migrate the data to Amazon S3 and to automatically verify the data.", "B. Use rsync to transfer the data directly to Amazon S3.", "C. Use the AWS CLI and multiple copy processes to send the data directly to Amazon S3.", "D. Order multiple AWS Snowball devices. Copy the data to the devices. Send the devices to AWS to copy the data to Amazon S3. 346 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 621, "question": "621# A company has several on-premises Internet Small Computer Systems Interface (ISCSI) network storage servers. The company wants to reduce the number of these servers by moving to the AWS Cloud. A solutions architect must provide low-latency access to frequently used data and reduce the dependency on on-premises servers with a minimal number of infrastructure changes. Which solution will meet these requirements?", "options": ["A. Deploy an Amazon S3 File Gateway.", "B. Deploy Amazon Elastic Block Store (Amazon EBS) storage with backups to Amazon S3.", "C. Deploy an AWS Storage Gateway volume gateway that is configured with stored volumes.", "D. Deploy an AWS Storage Gateway volume gateway that is configured with cached volumes. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 621, "question": "621# A company has several on-premises Internet Small Computer Systems Interface (ISCSI) network storage servers. The company wants to reduce the number of these servers by moving to the AWS Cloud. A solutions architect must provide low-latency access to frequently used data and reduce the dependency on on-premises servers with a minimal number of infrastructure changes. Which solution will meet these requirements?", "options": ["A. Deploy an Amazon S3 File Gateway.", "B. Deploy Amazon Elastic Block Store (Amazon EBS) storage with backups to Amazon S3.", "C. Deploy an AWS Storage Gateway volume gateway that is configured with stored volumes.", "D. Deploy an AWS Storage Gateway volume gateway that is configured with cached volumes. 347 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 622, "question": "622# A solutions architect is designing an application that will allow business users to upload objects to Amazon S3. The solution needs to maximize object durability. Objects also must be readily available at any time and for any length of time. Users will access objects frequently within the first 30 days after the objects are uploaded, but users are much less likely to access objects that are older than 30 days. Which solution meets these requirements MOST cost-effectively?", "options": ["A. Store all the objects in S3 Standard with an S3 Lifecycle rule to transition the objects to S3 Glacier after 30 days.", "B. Store all the objects in S3 Standard with an S3 Lifecycle rule to transition the objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days.", "C. Store all the objects in S3 Standard with an S3 Lifecycle rule to transition the objects to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 30 days.", "D. Store all the objects in S3 Intelligent-Tiering with an S3 Lifecycle rule to transition the objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 622, "question": "622# A solutions architect is designing an application that will allow business users to upload objects to Amazon S3. The solution needs to maximize object durability. Objects also must be readily available at any time and for any length of time. Users will access objects frequently within the first 30 days after the objects are uploaded, but users are much less likely to access objects that are older than 30 days. Which solution meets these requirements MOST cost-effectively?", "options": ["A. Store all the objects in S3 Standard with an S3 Lifecycle rule to transition the objects to S3 Glacier after 30 days.", "B. Store all the objects in S3 Standard with an S3 Lifecycle rule to transition the objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days.", "C. Store all the objects in S3 Standard with an S3 Lifecycle rule to transition the objects to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 30 days.", "D. Store all the objects in S3 Intelligent-Tiering with an S3 Lifecycle rule to transition the objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days. 348 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 623, "question": "623# A company has migrated a two-tier application from its on-premises data center to the AWS Cloud. The data tier is a Multi-AZ deployment of Amazon RDS for Oracle with 12 TB of General Purpose SSD Amazon Elastic Block Store (Amazon EBS) storage. The application is designed to process and store documents in the database as binary large objects (blobs) with an average document size of 6 MB. The database size has grown over time, reducing the performance and increasing the cost of storage. The company must improve the database performance and needs a solution that is highly available and resilient. Which solution will meet these requirements MOST cost-effectively?", "options": ["A. Reduce the RDS DB instance size. Increase the storage capacity to 24 TiB. Change the storage type to Magnetic.", "B. Increase the RDS DB instance size. Increase the storage capacity to 24 TiChange the storage type to Provisioned IOPS.", "C. Create an Amazon S3 bucket. Update the application to store documents in the S3 bucket. Store the object metadata in the existing database.", "D. Create an Amazon DynamoDB table. Update the application to use DynamoDB. Use AWS Database Migration Service (AWS DMS) to migrate data from the Oracle database to DynamoDB. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 623, "question": "623# A company has migrated a two-tier application from its on-premises data center to the AWS Cloud. The data tier is a Multi-AZ deployment of Amazon RDS for Oracle with 12 TB of General Purpose SSD Amazon Elastic Block Store (Amazon EBS) storage. The application is designed to process and store documents in the database as binary large objects (blobs) with an average document size of 6 MB. The database size has grown over time, reducing the performance and increasing the cost of storage. The company must improve the database performance and needs a solution that is highly available and resilient. Which solution will meet these requirements MOST cost-effectively?", "options": ["A. Reduce the RDS DB instance size. Increase the storage capacity to 24 TiB. Change the storage type to Magnetic.", "B. Increase the RDS DB instance size. Increase the storage capacity to 24 TiChange the storage type to Provisioned IOPS.", "C. Create an Amazon S3 bucket. Update the application to store documents in the S3 bucket. Store the object metadata in the existing database.", "D. Create an Amazon DynamoDB table. Update the application to use DynamoDB. Use AWS Database Migration Service (AWS DMS) to migrate data from the Oracle database to DynamoDB. 349 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 624, "question": "624# A company has an application that serves clients that are deployed in more than 20,000 retail storefront locations around the world. The application consists of backend web services that are exposed over HTTPS on port 443. The application is hosted on Amazon EC2 instances behind an Application Load Balancer (ALB). The retail locations communicate with the web application over the public internet. The company allows each retail location to register the IP address that the retail location has been allocated by its local ISP. The company's security team recommends to increase the security of the application endpoint by restricting access to only the IP addresses registered by the retail locations. What should a solutions architect do to meet these requirements?", "options": ["A. Associate an AWS WAF web ACL with the ALB. Use IP rule sets on the ALB to filter traffic. Update the IP addresses in the rule to include the registered IP addresses.", "B. Deploy AWS Firewall Manager to manage the ALConfigure firewall rules to restrict traffic to the ALModify the firewall rules to include the registered IP addresses.", "C. Store the IP addresses in an Amazon DynamoDB table. Configure an AWS Lambda authorization function on the ALB to validate that incoming requests are from the registered IP addresses.", "D. Configure the network ACL on the subnet that contains the public interface of the ALB. Update the ingress rules on the network ACL with entries for each of the registered IP addresses. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 624, "question": "624# A company has an application that serves clients that are deployed in more than 20,000 retail storefront locations around the world. The application consists of backend web services that are exposed over HTTPS on port 443. The application is hosted on Amazon EC2 instances behind an Application Load Balancer (ALB). The retail locations communicate with the web application over the public internet. The company allows each retail location to register the IP address that the retail location has been allocated by its local ISP. The company's security team recommends to increase the security of the application endpoint by restricting access to only the IP addresses registered by the retail locations. What should a solutions architect do to meet these requirements?", "options": ["A. Associate an AWS WAF web ACL with the ALB. Use IP rule sets on the ALB to filter traffic. Update the IP addresses in the rule to include the registered IP addresses.", "B. Deploy AWS Firewall Manager to manage the ALConfigure firewall rules to restrict traffic to the ALModify the firewall rules to include the registered IP addresses.", "C. Store the IP addresses in an Amazon DynamoDB table. Configure an AWS Lambda authorization function on the ALB to validate that incoming requests are from the registered IP addresses.", "D. Configure the network ACL on the subnet that contains the public interface of the ALB. Update the ingress rules on the network ACL with entries for each of the registered IP addresses. 350 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 625, "question": "625# A company is building a data analysis platform on AWS by using AWS Lake Formation. The platform will ingest data from different sources such as Amazon S3 and Amazon RDS. The company needs a secure solution to prevent access to portions of the data that contain sensitive information. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Create an IAM role that includes permissions to access Lake Formation tables.", "B. Create data filters to implement row-level security and cell-level security.", "C. Create an AWS Lambda function that removes sensitive information before Lake Formation ingests the data.", "D. Create an AWS Lambda function that periodically queries and removes sensitive information from Lake Formation tables. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 625, "question": "625# A company is building a data analysis platform on AWS by using AWS Lake Formation. The platform will ingest data from different sources such as Amazon S3 and Amazon RDS. The company needs a secure solution to prevent access to portions of the data that contain sensitive information. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Create an IAM role that includes permissions to access Lake Formation tables.", "B. Create data filters to implement row-level security and cell-level security.", "C. Create an AWS Lambda function that removes sensitive information before Lake Formation ingests the data.", "D. Create an AWS Lambda function that periodically queries and removes sensitive information from Lake Formation tables. 351 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 626, "question": "626# A company deploys Amazon EC2 instances that run in a VPC. The EC2 instances load source data into Amazon S3 buckets so that the data can be processed in the future. According to compliance laws, the data must not be transmitted over the public internet. Servers in the company's on-premises data center will consume the output from an application that runs on the EC2 instances. Which solution will meet these requirements?", "options": ["A. Deploy an interface VPC endpoint for Amazon EC2. Create an AWS Site-to-Site VPN connection between the company and the VPC.", "B. Deploy a gateway VPC endpoint for Amazon S3. Set up an AWS Direct Connect connection between the on-premises network and the VPC.", "C. Set up an AWS Transit Gateway connection from the VPC to the S3 buckets. Create an AWS Site-to-Site VPN connection between the company and the VPC.", "D. Set up proxy EC2 instances that have routes to NAT gateways. Configure the proxy EC2 instances to fetch S3 data and feed the application instances. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 626, "question": "626# A company deploys Amazon EC2 instances that run in a VPC. The EC2 instances load source data into Amazon S3 buckets so that the data can be processed in the future. According to compliance laws, the data must not be transmitted over the public internet. Servers in the company's on-premises data center will consume the output from an application that runs on the EC2 instances. Which solution will meet these requirements?", "options": ["A. Deploy an interface VPC endpoint for Amazon EC2. Create an AWS Site-to-Site VPN connection between the company and the VPC.", "B. Deploy a gateway VPC endpoint for Amazon S3. Set up an AWS Direct Connect connection between the on-premises network and the VPC.", "C. Set up an AWS Transit Gateway connection from the VPC to the S3 buckets. Create an AWS Site-to-Site VPN connection between the company and the VPC.", "D. Set up proxy EC2 instances that have routes to NAT gateways. Configure the proxy EC2 instances to fetch S3 data and feed the application instances. 352 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 627, "question": "627# A company has an application with a REST-based interface that allows data to be received in near-real time from a third-party vendor. Once received, the application processes and stores the data for further analysis. The application is running on Amazon EC2 instances. The third-party vendor has received many 503 Service Unavailable Errors when sending data to the application. When the data volume spikes, the compute capacity reaches its maximum limit and the application is unable to process all requests. Which design should a solutions architect recommend to provide a more scalable solution?", "options": ["A. Use Amazon Kinesis Data Streams to ingest the data. Process the data using AWS Lambda functions.", "B. Use Amazon API Gateway on top of the existing application. Create a usage plan with a quota limit for the third-party vendor.", "C. Use Amazon Simple Notification Service (Amazon SNS) to ingest the data. Put the EC2 instances in an Auto Scaling group behind an Application Load Balancer.", "D. Repackage the application as a container. Deploy the application using Amazon Elastic Container Service (Amazon ECS) using the EC2 launch type with an Auto Scaling group. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 627, "question": "627# A company has an application with a REST-based interface that allows data to be received in near-real time from a third-party vendor. Once received, the application processes and stores the data for further analysis. The application is running on Amazon EC2 instances. The third-party vendor has received many 503 Service Unavailable Errors when sending data to the application. When the data volume spikes, the compute capacity reaches its maximum limit and the application is unable to process all requests. Which design should a solutions architect recommend to provide a more scalable solution?", "options": ["A. Use Amazon Kinesis Data Streams to ingest the data. Process the data using AWS Lambda functions.", "B. Use Amazon API Gateway on top of the existing application. Create a usage plan with a quota limit for the third-party vendor.", "C. Use Amazon Simple Notification Service (Amazon SNS) to ingest the data. Put the EC2 instances in an Auto Scaling group behind an Application Load Balancer.", "D. Repackage the application as a container. Deploy the application using Amazon Elastic Container Service (Amazon ECS) using the EC2 launch type with an Auto Scaling group. 353 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 628, "question": "628# A company has an application that runs on Amazon EC2 instances in a private subnet. The application needs to process sensitive information from an Amazon S3 bucket. The application must not use the internet to connect to the S3 bucket. Which solution will meet these requirements?", "options": ["A. Configure an internet gateway. Update the S3 bucket policy to allow access from the internet gateway. Update the application to use the new internet gateway.", "B. Configure a VPN connection. Update the S3 bucket policy to allow access from the VPN connection. Update the application to use the new VPN connection.", "C. Configure a NAT gateway. Update the S3 bucket policy to allow access from the NAT gateway. Update the application to use the new NAT gateway.", "D. Configure a VPC endpoint. Update the S3 bucket policy to allow access from the VPC endpoint. Update the application to use the new VPC endpoint. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 628, "question": "628# A company has an application that runs on Amazon EC2 instances in a private subnet. The application needs to process sensitive information from an Amazon S3 bucket. The application must not use the internet to connect to the S3 bucket. Which solution will meet these requirements?", "options": ["A. Configure an internet gateway. Update the S3 bucket policy to allow access from the internet gateway. Update the application to use the new internet gateway.", "B. Configure a VPN connection. Update the S3 bucket policy to allow access from the VPN connection. Update the application to use the new VPN connection.", "C. Configure a NAT gateway. Update the S3 bucket policy to allow access from the NAT gateway. Update the application to use the new NAT gateway.", "D. Configure a VPC endpoint. Update the S3 bucket policy to allow access from the VPC endpoint. Update the application to use the new VPC endpoint. 354 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 629, "question": "629# A company uses Amazon Elastic Kubernetes Service (Amazon EKS) to run a container application. The EKS cluster stores sensitive information in the Kubernetes secrets object. The company wants to ensure that the information is encrypted. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Use the container application to encrypt the information by using AWS Key Management Service (AWS KMS).", "B. Enable secrets encryption in the EKS cluster by using AWS Key Management Service (AWS KMS).", "C. Implement an AWS Lambda function to encrypt the information by using AWS Key Management Service (AWS KMS).", "D. Use AWS Systems Manager Parameter Store to encrypt the information by using AWS Key Management Service (AWS KMS). sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 629, "question": "629# A company uses Amazon Elastic Kubernetes Service (Amazon EKS) to run a container application. The EKS cluster stores sensitive information in the Kubernetes secrets object. The company wants to ensure that the information is encrypted. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Use the container application to encrypt the information by using AWS Key Management Service (AWS KMS).", "B. Enable secrets encryption in the EKS cluster by using AWS Key Management Service (AWS KMS).", "C. Implement an AWS Lambda function to encrypt the information by using AWS Key Management Service (AWS KMS).", "D. Use AWS Systems Manager Parameter Store to encrypt the information by using AWS Key Management Service (AWS KMS). 355 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 630, "question": "630# A company is designing a new multi-tier web application that consists of the following components: \u2022 Web and application servers that run on Amazon EC2 instances as part of Auto Scaling groups. \u2022 An Amazon RDS DB instance for data storage. A solutions architect needs to limit access to the application servers so that only the web servers can access them. Which solution will meet these requirements?", "options": ["A. Deploy AWS PrivateLink in front of the application servers. Configure the network ACL to allow only the web servers to access the application servers.", "B. Deploy a VPC endpoint in front of the application servers. Configure the security group to allow only the web servers to access the application servers.", "C. Deploy a Network Load Balancer with a target group that contains the application servers' Auto Scaling group. Configure the network ACL to allow only the web servers to access the application servers.", "D. Deploy an Application Load Balancer with a target group that contains the application servers' Auto Scaling group. Configure the security group to allow only the web servers to access the application servers. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}]