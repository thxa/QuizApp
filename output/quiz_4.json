[{"_id": 182, "question": "182 # A company that uses AWS is building an application to transfer data to a product manufacturer. The company has its own identity provider (IdP). The company wants the IdP to authenticate application users while the users use the application to transfer data. The company must use Applicability Statement 2 (AS2) protocol. Which solution will meet these requirements?", "options": ["A. Use AWS DataSync to transfer the data. Create an AWS Lambda function for IdP authentication.", "B. Use Amazon AppFlow flows to transfer the data. Create an Amazon Elastic Container Service (Amazon ECS) task for IdP authentication.", "C. Use AWS Transfer Family to transfer the data. Create an AWS Lambda function for IdP authentication.", "D. Use AWS Storage Gateway to transfer the data. Create an Amazon Cognito identity pool for IdP authentication. Selected Answer: C Option C stands out stronger because AWS Transfer Family securely scales your recurring business-to- business file transfers to AWS Storage services using SFTP, FTPS, FTP, and AS2 protocols. And AWS Lambda can be used to authenticate users with the company's IdP."], "explain": "", "answers": [], "resources": ["https://docs.aws.amazon.com/transfer/latest/userguide/custom-identity-provider-users.html", "https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248510887705&usg=AOvVaw3gUoAlPfXAZGcfKv0wiRZ8", "https://www.google.com/url?q=https://docs.aws.amazon.com/ja_jp/awsaccountbilling/latest/aboutv2/view-billing-dashboard.html&sa=D&source=apps-viewer-frontend&ust=1720248510887773&usg=AOvVaw3NDD_FQ1fVqzt7Bu4HtCzB", "https://docs.aws.amazon.com/ja_jp/awsaccountbilling/latest/aboutv2/view-billing-dashboard.html", "https://www.google.com/url?q=https://docs.aws.amazon.com/transfer/latest/userguide/custom-identity-provider-users.html&sa=D&source=apps-viewer-frontend&ust=1720248510887786&usg=AOvVaw3l8mFGmlB8w8-zHKZ5igeA", "https://docs.aws.amazon.com/transfer/latest/userguide/custom-identity-provider-users.html"]}, {"_id": 183, "question": "183 # A company is moving its data management application to AWS. The company wants to transition to an event-driven architecture. The architecture needs to be more distributed and to use serverless concepts while performing the different aspects of the workflow. The company also wants to minimize operational overhead. Which solution will meet these requirements?", "options": ["A. Build out the workflow in AWS Glue. Use AWS Glue to invoke AWS Lambda functions to process the workflow steps.", "B. Build out the workflow in AWS Step Functions. Deploy the application on Amazon EC2 instances. Use Step Functions to invoke the workflow steps on the EC2 instances.", "C. Build out the workflow in Amazon EventBridge. Use EventBridge to invoke AWS Lambda functions on a schedule to process the workflow steps.", "D. Build out the workflow in AWS Step Functions. Use Step Functions to create a state machine. Use the state machine to invoke AWS Lambda functions to process the workflow steps. Selected Answer: D Step Functions is based on state machines and tasks. A state machine is a workflow. A task is a state in a workflow that represents a single unit of work that another AWS service performs. Each step in a workflow is a state. Depending on your use case, you can have Step Functions call AWS services, such as Lambda, to perform tasks."], "explain": "", "answers": [], "resources": ["https://docs.aws.amazon.com/step-functions/latest/dg/welcome.html"]}, {"_id": 184, "question": "184 # A company is designing the network for an online multi-player game. The game uses the UDP networking protocol and will be deployed in eight AWS Regions. The network architecture needs to minimize latency and packet loss to give end users a high-quality gaming experience. Which solution will meet these requirements?", "options": ["A. Setup a transit gateway in each Region. Create inter-Region peering attachments between each transit gateway.", "B. Set up AWS Global Accelerator with UDP listeners and endpoint groups in each Region.", "C. Set up Amazon CloudFront with UDP turned on. Configure an origin in each Region.", "D. Set up a VPC peering mesh between each Region. Turn on UDP for each VPC. Selected Answer: B AWS Global Accelerator = TCP/UDP minimize latency Q: What is AWS Global Accelerator? A: AWS Global Accelerator is a networking service that helps you improve the availability and performance of the applications that you offer to your global users. AWS Global Accelerator is easy to set up, configure, and manage. It provides static IP addresses that provide a fixed entry point to your applications and eliminate the complexity of managing specific IP addresses for different AWS Regions and Availability Zones. AWS Global Accelerator always routes user traffic to the optimal endpoint based on performance, reacting instantly to changes in application health, your user\u2019s location, and policies that you configure. You can test the performance benefits from your location with a speed comparison tool. Like other AWS services, AWS Global Accelerator is a self-service, pay-per-use offering, requiring no long term commitments or minimum fees."], "explain": "", "answers": [], "resources": ["https://aws.amazon.com/global-", "https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248511483821&usg=AOvVaw1xbFAoOAL3IY20kuc02ZWC", "https://www.google.com/url?q=https://docs.aws.amazon.com/step-functions/latest/dg/welcome.html&sa=D&source=apps-viewer-frontend&ust=1720248511483956&usg=AOvVaw1X2sKdXXuUGdsa0iewGBZV", "https://docs.aws.amazon.com/step-functions/latest/dg/welcome.html", "https://www.google.com/url?q=https://aws.amazon.com/global-accelerator/faqs/&sa=D&source=apps-viewer-frontend&ust=1720248511483968&usg=AOvVaw1B-JDklUTC-2kqcgbkMBjE", "https://aws.amazon.com/global-accelerator/faqs/"]}, {"_id": 90, "question": "90 The company wants to minimize any disruptions, stabilize performance, and reduce costs while retaining the capacity for double the IOPS. The company wants to move the database tier to a fully managed solution that is highly available and fault tolerant. Which solution will meet these requirements MOST cost-effectively?", "options": ["A. Use a Multi-AZ deployment of an Amazon RDS for MySQL DB instance with an io2 Block Express EBS volume.", "B. Use a Multi-AZ deployment of an Amazon RDS for MySQL DB instance with a General Purpose SSD (gp2) EBS volume.", "C. Use Amazon S3 Intelligent-Tiering access tiers.", "D. Use two large EC2 instances to host the database in active-passive mode. Selected Answer: B RDS does not support IO2 or IO2express . GP2 can do the required IOPS RDS supported Storage >"], "explain": "", "answers": [], "resources": ["https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html", "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/general-purpose.html#gp2-performance"]}, {"_id": 186, "question": "186 # A company hosts a serverless application on AWS. The application uses Amazon API Gateway, AWS Lambda, and an Amazon RDS for PostgreSQL database. The company notices an increase in application errors that result from database connection timeouts during times of peak traffic or unpredictable traffic. The company needs a solution that reduces the application failures with the least amount of change to the code. What should a solutions architect do to meet these requirements?", "options": ["A. Reduce the Lambda concurrency rate.", "B. Enable RDS Proxy on the RDS DB instance.", "C. Resize the RDS DB instance class to accept more connections.", "D. Migrate the database to Amazon DynamoDB with on-demand scaling. Selected Answer: B Many applications, including those built on modern serverless architectures, can have a large number of open connections to the database server and may open and close database connections at a high rate, exhausting database memory and compute resources. Amazon RDS Proxy allows applications to pool and share connections established with the database, improving database efficiency and application scalability. With RDS Proxy, failover times for Aurora and RDS databases are reduced by up to 66%."], "explain": "", "answers": [], "resources": ["https://aws.amazon.com/rds/proxy/"]}, {"_id": 187, "question": "187 # A company is migrating an old application to AWS. The application runs a batch job every hour and is CPU intensive. The batch job takes 15 minutes on average with an on-premises server. The server has 64 virtual CPU (vCPU) and 512 GiB of memory. Which solution will run the batch job within 15 minutes with the LEAST operational overhead?", "options": ["A. Use AWS Lambda with functional scaling.", "B. Use Amazon Elastic Container Service (Amazon ECS) with AWS Fargate.", "C. Use Amazon Lightsail with AWS Auto Scaling.", "D. Use AWS Batch on Amazon EC2. A Wrong, the job takes \"On average 15 minutes\" and requires more cpu and ram than lambda can deal with \"AWS Lambda now supports up to 10 GB of memory and 6 vCPU cores for Lambda Functions.\""], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248512051474&usg=AOvVaw13yUb0ltp1f4LvdJc7nxuJ", "https://www.google.com/url?q=https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html&sa=D&source=apps-viewer-frontend&ust=1720248512051534&usg=AOvVaw008BqCKIexltIcQKx-qxZy", "https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html", "https://www.google.com/url?q=https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/general-purpose.html%23gp2-performance&sa=D&source=apps-viewer-frontend&ust=1720248512051548&usg=AOvVaw1HSvhZ4sg3zUDxKKKgUQb9", "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/general-purpose.html#gp2-performance", "https://www.google.com/url?q=https://aws.amazon.com/rds/proxy/&sa=D&source=apps-viewer-frontend&ust=1720248512051560&usg=AOvVaw0ZNeI9j9vbhxKYVDw6Dx86", "https://aws.amazon.com/rds/proxy/", "https://aws.amazon.com/about-aws/whats-new/2020/12/aws-lambda-supports-10gb-memory-6-vcpu-"]}, {"_id": 188, "question": "188 # A company stores its data objects in Amazon S3 Standard storage. A solutions architect has found that 75% of the data is rarely accessed after 30 days. The company needs all the data to remain immediately accessible with the same high availability and resiliency, but the company wants to minimize storage costs. Which storage solution will meet these requirements?", "options": ["A. Move the data objects to S3 Glacier Deep Archive after 30 days.", "B. Move the data objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days.", "C. Move the data objects to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 30 days.", "D. Move the data objects to S3 One Zone-Infrequent Access (S3 One Zone-IA) immediately. Selected Answer: B S3 Glacier Deep Archive is intended for data that is rarely accessed and can tolerate retrieval times measured in hours. Moving data to S3 One Zone-IA immediately would not meet the requirement of immediate accessibility with the same high availability and resiliency. Question #: 357"], "explain": "", "answers": [], "resources": []}, {"_id": 189, "question": "189 # A gaming company is moving its public scoreboard from a data center to the AWS Cloud. The company uses Amazon EC2 Windows Server instances behind an Application Load Balancer to host its dynamic application. The company needs a highly available storage solution for the application. The application consists of static files and dynamic server-side code. Which combination of steps should a solutions architect take to meet these requirements? (Choose two.)", "options": ["A. Store the static files on Amazon S3. Use Amazon CloudFront to cache objects at the edge.", "B. Store the static files on Amazon S3. Use Amazon ElastiCache to cache objects at the edge.", "C. Store the server-side code on Amazon Elastic File System (Amazon EFS). Mount the EFS volume on each EC2 instance to share the files.", "D. Store the server-side code on Amazon FSx for Windows File Server. Mount the FSx for Windows File Server volume on each EC2 instance to share the files.", "E. Store the server-side code on a General Purpose SSD (gp2) Amazon Elastic Block Store (Amazon EBS) volume. Mount the EBS volume on each EC2 instance to share the files. Selected Answer: AD A because Elasticache, despite being ideal for leaderboards per Amazon, doesn't cache at edge locations. D because FSx has higher performance for low latency needs."], "explain": "", "answers": [], "resources": ["https://www.techtarget.com/searchaws/tip/Amazon-FSx-vs-EFS-Compare-the-AWS-file-services", "https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248512646511&usg=AOvVaw15J1goOdRN4EVWnYtjUShx", "https://www.google.com/url?q=https://aws.amazon.com/about-aws/whats-new/2020/12/aws-lambda-supports-10gb-memory-6-vcpu-cores-lambda-functions/&sa=D&source=apps-viewer-frontend&ust=1720248512646588&usg=AOvVaw0017YNzlbM1L4-uC8u4bO0", "https://aws.amazon.com/about-aws/whats-new/2020/12/aws-lambda-supports-10gb-memory-6-vcpu-cores-lambda-functions/", "https://www.google.com/url?q=https://www.techtarget.com/searchaws/tip/Amazon-FSx-vs-EFS-Compare-the-AWS-file-services&sa=D&source=apps-viewer-frontend&ust=1720248512646605&usg=AOvVaw3RySLsO3hFZtYjNch8zFow", "https://www.techtarget.com/searchaws/tip/Amazon-FSx-vs-EFS-Compare-the-AWS-file-services"]}, {"_id": 92, "question": "92 The company wants to resize the images dynamically and serve appropriate formats to clients. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Install an external image management library on an EC2 instance. Use the image management library to process the images.", "B. Create a CloudFront origin request policy. Use the policy to automatically resize images and to serve the appropriate format based on the User-Agent HTTP header in the request.", "C. Use a Lambda@Edge function with an external image management library. Associate the Lambda@Edge function with the CloudFront behaviours that serve the images.", "D. Create a CloudFront response headers policy. Use the policy to automatically resize images and to serve the appropriate format based on the User-Agent HTTP header in the request. Selected Answer: C"], "explain": "", "answers": [], "resources": ["https://aws.amazon.com/cn/blogs/networking-and-content-delivery/resizing-images-with-amazon-"]}, {"_id": 191, "question": "191 # A hospital needs to store patient records in an Amazon S3 bucket. The hospital\u2019s compliance team must ensure that all protected health information (PHI) is encrypted in transit and at rest. The compliance team must administer the encryption key for data at rest. Which solution will meet these requirements?", "options": ["A. Create a public SSL/TLS certificate in AWS Certificate Manager (ACM). Associate the certificate with Amazon S3. Configure default encryption for each S3 bucket to use server-side encryption with AWS KMS keys (SSE-KMS). Assign the compliance team to manage the KMS keys.", "B. Use the aws:SecureTransport condition on S3 bucket policies to allow only encrypted connections over HTTPS (TLS). Configure default encryption for each S3 bucket to use server-side encryption with S3 managed encryption keys (SSE-S3). Assign the compliance team to manage the SSE-S3 keys.", "C. Use the aws:SecureTransport condition on S3 bucket policies to allow only encrypted connections over HTTPS (TLS). Configure default encryption for each S3 bucket to use server-side encryption with AWS KMS keys (SSE-KMS). Assign the compliance team to manage the KMS keys.", "D. Use the aws:SecureTransport condition on S3 bucket policies to allow only encrypted connections over HTTPS (TLS). Use Amazon Macie to protect the sensitive data that is stored in Amazon S3. Assign the compliance team to manage Macie. Correct Answer is \"C\" \u201cD\u201d is not correct because Amazon Macie securely stores your data at rest using AWS encryption solutions. Macie encrypts data, such as findings, using an AWS managed key from AWS Key Management Service (AWS KMS). However, in the question there is a requirement that the compliance team must administer the encryption key for data at rest."], "explain": "", "answers": [], "resources": ["https://docs.aws.amazon.com/macie/latest/user/data-protection.html", "https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248513221104&usg=AOvVaw2CTKtmVJMLYpBRVF2LYvT7", "https://www.google.com/url?q=https://aws.amazon.com/cn/blogs/networking-and-content-delivery/resizing-images-with-amazon-cloudfront-lambdaedge-aws-cdn-blog/&sa=D&source=apps-viewer-frontend&ust=1720248513221152&usg=AOvVaw2ljXKwuVXrkwu7Jvow8jL_", "https://aws.amazon.com/cn/blogs/networking-and-content-delivery/resizing-images-with-amazon-cloudfront-lambdaedge-aws-cdn-blog/", "https://www.google.com/url?q=https://docs.aws.amazon.com/macie/latest/user/data-protection.html&sa=D&source=apps-viewer-frontend&ust=1720248513221161&usg=AOvVaw18q_bQI8wRKwYPP2GPZkya", "https://docs.aws.amazon.com/macie/latest/user/data-protection.html"]}, {"_id": 192, "question": "192 # A company uses Amazon API Gateway to run a private gateway with two REST APIs in the same VPC. The BuyStock RESTful web service calls the CheckFunds RESTful web service to ensure that enough funds are available before a stock can be purchased. The company has noticed in the VPC flow logs that the BuyStock RESTful web service calls the CheckFunds RESTful web service over the internet instead of through the VPC. A solutions architect must implement a solution so that the APIs communicate through the VPC. Which solution will meet these requirements with the FEWEST changes to the code?", "options": ["A. Add an X-API-Key header in the HTTP header for authorization.", "B. Use an interface endpoint.", "C. Use a gateway endpoint.", "D. Add an Amazon Simple Queue Service (Amazon SQS) queue between the two REST APIs. Answer B With API GW, you can create multiple prv REST APIs, only accessible with an interface VPC endpt. To allow/ deny simple or cross acc access to your API from selected VPCs & its endpts, you use resource plcys. In addition, you can also use DX for a connection between onprem network to VPC or your prv API. API GW to VPC:"], "explain": "", "answers": [], "resources": ["https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-private-apis.html"]}, {"_id": 193, "question": "193 # A company hosts a multiplayer gaming application on AWS. The company wants the application to read data with sub-millisecond latency and run one-time queries on historical data. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Use Amazon RDS for data that is frequently accessed. Run a periodic custom script to export the data to an Amazon S3 bucket.", "B. Store the data directly in an Amazon S3 bucket. Implement an S3 Lifecycle policy to move older data to S3 Glacier Deep Archive for long-term storage. Run one-time queries on the data in Amazon S3 by using Amazon Athena.", "C. Use Amazon DynamoDB with DynamoDB Accelerator (DAX) for data that is frequently accessed. Export the data to an Amazon S3 bucket by using DynamoDB table export. Run one-time queries on the data in Amazon S3 by using Amazon Athena.", "D. Use Amazon DynamoDB for data that is frequently accessed. Turn on streaming to Amazon Kinesis Data Streams. Use Amazon Kinesis Data Firehose to read the data from Kinesis Data Streams. Store the records in an Amazon S3 bucket. Selected Answer: C C is correct As they would like to retrieve the data with sub-millisecond, DynamoDB with DAX is the answer. DynamoDB supports some of the world's largest scale applications by providing consistent, single-digit millisecond response times at any scale. You can build applications with virtually unlimited throughput and storage. A don't meets a requirement (LEAST operational overhead) because use script"], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248513839784&usg=AOvVaw3E76oGhKwbeJY7xt9MzH1w", "https://www.google.com/url?q=https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-private-apis.html&sa=D&source=apps-viewer-frontend&ust=1720248513839837&usg=AOvVaw1nxGa_m2U7xGYGMHkbPFTD", "https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-private-apis.html"]}, {"_id": 194, "question": "194 # A company uses a payment processing system that requires messages for a particular payment ID to be received in the same order that they were sent. Otherwise, the payments might be processed incorrectly. Which actions should a solutions architect take to meet this requirement? (Choose two.)", "options": ["A. Write the messages to an Amazon DynamoDB table with the payment ID as the partition key.", "B. Write the messages to an Amazon Kinesis data stream with the payment ID as the partition key.", "C. Write the messages to an Amazon ElastiCache for Memcached cluster with the payment ID as the key.", "D. Write the messages to an Amazon Simple Queue Service (Amazon SQS) queue. Set the message attribute to use the payment ID.", "E. Write the messages to an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Set the message group to use the payment ID.Most Voted Selected Answer: BE 1) SQS FIFO queues guarantee that messages are received in the exact order they are sent. Using the payment ID as the message group ensures all messages for a payment ID are received sequentially. 2) Kinesis data streams can also enforce ordering on a per partition key basis. Using the payment ID as the partition key will ensure strict ordering of messages for each payment ID. The other options do not guarantee message ordering. DynamoDB and ElastiCache are not message queues. SQS standard queues deliver messages in approximate order only. E --> no doubt B --> see"], "explain": "", "answers": [], "resources": ["https://docs.aws.amazon.com/streams/latest/dev/key-concepts.html"]}, {"_id": 195, "question": "195 # A company is building a game system that needs to send unique events to separate leaderboard, matchmaking, and authentication services concurrently. The company needs an AWS event-driven system that guarantees the order of the events. Which solution will meet these requirements?", "options": ["A. Amazon EventBridge event bus", "B. Amazon Simple Notification Service (Amazon SNS) FIFO topics", "C. Amazon Simple Notification Service (Amazon SNS) standard topics", "D. Amazon Simple Queue Service (Amazon SQS) FIFO queues Selected Answer: B Amazon SNS is a highly available and durable publish-subscribe messaging service that allows applications to send messages to multiple subscribers through a topic. SNS FIFO topics are designed to ensure that messages are delivered in the order in which they are sent. This makes them ideal for situations where message order is important, such as in the case of the company's game system. Option A, Amazon EventBridge event bus, is a serverless event bus service that makes it easy to build event- driven applications. While it supports ordering of events, it does not provide guarantees on the order of delivery."], "explain": "", "answers": [], "resources": ["https://docs.aws.amazon.com/sns/latest/dg/fifo-example-use-case.html"]}, {"_id": 196, "question": "196 # A hospital is designing a new application that gathers symptoms from patients. The hospital has decided to use Amazon Simple Queue Service (Amazon SQS) and Amazon Simple Notification Service (Amazon SNS) in the architecture. A solutions architect is reviewing the infrastructure design. Data must be encrypted at rest and in transit. Only authorized personnel of the hospital should be able to access the data. Which combination of steps should the solutions architect take to meet these requirements? (Choose two.) https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248514439375&usg=AOvVaw0NQkkzTgUoBzt6fEb8Ch0F https://www.google.com/url?q=https://docs.aws.amazon.com/streams/latest/dev/key-concepts.html&sa=D&source=apps-viewer-frontend&ust=1720248514439417&usg=AOvVaw3TJF4HZfChgFiwLBdKEQn1 https://docs.aws.amazon.com/streams/latest/dev/key-concepts.html https://www.google.com/url?q=https://docs.aws.amazon.com/sns/latest/dg/fifo-example-use-case.html&sa=D&source=apps-viewer-frontend&ust=1720248514439425&usg=AOvVaw3LAyEVk7PtenHRhkR_De8A https://docs.aws.amazon.com/sns/latest/dg/fifo-example-use-case.html 95", "options": ["A. Turn on server-side encryption on the SQS components. Update the default key policy to restrict key usage to a set of authorized principals.", "B. Turn on server-side encryption on the SNS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply a key policy to restrict key usage to a set of authorized principals.", "C. Turn on encryption on the SNS components. Update the default key policy to restrict key usage to a set of authorized principals. Set a condition in the topic policy to allow only encrypted connections over TLS.", "D. Turn on server-side encryption on the SQS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply a key policy to restrict key usage to a set of authorized principals. Set a condition in the queue policy to allow only encrypted connections over TLS.", "E. Turn on server-side encryption on the SQS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply an IAM policy to restrict key usage to a set of authorized principals. Set a condition in the queue policy to allow only encrypted connections over TLS. Selected Answer: BD read this:"], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248514439375&usg=AOvVaw0NQkkzTgUoBzt6fEb8Ch0F", "https://www.google.com/url?q=https://docs.aws.amazon.com/streams/latest/dev/key-concepts.html&sa=D&source=apps-viewer-frontend&ust=1720248514439417&usg=AOvVaw3TJF4HZfChgFiwLBdKEQn1", "https://docs.aws.amazon.com/streams/latest/dev/key-concepts.html", "https://www.google.com/url?q=https://docs.aws.amazon.com/sns/latest/dg/fifo-example-use-case.html&sa=D&source=apps-viewer-frontend&ust=1720248514439425&usg=AOvVaw3LAyEVk7PtenHRhkR_De8A", "https://docs.aws.amazon.com/sns/latest/dg/fifo-example-use-case.html", "https://docs.aws.amazon.com/sns/latest/dg/sns-server-side-encryption.html", "https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-server-side-"]}, {"_id": 197, "question": "197 # A company runs a web application that is backed by Amazon RDS. A new database administrator caused data loss by accidentally editing information in a database table. To help recover from this type of incident, the company wants the ability to restore the database to its state from 5 minutes before any change within the last 30 days. Which feature should the solutions architect include in the design to meet this requirement?", "options": ["A. Read replicas", "B. Manual snapshots", "C. Automated backups", "D. Multi-AZ deployments Selected Answer: C Option C, Automated backups, will meet the requirement. Amazon RDS allows you to automatically create backups of your DB instance. Automated backups enable point-in-time recovery (PITR) for your DB instance down to a specific second within the retention period, which can be up to 35 days. By setting the retention period to 30 days, the company can restore the database to its state from up to 5 minutes before any change within the last 30 days."], "explain": "", "answers": [], "resources": ["https://aws.amazon.com/rds/features/backup/"]}, {"_id": 198, "question": "198 # A company\u2019s web application consists of an Amazon API Gateway API in front of an AWS Lambda function and an Amazon DynamoDB database. The Lambda function handles the business logic, and the DynamoDB table hosts the data. The application uses Amazon Cognito user pools to identify the individual users of the application. A solutions architect needs to update the application so that only users who have a subscription can access premium content. Which solution will meet this requirement with the LEAST operational overhead?", "options": [], "explain": "", "answers": [], "resources": []}, {"_id": 198, "question": "198 # A company\u2019s web application consists of an Amazon API Gateway API in front of an AWS Lambda function and an Amazon DynamoDB database. The Lambda function handles the business logic, and the DynamoDB table hosts the data. The application uses Amazon Cognito user pools to identify the individual users of the application. A solutions architect needs to update the application so that only users who have a subscription can access premium content. Which solution will meet this requirement with the LEAST operational overhead? A. Enable API caching and throttling on the API Gateway API. B. Set up AWS WAF on the API Gateway API. Create a rule to filter users who have a subscription. C. Apply fine-grained IAM permissions to the premium content in the DynamoDB table. https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248514975618&usg=AOvVaw0g1DM6NDBlys6mdi3n40r0 https://www.google.com/url?q=https://docs.aws.amazon.com/sns/latest/dg/sns-server-side-encryption.html&sa=D&source=apps-viewer-frontend&ust=1720248514975660&usg=AOvVaw2bx5T5Js8hT7VcJuF6qEsk https://docs.aws.amazon.com/sns/latest/dg/sns-server-side-encryption.html https://www.google.com/url?q=https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-server-side-encryption.html&sa=D&source=apps-viewer-frontend&ust=1720248514975673&usg=AOvVaw07SmjGcfo7cEhSqima2zJ- https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-server-side-encryption.html https://www.google.com/url?q=https://aws.amazon.com/rds/features/backup/&sa=D&source=apps-viewer-frontend&ust=1720248514975684&usg=AOvVaw3scYQp9DF84tbY89Io4X5w https://aws.amazon.com/rds/features/backup/ 96 D. Implement API usage plans and API keys to limit the access of users who do not have a subscription. Selected Answer: D", "options": ["A. Enable API caching and throttling on the API Gateway API.", "B. Set up AWS WAF on the API Gateway API. Create a rule to filter users who have a subscription.", "C. Apply fine-grained IAM permissions to the premium content in the DynamoDB table.", "https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248514975618&usg=AOvVaw0g1DM6NDBlys6mdi3n40r0 https://www.google.com/url?q=https://docs.aws.amazon.com/sns/latest/dg/sns-server-side-encryption.html&sa=D&source=apps-viewer-frontend&ust=1720248514975660&usg=AOvVaw2bx5T5Js8hT7VcJuF6qEsk https://docs.aws.amazon.com/sns/latest/dg/sns-server-side-encryption.html https://www.google.com/url?q=https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-server-side-encryption.html&sa=D&source=apps-viewer-frontend&ust=1720248514975673&usg=AOvVaw07SmjGcfo7cEhSqima2zJ- https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-server-side-encryption.html https://www.google.com/url?q=https://aws.amazon.com/rds/features/backup/&sa=D&source=apps-viewer-frontend&ust=1720248514975684&usg=AOvVaw3scYQp9DF84tbY89Io4X5w https://aws.amazon.com/rds/features/backup/ 96", "A. This would not actually limit access based on subscriptions. It helps optimize and control API usage, but does not address the core requirement.", "B. This could work by checking user subscription status in the WAF rule, but would require ongoing management of WAF and increases operational overhead.", "C. This is a good approach, using IAM permissions to control DynamoDB access at a granular level based on subscriptions. However, it would require managing IAM permissions which adds some operational overhead.", "D. This option uses API Gateway mechanisms to limit API access based on subscription status. It would require the least amount of ongoing management and changes, minimizing operational overhead. API keys could be easily revoked/changed as subscription status changes. Question #: 367"], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248514975618&usg=AOvVaw0g1DM6NDBlys6mdi3n40r0", "https://www.google.com/url?q=https://docs.aws.amazon.com/sns/latest/dg/sns-server-side-encryption.html&sa=D&source=apps-viewer-frontend&ust=1720248514975660&usg=AOvVaw2bx5T5Js8hT7VcJuF6qEsk", "https://docs.aws.amazon.com/sns/latest/dg/sns-server-side-encryption.html", "https://www.google.com/url?q=https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-server-side-encryption.html&sa=D&source=apps-viewer-frontend&ust=1720248514975673&usg=AOvVaw07SmjGcfo7cEhSqima2zJ-", "https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-server-side-encryption.html", "https://www.google.com/url?q=https://aws.amazon.com/rds/features/backup/&sa=D&source=apps-viewer-frontend&ust=1720248514975684&usg=AOvVaw3scYQp9DF84tbY89Io4X5w", "https://aws.amazon.com/rds/features/backup/"]}, {"_id": 199, "question": "199 # A company is using Amazon Route 53 latency-based routing to route requests to its UDP-based application for users around the world. The application is hosted on redundant servers in the company's on-premises data centers in the United States, Asia, and Europe. The company\u2019s compliance requirements state that the application must be hosted on premises. The company wants to improve the performance and availability of the application. What should a solutions architect do to meet these requirements?", "options": ["A. Configure three Network Load Balancers (NLBs) in the three AWS Regions to address the on-premises endpoints. Create an accelerator by using AWS Global Accelerator, and register the NLBs as its endpoints. Provide access to the application by using a CNAME that points to the accelerator DNS.", "B. Configure three Application Load Balancers (ALBs) in the three AWS Regions to address the on- premises endpoints. Create an accelerator by using AWS Global Accelerator, and register the ALBs as its endpoints. Provide access to the application by using a CNAME that points to the accelerator DNS.", "C. Configure three Network Load Balancers (NLBs) in the three AWS Regions to address the on-premises endpoints. In Route 53, create a latency-based record that points to the three NLBs, and use it as an origin for an Amazon CloudFront distribution. Provide access to the application by using a CNAME that points to the CloudFront DNS.", "D. Configure three Application Load Balancers (ALBs) in the three AWS Regions to address the on- premises endpoints. In Route 53, create a latency-based record that points to the three ALBs, and use it as an origin for an Amazon CloudFront distribution. Provide access to the application by using a CNAME that points to the CloudFront DNS. Selected Answer: A C - D: Cloudfront don't support UDP/TCP B: Global accelerator don't support ALB"], "explain": "", "answers": [], "resources": ["https://blog.cloudcraft.co/alb-vs-nlb-which-aws-load-balancer-fits-your-needs/"]}, {"_id": 200, "question": "200 # A solutions architect wants all new users to have specific complexity requirements and mandatory rotation periods for IAM user passwords. What should the solutions architect do to accomplish this?", "options": ["A. Set an overall password policy for the entire AWS account.", "B. Set a password policy for each IAM user in the AWS account.", "C. Use third-party vendor software to set password requirements.", "D. Attach an Amazon CloudWatch rule to the Create_newuser event to set the password with the appropriate requirements. Selected Answer: A To accomplish this, the solutions architect should set an overall password policy for the entire AWS account. This policy will apply to all IAM users in the account, including new users."], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248515925634&usg=AOvVaw1bRzXKyoZw_iA5RGUaU7NO", "https://www.google.com/url?q=https://blog.cloudcraft.co/alb-vs-nlb-which-aws-load-balancer-fits-your-needs/&sa=D&source=apps-viewer-frontend&ust=1720248515925691&usg=AOvVaw0N5wtXTAsZZdUWiphs5slX", "https://blog.cloudcraft.co/alb-vs-nlb-which-aws-load-balancer-fits-your-needs/"]}, {"_id": 201, "question": "201 # A company has migrated an application to Amazon EC2 Linux instances. One of these EC2 instances runs several 1-hour tasks on a schedule. These tasks were written by different teams and have no common programming language. The company is concerned about performance and scalability while these tasks run on a single instance. A solutions architect needs to implement a solution to resolve these concerns. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Use AWS Batch to run the tasks as jobs. Schedule the jobs by using Amazon EventBridge (Amazon CloudWatch Events).", "B. Convert the EC2 instance to a container. Use AWS App Runner to create the container on demand to run the tasks as jobs.", "C. Copy the tasks into AWS Lambda functions. Schedule the Lambda functions by using Amazon EventBridge (Amazon CloudWatch Events).", "D. Create an Amazon Machine Image (AMI) of the EC2 instance that runs the tasks. Create an Auto Scaling group with the AMI to run multiple copies of the instance. Selected Answer: A B and D out! A and C let's think! AWS Lambda functions are time limited. Question #: 370"], "explain": "", "answers": [], "resources": []}, {"_id": 202, "question": "202 # A company runs a public three-tier web application in a VPC. The application runs on Amazon EC2 instances across multiple Availability Zones. The EC2 instances that run in private subnets need to communicate with a license server over the internet. The company needs a managed solution that minimizes operational maintenance. Which solution meets these requirements?", "options": ["A. Provision a NAT instance in a public subnet. Modify each private subnet's route table with a default route that points to the NAT instance.", "B. Provision a NAT instance in a private subnet. Modify each private subnet's route table with a default route that points to the NAT instance.", "C. Provision a NAT gateway in a public subnet. Modify each private subnet's route table with a default route that points to the NAT gateway.", "D. Provision a NAT gateway in a private subnet. Modify each private subnet's route table with a default route that points to the NAT gateway. Selected Answer: C \"The company needs a managed solution that minimizes operational maintenance\" Watch out for NAT instances vs NAT Gateways. As the company needs a managed solution that minimizes operational maintenance - NAT Gateway is a public subnet is the answer. Question #: 371"], "explain": "", "answers": [], "resources": []}, {"_id": 203, "question": "203 # A company needs to create an Amazon Elastic Kubernetes Service (Amazon EKS) cluster to host a digital media streaming application. The EKS cluster will use a managed node group that is backed by Amazon Elastic Block Store (Amazon EBS) volumes for storage. The company must encrypt all data at rest by using a customer managed key that is stored in AWS Key Management Service (AWS KMS). Which combination of actions will meet this requirement with the LEAST operational overhead? (Choose two.)", "options": [], "explain": "", "answers": [], "resources": []}, {"_id": 203, "question": "203 # A company needs to create an Amazon Elastic Kubernetes Service (Amazon EKS) cluster to host a digital media streaming application. The EKS cluster will use a managed node group that is backed by Amazon Elastic Block Store (Amazon EBS) volumes for storage. The company must encrypt all data at rest by using a customer managed key that is stored in AWS Key Management Service (AWS KMS). Which combination of actions will meet this requirement with the LEAST operational overhead? (Choose two.) A. Use a Kubernetes plugin that uses the customer managed key to perform data encryption. B. After creation of the EKS cluster, locate the EBS volumes. Enable encryption by using the customer managed key. C. Enable EBS encryption by default in the AWS Region where the EKS cluster will be created. Select the customer managed key as the default key. https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248516517031&usg=AOvVaw2qGZWr5mcILTJvrxKt1n5n 98 D. Create the EKS cluster. Create an IAM role that has a policy that grants permission to the customer managed key. Associate the role with the EKS cluster. E. Store the customer managed key as a Kubernetes secret in the EKS cluster. Use the customer managed key to encrypt the EBS volumes. Selected Answer: CD C - enable EBS encryption by default in a region - https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html D - Provides key access permission just to the EKS cluster without changing broader IAM permissions", "options": ["A. Use a Kubernetes plugin that uses the customer managed key to perform data encryption.", "B. After creation of the EKS cluster, locate the EBS volumes. Enable encryption by using the customer managed key.", "C. Enable EBS encryption by default in the AWS Region where the EKS cluster will be created. Select the customer managed key as the default key.", "https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248516517031&usg=AOvVaw2qGZWr5mcILTJvrxKt1n5n 98", "D. Create the EKS cluster. Create an IAM role that has a policy that grants permission to the customer managed key. Associate the role with the EKS cluster.", "A. Using a custom plugin requires installing, managing and troubleshooting the plugin. Significant operational overhead.", "E. Managing Kubernetes secrets for key access requires operations within the EKS cluster. Additional operational complexity. Question #: 372"], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248516517031&usg=AOvVaw2qGZWr5mcILTJvrxKt1n5n", "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html"]}, {"_id": 204, "question": "204 # A company wants to migrate an Oracle database to AWS. The database consists of a single table that contains millions of geographic information systems (GIS) images that are high resolution and are identified by a geographic code. When a natural disaster occurs, tens of thousands of images get updated every few minutes. Each geographic code has a single image or row that is associated with it. The company wants a solution that is highly available and scalable during such events. Which solution meets these requirements MOST cost-effectively?", "options": ["A. Store the images and geographic codes in a database table. Use Oracle running on an Amazon RDS Multi-AZ DB instance.", "B. Store the images in Amazon S3 buckets. Use Amazon DynamoDB with the geographic code as the key and the image S3 URL as the value.", "C. Store the images and geographic codes in an Amazon DynamoDB table. Configure DynamoDB Accelerator (DAX) during times of high load.", "D. Store the images in Amazon S3 buckets. Store geographic codes and image S3 URLs in a database table. Use Oracle running on an Amazon RDS Multi-AZ DB instance. Selected Answer: B This uses: - S3 for inexpensive, scalable image storage - DynamoDB as an index, which can scale seamlessly and cost-effectively - No expensive database storage/compute required Question #: 373"], "explain": "", "answers": [], "resources": []}, {"_id": 205, "question": "205 # A company has an application that collects data from IoT sensors on automobiles. The data is streamed and stored in Amazon S3 through Amazon Kinesis Data Firehose. The data produces trillions of S3 objects each year. Each morning, the company uses the data from the previous 30 days to retrain a suite of machine learning (ML) models. Four times each year, the company uses the data from the previous 12 months to perform analysis and train other ML models. The data must be available with minimal delay for up to 1 year. After 1 year, the data must be retained for archival purposes. Which storage solution meets these requirements MOST cost-effectively?", "options": ["A. Use the S3 Intelligent-Tiering storage class. Create an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive after 1 year.", "B. Use the S3 Intelligent-Tiering storage class. Configure S3 Intelligent-Tiering to automatically move objects to S3 Glacier Deep Archive after 1 year.", "C. Use the S3 Standard-Infrequent Access (S3 Standard-IA) storage class. Create an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive after 1 year.", "D. Use the S3 Standard storage class. Create an S3 Lifecycle policy to transition objects to S3 Standard- Infrequent Access (S3 Standard-IA) after 30 days, and then to S3 Glacier Deep Archive after 1 year."], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248517061422&usg=AOvVaw2qZetw7G8NudPbbcsXUFTZ", "https://www.google.com/url?q=https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html&sa=D&source=apps-viewer-frontend&ust=1720248517061470&usg=AOvVaw0cmKgQckRMA8oZTSgvVYTH", "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html"]}, {"_id": 206, "question": "206 # A company is running several business applications in three separate VPCs within the us-east-1 Region. The applications must be able to communicate between VPCs. The applications also must be able to consistently send hundreds of gigabytes of data each day to a latency-sensitive application that runs in a single on-premises data center. A solutions architect needs to design a network connectivity solution that maximizes cost-effectiveness. Which solution meets these requirements?", "options": ["A. Configure three AWS Site-to-Site VPN connections from the data center to AWS. Establish connectivity by configuring one VPN connection for each VPC.", "B. Launch a third-party virtual network appliance in each VPC. Establish an IPsec VPN tunnel between the data center and each virtual appliance.", "C. Set up three AWS Direct Connect connections from the data center to a Direct Connect gateway in us- east-1. Establish connectivity by configuring each VPC to use one of the Direct Connect connections.", "D. Set up one AWS Direct Connect connection from the data center to AWS. Create a transit gateway, and attach each VPC to the transit gateway. Establish connectivity between the Direct Connect connection and the transit gateway. Selected Answer: D Transit GW, is a hub for connecting all VPCs. Direct Connect is expensive, therefor only 1 of them connected to the Transit GW (Hub for all our VPCs that we connect to it) Question #: 375"], "explain": "", "answers": [], "resources": []}, {"_id": 207, "question": "207 # An ecommerce company is building a distributed application that involves several serverless functions and AWS services to complete order-processing tasks. These tasks require manual approvals as part of the workflow. A solutions architect needs to design an architecture for the order-processing application. The solution must be able to combine multiple AWS Lambda functions into responsive serverless applications. The solution also must orchestrate data and services that run on Amazon EC2 instances, containers, or on-premises servers. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Use AWS Step Functions to build the application.", "B. Integrate all the application components in an AWS Glue job.", "C. Use Amazon Simple Queue Service (Amazon SQS) to build the application.", "D. Use AWS Lambda functions and Amazon EventBridge events to build the application. Selected Answer: A Option A: Use AWS Step Functions to build the application. AWS Step Functions is a serverless workflow service that makes it easy to coordinate distributed applications and microservices using visual workflows. It is an ideal solution for designing architectures for distributed applications that involve multiple AWS services and serverless functions, as it allows us to orchestrate the flow of our application components using visual workflows. AWS Step Functions also integrates with other AWS services like AWS Lambda, Amazon EC2, and Amazon ECS, and it has built-in error handling and retry mechanisms. This option provides a serverless solution with the least operational overhead for building the application. Question #: 376"], "explain": "", "answers": [], "resources": []}, {"_id": 208, "question": "208 # A company has launched an Amazon RDS for MySQL DB instance. Most of the connections to the database come from serverless applications. Application traffic to the database changes significantly at https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248517600518&usg=AOvVaw1RYh9Z6WEdIMS64_qlgWMs 100 random intervals. At times of high demand, users report that their applications experience database connection rejection errors. Which solution will resolve this issue with the LEAST operational overhead?", "options": ["A. Create a proxy in RDS Proxy. Configure the users\u2019 applications to use the DB instance through RDS Proxy.", "B. Deploy Amazon ElastiCache for Memcached between the users\u2019 applications and the DB instance.", "C. Migrate the DB instance to a different instance class that has higher I/O capacity. Configure the users\u2019 applications to use the new DB instance.", "D. Configure Multi-AZ for the DB instance. Configure the users\u2019 applications to switch between the DB instances. Selected Answer: A Many applications, including those built on modern serverless architectures, can have a large number of open connections to the database server and may open and close database connections at a high rate, exhausting database memory and compute resources. Amazon RDS Proxy allows applications to pool and share connections established with the database, improving database efficiency and application scalability. (https://aws.amazon.com/pt/rds/proxy/) Question #: 377"], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248517600518&usg=AOvVaw1RYh9Z6WEdIMS64_qlgWMs"]}, {"_id": 209, "question": "209 # A company recently deployed a new auditing system to centralize information about operating system versions, patching, and installed software for Amazon EC2 instances. A solutions architect must ensure all instances provisioned through EC2 Auto Scaling groups successfully send reports to the auditing system as soon as they are launched and terminated. Which solution achieves these goals MOST efficiently?", "options": ["A. Use a scheduled AWS Lambda function and run a script remotely on all EC2 instances to send data to the audit system.", "B. Use EC2 Auto Scaling lifecycle hooks to run a custom script to send data to the audit system when instances are launched and terminated.", "C. Use an EC2 Auto Scaling launch configuration to run a custom script through user data to send data to the audit system when instances are launched and terminated.", "D. Run a custom script on the instance operating system to send data to the audit system. Configure the script to be invoked by the EC2 Auto Scaling group when the instance starts and is terminated. Selected Answer: B Amazon EC2 Auto Scaling offers the ability to add lifecycle hooks to your Auto Scaling groups. These hooks let you create solutions that are aware of events in the Auto Scaling instance lifecycle, and then perform a custom action on instances when the corresponding lifecycle event occurs. (https://docs.aws.amazon.com/autoscaling/ec2/userguide/lifecycle-hooks.html) Question #: 378"], "explain": "", "answers": [], "resources": []}, {"_id": 210, "question": "210 # A company is developing a real-time multiplayer game that uses UDP for communications between the client and servers in an Auto Scaling group. Spikes in demand are anticipated during the day, so the game server platform must adapt accordingly. Developers want to store gamer scores and other non-relational data in a database solution that will scale without intervention. Which solution should a solutions architect recommend?", "options": ["A. Use Amazon Route 53 for traffic distribution and Amazon Aurora Serverless for data storage.", "B. Use a Network Load Balancer for traffic distribution and Amazon DynamoDB on-demand for data storage.", "C. Use a Network Load Balancer for traffic distribution and Amazon Aurora Global Database for data storage.", "https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248518203177&usg=AOvVaw31eAyOAKk9wxKcyD0yjHLN https://www.google.com/url?q=https://aws.amazon.com/pt/rds/proxy/&sa=D&source=apps-viewer-frontend&ust=1720248518203212&usg=AOvVaw2A8wrQEQ3fb41asYrzBC4Z https://aws.amazon.com/pt/rds/proxy/ https://www.google.com/url?q=https://docs.aws.amazon.com/autoscaling/ec2/userguide/lifecycle-hooks.html&sa=D&source=apps-viewer-frontend&ust=1720248518203224&usg=AOvVaw3gOiC3bTqBtIyiyTK0OlEg https://docs.aws.amazon.com/autoscaling/ec2/userguide/lifecycle-hooks.html 101"], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248518203177&usg=AOvVaw31eAyOAKk9wxKcyD0yjHLN", "https://www.google.com/url?q=https://aws.amazon.com/pt/rds/proxy/&sa=D&source=apps-viewer-frontend&ust=1720248518203212&usg=AOvVaw2A8wrQEQ3fb41asYrzBC4Z", "https://aws.amazon.com/pt/rds/proxy/", "https://www.google.com/url?q=https://docs.aws.amazon.com/autoscaling/ec2/userguide/lifecycle-hooks.html&sa=D&source=apps-viewer-frontend&ust=1720248518203224&usg=AOvVaw3gOiC3bTqBtIyiyTK0OlEg", "https://docs.aws.amazon.com/autoscaling/ec2/userguide/lifecycle-hooks.html"]}, {"_id": 211, "question": "211 # A company hosts a frontend application that uses an Amazon API Gateway API backend that is integrated with AWS Lambda. When the API receives requests, the Lambda function loads many libraries. Then the Lambda function connects to an Amazon RDS database, processes the data, and returns the data to the frontend application. The company wants to ensure that response latency is as low as possible for all its users with the fewest number of changes to the company's operations. Which solution will meet these requirements?", "options": ["A. Establish a connection between the frontend application and the database to make queries faster by bypassing the API.", "B. Configure provisioned concurrency for the Lambda function that handles the requests.", "C. Cache the results of the queries in Amazon S3 for faster retrieval of similar datasets.", "D. Increase the size of the database to increase the number of connections Lambda can establish at one time. Selected Answer: B Key: the Lambda function loads many libraries Configuring provisioned concurrency would get rid of the \"cold start\" of the function therefore speeding up the proccess."], "explain": "", "answers": [], "resources": ["https://docs.aws.amazon.com/lambda/latest/dg/provisioned-concurrency.html"]}, {"_id": 212, "question": "212 # A company is migrating its on-premises workload to the AWS Cloud. The company already uses several Amazon EC2 instances and Amazon RDS DB instances. The company wants a solution that automatically starts and stops the EC2 instances and DB instances outside of business hours. The solution must minimize cost and infrastructure maintenance. Which solution will meet these requirements?", "options": ["A. Scale the EC2 instances by using elastic resize. Scale the DB instances to zero outside of business hours.", "B. Explore AWS Marketplace for partner solutions that will automatically start and stop the EC2 instances and DB instances on a schedule.", "C. Launch another EC2 instance. Configure a crontab schedule to run shell scripts that will start and stop the existing EC2 instances and DB instances on a schedule.", "D. Create an AWS Lambda function that will start and stop the EC2 instances and DB instances. Configure Amazon EventBridge to invoke the Lambda function on a schedule. Selected Answer: D"], "explain": "", "answers": [], "resources": ["https://docs.aws.amazon.com/redshift/latest/mgmt/managing-cluster-operations.html", "https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248518720242&usg=AOvVaw0_GPV6DZkXejX3xbNae41h", "https://www.google.com/url?q=https://docs.aws.amazon.com/lambda/latest/dg/provisioned-concurrency.html&sa=D&source=apps-viewer-frontend&ust=1720248518720296&usg=AOvVaw0qgRSqLyXiKKxvNKY6LCg_", "https://docs.aws.amazon.com/lambda/latest/dg/provisioned-concurrency.html", "https://www.google.com/url?q=https://docs.aws.amazon.com/redshift/latest/mgmt/managing-cluster-operations.html&sa=D&source=apps-viewer-frontend&ust=1720248518720309&usg=AOvVaw1xyWGclPgx9g4sxp3YG9hs", "https://docs.aws.amazon.com/redshift/latest/mgmt/managing-cluster-operations.html"]}, {"_id": 213, "question": "213 # A company hosts a three-tier web application that includes a PostgreSQL database. The database stores the metadata from documents. The company searches the metadata for key terms to retrieve documents that the company reviews in a report each month. The documents are stored in Amazon S3. The documents are usually written only once, but they are updated frequently. The reporting process takes a few hours with the use of relational queries. The reporting process must not prevent any document modifications or the addition of new documents. A solutions architect needs to implement a solution to speed up the reporting process. Which solution will meet these requirements with the LEAST amount of change to the application code?", "options": ["A. Set up a new Amazon DocumentDB (with MongoDB compatibility) cluster that includes a read replica. Scale the read replica to generate the reports.", "B. Set up a new Amazon Aurora PostgreSQL DB cluster that includes an Aurora Replica. Issue queries to the Aurora Replica to generate the reports.", "C. Set up a new Amazon RDS for PostgreSQL Multi-AZ DB instance. Configure the reporting module to query the secondary RDS node so that the reporting module does not affect the primary node.", "D. Set up a new Amazon DynamoDB table to store the documents. Use a fixed write capacity to support new document entries. Automatically scale the read capacity to support the reports. Selected Answer: B The reporting process queries the metadata (not the documents) and use relational queries-> A, D out C: wrong since secondary RDS node in MultiAZ setup is in standby mode, not available for querying B: reporting using a Replica is a design pattern. Using Aurora is an exam pattern. \"LEAST amount of change to the application code\" Aurora is a relational database, it supports PostgreSQL and with the help of read replicas we can issue the reporting proccess that take several hours to the replica, therefore not affecting the primary node which can handle new writes or document modifications. Question #: 382"], "explain": "", "answers": [], "resources": []}, {"_id": 214, "question": "214 # A company has a three-tier application on AWS that ingests sensor data from its users\u2019 devices. The traffic flows through a Network Load Balancer (NLB), then to Amazon EC2 instances for the web tier, and finally to EC2 instances for the application tier. The application tier makes calls to a database. What should a solutions architect do to improve the security of the data in transit?", "options": ["A. Configure a TLS listener. Deploy the server certificate on the NLB.", "B. Configure AWS Shield Advanced. Enable AWS WAF on the NLB.", "C. Change the load balancer to an Application Load Balancer (ALB). Enable AWS WAF on the ALB.", "D. Encrypt the Amazon Elastic Block Store (Amazon EBS) volume on the EC2 instances by using AWS Key Management Service (AWS KMS). Selected Answer: A To improve the security of data in transit, you can configure a TLS listener on the Network Load Balancer (NLB) and deploy the server certificate on it. This will encrypt traffic between clients and the NLB. You can also use AWS Certificate Manager (ACM) to provision, manage, and deploy SSL/TLS certificates for use with AWS services and your internal connected resources1. You can also change the load balancer to an Application Load Balancer (ALB) and enable AWS WAF on it. AWS WAF is a web application firewall that helps protect your web applications from common web exploits that could affect application"], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248519415663&usg=AOvVaw0y6g0NrjYSECh-Uy-TVMQ0", "https://docs.aws.amazon.com/elasticloadbalancing/latest/network/create-tls-listener.html", "https://exampleloadbalancer.com/nlbtls_demo.html"]}, {"_id": 215, "question": "215 # A company is planning to migrate a commercial off-the-shelf application from its on-premises data center to AWS. The software has a software licensing model using sockets and cores with predictable capacity and uptime requirements. The company wants to use its existing licenses, which were purchased earlier this year. Which Amazon EC2 pricing option is the MOST cost-effective?", "options": ["A. Dedicated Reserved Hosts", "B. Dedicated On-Demand Hosts", "C. Dedicated Reserved Instances", "D. Dedicated On-Demand Instances Selected Answer: A Bring custom purchased licenses to AWS -> Dedicated Host -> C,D out Need cost effective solution -> \"reserved\" -> A Dedicated Host Reservations provide a billing discount compared to running On-Demand Dedicated Hosts. Reservations are available in three payment options."], "explain": "", "answers": [], "resources": ["https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/dedicated-hosts-overview.html"]}, {"_id": 216, "question": "216 # A company runs an application on Amazon EC2 Linux instances across multiple Availability Zones. The application needs a storage layer that is highly available and Portable Operating System Interface (POSIX)-compliant. The storage layer must provide maximum data durability and must be shareable across the EC2 instances. The data in the storage layer will be accessed frequently for the first 30 days and will be accessed infrequently after that time. Which solution will meet these requirements MOST cost-effectively?", "options": ["A. Use the Amazon S3 Standard storage class. Create an S3 Lifecycle policy to move infrequently accessed data to S3 Glacier.", "B. Use the Amazon S3 Standard storage class. Create an S3 Lifecycle policy to move infrequently accessed data to S3 Standard-Infrequent Access (S3 Standard-IA).", "C. Use the Amazon Elastic File System (Amazon EFS) Standard storage class. Create a lifecycle management policy to move infrequently accessed data to EFS Standard-Infrequent Access (EFS Standard-IA).", "D. Use the Amazon Elastic File System (Amazon EFS) One Zone storage class. Create a lifecycle management policy to move infrequently accessed data to EFS One Zone-Infrequent Access (EFS One Zone-IA). Selected Answer: C Option A, using S3, is not a good option as it is an object storage service and not POSIX-compliant. Option B, using S3 Standard-IA, is also not a good option as it is an object storage service and not POSIX- compliant. Option D, using EFS One Zone, is not the best option for high availability since it is only stored in a single AZ. Answer c :"], "explain": "", "answers": [], "resources": ["https://aws.amazon.com/efs/features/infrequent-access/", "https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248520204178&usg=AOvVaw0zFfPhXosWEDpCt-o5Ojpc", "https://www.google.com/url?q=https://docs.aws.amazon.com/elasticloadbalancing/latest/network/create-tls-listener.html&sa=D&source=apps-viewer-frontend&ust=1720248520204234&usg=AOvVaw3gtwAge5wYsK5VyuhSunPl", "https://docs.aws.amazon.com/elasticloadbalancing/latest/network/create-tls-listener.html", "https://www.google.com/url?q=https://exampleloadbalancer.com/nlbtls_demo.html&sa=D&source=apps-viewer-frontend&ust=1720248520204249&usg=AOvVaw2l3_vY26B4sIztCjy4gOob", "https://exampleloadbalancer.com/nlbtls_demo.html", "https://www.google.com/url?q=https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/dedicated-hosts-overview.html&sa=D&source=apps-viewer-frontend&ust=1720248520204261&usg=AOvVaw0Ig59Ip9hOB70PtwA1kIiY", "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/dedicated-hosts-overview.html", "https://www.google.com/url?q=https://aws.amazon.com/efs/features/infrequent-access/&sa=D&source=apps-viewer-frontend&ust=1720248520204274&usg=AOvVaw24On5hoI-eVodLM0pERpim", "https://aws.amazon.com/efs/features/infrequent-access/"]}, {"_id": 217, "question": "217 # A solutions architect is creating a new VPC design. There are two public subnets for the load balancer, two private subnets for web servers, and two private subnets for MySQL. The web servers use only HTTPS. The solutions architect has already created a security group for the load balancer allowing port 443 from 0.0.0.0/0. Company policy requires that each resource has the least access required to still be able to perform its tasks. Which additional configuration strategy should the solutions architect use to meet these requirements?", "options": ["A. Create a security group for the web servers and allow port 443 from 0.0.0.0/0. Create a security group for the MySQL servers and allow port 3306 from the web servers security group.", "B. Create a network ACL for the web servers and allow port 443 from 0.0.0.0/0. Create a network ACL for the MySQL servers and allow port 3306 from the web servers security group.", "C. Create a security group for the web servers and allow port 443 from the load balancer. Create a security group for the MySQL servers and allow port 3306 from the web servers security group.", "D. Create a network ACL for the web servers and allow port 443 from the load balancer. Create a network ACL for the MySQL servers and allow port 3306 from the web servers security group. Selected Answer: C Load balancer is public facing accepting all traffic coming towards the VPC (0.0.0.0/0). The web server needs to trust traffic originating from the ALB. The DB will only trust traffic originating from the Web server on port 3306 for Mysql Question #: 386"], "explain": "", "answers": [], "resources": []}, {"_id": 218, "question": "218 # An ecommerce company is running a multi-tier application on AWS. The front-end and backend tiers both run on Amazon EC2, and the database runs on Amazon RDS for MySQL. The backend tier communicates with the RDS instance. There are frequent calls to return identical datasets from the database that are causing performance slowdowns. Which action should be taken to improve the performance of the backend?", "options": ["A. Implement Amazon SNS to store the database calls.", "B. Implement Amazon ElastiCache to cache the large datasets.", "C. Implement an RDS for MySQL read replica to cache database calls.", "D. Implement Amazon Kinesis Data Firehose to stream the calls to the database. Selected Answer: B the best solution is to implement Amazon ElastiCache to cache the large datasets, which will store the frequently accessed data in memory, allowing for faster retrieval times. This can help to alleviate the frequent calls to the database, reduce latency, and improve the overall performance of the backend tier. frequent identical calls = ElastiCache Question #: 387"], "explain": "", "answers": [], "resources": []}, {"_id": 219, "question": "219 # A new employee has joined a company as a deployment engineer. The deployment engineer will be using AWS CloudFormation templates to create multiple AWS resources. A solutions architect wants the deployment engineer to perform job activities while following the principle of least privilege. Which combination of actions should the solutions architect take to accomplish this goal? (Choose two.)", "options": ["A. Have the deployment engineer use AWS account root user credentials for performing AWS CloudFormation stack operations.", "B. Create a new IAM user for the deployment engineer and add the IAM user to a group that has the PowerUsers IAM policy attached.", "C. Create a new IAM user for the deployment engineer and add the IAM user to a group that has the AdministratorAccess IAM policy attached.", "D. Create a new IAM user for the deployment engineer and add the IAM user to a group that has an IAM policy that allows AWS CloudFormation actions only.", "https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248520909320&usg=AOvVaw1VF_MmgYLUPF3LQ-4f13MN 105"], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248520909320&usg=AOvVaw1VF_MmgYLUPF3LQ-4f13MN"]}, {"_id": 220, "question": "220 # A company is deploying a two-tier web application in a VPC. The web tier is using an Amazon EC2 Auto Scaling group with public subnets that span multiple Availability Zones. The database tier consists of an Amazon RDS for MySQL DB instance in separate private subnets. The web tier requires access to the database to retrieve product information. The web application is not working as intended. The web application reports that it cannot connect to the database. The database is confirmed to be up and running. All configurations for the network ACLs, security groups, and route tables are still in their default states. What should a solutions architect recommend to fix the application?", "options": ["A. Add an explicit rule to the private subnet\u2019s network ACL to allow traffic from the web tier\u2019s EC2 instances.", "B. Add a route in the VPC route table to allow traffic between the web tier\u2019s EC2 instances and the database tier.", "C. Deploy the web tier's EC2 instances and the database tier\u2019s RDS instance into two separate VPCs, and configure VPC peering.", "D. Add an inbound rule to the security group of the database tier\u2019s RDS instance to allow traffic from the web tiers security group. Selected Answer: D Security group defaults block all inbound traffic..Add an inbound rule to the security group of the database tier\u2019s RDS instance to allow traffic from the web tiers security group Question #: 389"], "explain": "", "answers": [], "resources": []}, {"_id": 221, "question": "221 # A company has a large dataset for its online advertising business stored in an Amazon RDS for MySQL DB instance in a single Availability Zone. The company wants business reporting queries to run without impacting the write operations to the production DB instance. Which solution meets these requirements?", "options": ["A. Deploy RDS read replicas to process the business reporting queries.", "B. Scale out the DB instance horizontally by placing it behind an Elastic Load Balancer.", "C. Scale up the DB instance to a larger instance type to handle write operations and queries.", "D. Deploy the DB instance in multiple Availability Zones to process the business reporting queries. Selected Answer: A Option \"A\" is the right answer . Read replica use cases - You have a production database that is taking on normal load & You want to run a reporting application to run some analytics You create a Read Replica to run the new workload there The production application is unaffected Read replicas are used for SELECT (=read) only kind of statements (not INSERT, UPDATE, DELETE)"], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248521532400&usg=AOvVaw233wzt_DLTYIli5A2wf8Wf"]}, {"_id": 222, "question": "222 # A company hosts a three-tier ecommerce application on a fleet of Amazon EC2 instances. The instances run in an Auto Scaling group behind an Application Load Balancer (ALB). All ecommerce data is stored in an Amazon RDS for MariaDB Multi-AZ DB instance. The company wants to optimize customer session management during transactions. The application must store session data durably. Which solutions will meet these requirements? (Choose two.)", "options": ["A. Turn on the sticky sessions feature (session affinity) on the ALB.", "B. Use an Amazon DynamoDB table to store customer session information.", "C. Deploy an Amazon Cognito user pool to manage user session information.", "D. Deploy an Amazon ElastiCache for Redis cluster to store customer session information.", "E. Use AWS Systems Manager Application Manager in the application to manage user session information. Selected Answer: AD It is A and", "D. Proof is in link below."], "explain": "", "answers": [], "resources": ["https://aws.amazon.com/caching/session-management/"]}, {"_id": 223, "question": "223 # A company needs a backup strategy for its three-tier stateless web application. The web application runs on Amazon EC2 instances in an Auto Scaling group with a dynamic scaling policy that is configured to respond to scaling events. The database tier runs on Amazon RDS for PostgreSQL. The web application does not require temporary local storage on the EC2 instances. The company\u2019s recovery point objective (RPO) is 2 hours. The backup strategy must maximize scalability and optimize resource utilization for this environment. Which solution will meet these requirements?", "options": ["A. Take snapshots of Amazon Elastic Block Store (Amazon EBS) volumes of the EC2 instances and database every 2 hours to meet the RPO.", "B. Configure a snapshot lifecycle policy to take Amazon Elastic Block Store (Amazon EBS) snapshots. Enable automated backups in Amazon RDS to meet the RPO.", "C. Retain the latest Amazon Machine Images (AMIs) of the web and application tiers. Enable automated backups in Amazon RDS and use point-in-time recovery to meet the RPO.", "D. Take snapshots of Amazon Elastic Block Store (Amazon EBS) volumes of the EC2 instances every 2 hours. Enable automated backups in Amazon RDS and use point-in-time recovery to meet the RPO. Selected Answer: C Since the application has no local data on instances, AMIs alone can meet the RPO by restoring instances from the most recent AMI backup. When combined with automated RDS backups for the database, this provides a complete backup solution for this environment. The other options involving EBS snapshots would be unnecessary given the stateless nature of the instances. AMIs provide all the backup needed for the app tier. This uses native, automated AWS backup features that require minimal ongoing management: - AMI automated backups provide point-in-time recovery for the stateless app tier. - RDS automated backups provide point-in-time recovery for the database."], "explain": "", "answers": [], "resources": ["https://repost.aws/knowledge-center/instance-store-vs-ebs"]}, {"_id": 224, "question": "224 # A company wants to deploy a new public web application on AWS. The application includes a web server tier that uses Amazon EC2 instances. The application also includes a database tier that uses an Amazon RDS for MySQL DB instance. The application must be secure and accessible for global customers that have dynamic IP addresses. How should a solutions architect configure the security groups to meet these requirements? https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248522278187&usg=AOvVaw0V8x7MaOwLM-ojufutc8OY https://www.google.com/url?q=https://aws.amazon.com/caching/session-management/&sa=D&source=apps-viewer-frontend&ust=1720248522278234&usg=AOvVaw0xzWwBXFpmYXLMtLmWKyIL https://aws.amazon.com/caching/session-management/ https://www.google.com/url?q=https://repost.aws/knowledge-center/instance-store-vs-ebs&sa=D&source=apps-viewer-frontend&ust=1720248522278259&usg=AOvVaw0X_qs-N8hVwQpvCj8tZz56 https://repost.aws/knowledge-center/instance-store-vs-ebs 107", "options": [], "explain": "", "answers": [], "resources": []}, {"_id": 224, "question": "224 # A company wants to deploy a new public web application on AWS. The application includes a web server tier that uses Amazon EC2 instances. The application also includes a database tier that uses an Amazon RDS for MySQL DB instance. The application must be secure and accessible for global customers that have dynamic IP addresses. How should a solutions architect configure the security groups to meet these requirements? https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248522278187&usg=AOvVaw0V8x7MaOwLM-ojufutc8OY https://www.google.com/url?q=https://aws.amazon.com/caching/session-management/&sa=D&source=apps-viewer-frontend&ust=1720248522278234&usg=AOvVaw0xzWwBXFpmYXLMtLmWKyIL https://aws.amazon.com/caching/session-management/ https://www.google.com/url?q=https://repost.aws/knowledge-center/instance-store-vs-ebs&sa=D&source=apps-viewer-frontend&ust=1720248522278259&usg=AOvVaw0X_qs-N8hVwQpvCj8tZz56 https://repost.aws/knowledge-center/instance-store-vs-ebs 107 A. Configure the security group for the web servers to allow inbound traffic on port 443 from 0.0.0.0/0. Configure the security group for the DB instance to allow inbound traffic on port 3306 from the security group of the web servers. B. Configure the security group for the web servers to allow inbound traffic on port 443 from the IP addresses of the customers. Configure the security group for the DB instance to allow inbound traffic on port 3306 from the security group of the web servers. C. Configure the security group for the web servers to allow inbound traffic on port 443 from the IP addresses of the customers. Configure the security group for the DB instance to allow inbound traffic on port 3306 from the IP addresses of the customers. D. Configure the security group for the web servers to allow inbound traffic on port 443 from 0.0.0.0/0. Configure the security group for the DB instance to allow inbound traffic on port 3306 from 0.0.0.0/0. Correct answer is", "options": ["A. Configure the security group for the web servers to allow inbound traffic on port 443 from 0.0.0.0/0. Configure the security group for the DB instance to allow inbound traffic on port 3306 from the security group of the web servers.", "B. Configure the security group for the web servers to allow inbound traffic on port 443 from the IP addresses of the customers. Configure the security group for the DB instance to allow inbound traffic on port 3306 from the security group of the web servers.", "C. Configure the security group for the web servers to allow inbound traffic on port 443 from the IP addresses of the customers. Configure the security group for the DB instance to allow inbound traffic on port 3306 from the IP addresses of the customers.", "A. B and C are out. D is out because it is accepting traffic from everywhere instead of from webservers only Question #: 393"], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248522278187&usg=AOvVaw0V8x7MaOwLM-ojufutc8OY", "https://www.google.com/url?q=https://aws.amazon.com/caching/session-management/&sa=D&source=apps-viewer-frontend&ust=1720248522278234&usg=AOvVaw0xzWwBXFpmYXLMtLmWKyIL", "https://aws.amazon.com/caching/session-management/", "https://www.google.com/url?q=https://repost.aws/knowledge-center/instance-store-vs-ebs&sa=D&source=apps-viewer-frontend&ust=1720248522278259&usg=AOvVaw0X_qs-N8hVwQpvCj8tZz56", "https://repost.aws/knowledge-center/instance-store-vs-ebs"]}, {"_id": 225, "question": "225 # A payment processing company records all voice communication with its customers and stores the audio files in an Amazon S3 bucket. The company needs to capture the text from the audio files. The company must remove from the text any personally identifiable information (PII) that belongs to customers. What should a solutions architect do to meet these requirements?", "options": ["A. Process the audio files by using Amazon Kinesis Video Streams. Use an AWS Lambda function to scan for known PII patterns.", "B. When an audio file is uploaded to the S3 bucket, invoke an AWS Lambda function to start an Amazon Textract task to analyze the call recordings.", "C. Configure an Amazon Transcribe transcription job with PII redaction turned on. When an audio file is uploaded to the S3 bucket, invoke an AWS Lambda function to start the transcription job. Store the output in a separate S3 bucket.", "D. Create an Amazon Connect contact flow that ingests the audio files with transcription turned on. Embed an AWS Lambda function to scan for known PII patterns. Use Amazon EventBridge to start the contact flow when an audio file is uploaded to the S3 bucket. Selected Answer: C Option C is the most suitable solution as it suggests using Amazon Transcribe with PII redaction turned on. When an audio file is uploaded to the S3 bucket, an AWS Lambda function can be used to start the transcription job. The output can be stored in a separate S3 bucket to ensure that the PII redaction is applied to the transcript. Amazon Transcribe can redact PII such as credit card numbers, social security numbers, and phone numbers."], "explain": "", "answers": [], "resources": ["https://docs.aws.amazon.com/transcribe/latest/dg/pii-redaction-stream.html", "https://aws.amazon.com/transcribe/"]}, {"_id": 226, "question": "226 # A company is running a multi-tier ecommerce web application in the AWS Cloud. The application runs on Amazon EC2 instances with an Amazon RDS for MySQL Multi-AZ DB instance. Amazon RDS is configured with the latest generation DB instance with 2,000 GB of storage in a General Purpose SSD (gp3) Amazon Elastic Block Store (Amazon EBS) volume. The database performance affects the application during periods of high demand. A database administrator analyzes the logs in Amazon CloudWatch Logs and discovers that the application performance always degrades when the number of https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248523040819&usg=AOvVaw2hSm0mjZd5Kdxmmq68KIDK https://www.google.com/url?q=https://docs.aws.amazon.com/transcribe/latest/dg/pii-redaction-stream.html&sa=D&source=apps-viewer-frontend&ust=1720248523040847&usg=AOvVaw1U_Tn41yZ99kux6y9DN-Pz https://docs.aws.amazon.com/transcribe/latest/dg/pii-redaction-stream.html https://www.google.com/url?q=https://aws.amazon.com/transcribe/&sa=D&source=apps-viewer-frontend&ust=1720248523040856&usg=AOvVaw0r71oYMWf6q9P02HjTbV1V https://aws.amazon.com/transcribe/ 108 read and write IOPS is higher than 20,000. What should a solutions architect do to improve the application performance?", "options": ["A. Replace the volume with a magnetic volume.", "B. Increase the number of IOPS on the gp3 volume.", "C. Replace the volume with a Provisioned IOPS SSD (io2) volume.", "D. Replace the 2,000 GB gp3 volume with two 1,000 GB gp3 volumes. Selected Answer: D {C} - io2 is not supported {D} - ?? {B} - definitely feasible Amazon RDS gp3 volumes give you the flexibility to provision storage performance independently of storage capacity, paying only for the resources you need. Every gp3 volume provides you the ability to select from 20 GiB to 64 TiB of storage capacity, with a baseline storage performance of 3,000 IOPS included with the price of storage. For workloads that need even more performance, you can scale up to 64,000 IOPS for an additional cost."], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248523040819&usg=AOvVaw2hSm0mjZd5Kdxmmq68KIDK", "https://www.google.com/url?q=https://docs.aws.amazon.com/transcribe/latest/dg/pii-redaction-stream.html&sa=D&source=apps-viewer-frontend&ust=1720248523040847&usg=AOvVaw1U_Tn41yZ99kux6y9DN-Pz", "https://docs.aws.amazon.com/transcribe/latest/dg/pii-redaction-stream.html", "https://www.google.com/url?q=https://aws.amazon.com/transcribe/&sa=D&source=apps-viewer-frontend&ust=1720248523040856&usg=AOvVaw0r71oYMWf6q9P02HjTbV1V", "https://aws.amazon.com/transcribe/", "https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html"]}, {"_id": 227, "question": "227 # An IAM user made several configuration changes to AWS resources in their company's account during a production deployment last week. A solutions architect learned that a couple of security group rules are not configured as desired. The solutions architect wants to confirm which IAM user was responsible for making changes. Which service should the solutions architect use to find the desired information?", "options": ["A. Amazon GuardDuty", "B. Amazon Inspector", "C. AWS CloudTrail", "D. AWS Config Selected Answer: C", "C. AWS CloudTrail The best option is to use AWS CloudTrail to find the desired information. AWS CloudTrail is a service that enables governance, compliance, operational auditing, and risk auditing of AWS account activities. CloudTrail can be used to log all changes made to resources in an AWS account, including changes made by IAM users, EC2 instances, AWS management console, and other AWS services. By using CloudTrail, the solutions architect can identify the IAM user who made the configuration changes to the security group rules. Question #: 396"], "explain": "", "answers": [], "resources": []}, {"_id": 228, "question": "228 # A company has implemented a self-managed DNS service on AWS. The solution consists of the following: Amazon EC2 instances in different AWS Regions Endpoints of a standard accelerator in AWS Global Accelerator The company wants to protect the solution against DDoS attacks. What should a solutions architect do to meet this requirement?", "options": ["A. Subscribe to AWS Shield Advanced. Add the accelerator as a resource to protect.", "B. Subscribe to AWS Shield Advanced. Add the EC2 instances as resources to protect.", "C. Create an AWS WAF web ACL that includes a rate-based rule. Associate the web ACL with the accelerator.", "D. Create an AWS WAF web ACL that includes a rate-based rule. Associate the web ACL with the EC2 instances. Selected Answer: A DDoS attacks = AWS Shield Advance resource as Global Acc"], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248523598979&usg=AOvVaw0zesGn3o-YnYkndjfttyJD", "https://www.google.com/url?q=https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html&sa=D&source=apps-viewer-frontend&ust=1720248523599009&usg=AOvVaw2zJXlAnJtquIPdp-6azgvd", "https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html", "https://docs.aws.amazon.com/waf/latest/developerguide/ddos-event-mitigation-logic-gax.html"]}, {"_id": 229, "question": "229 # An ecommerce company needs to run a scheduled daily job to aggregate and filter sales records for analytics. The company stores the sales records in an Amazon S3 bucket. Each object can be up to 10 GB in size. Based on the number of sales events, the job can take up to an hour to complete. The CPU and memory usage of the job are constant and are known in advance. A solutions architect needs to minimize the amount of operational effort that is needed for the job to run. Which solution meets these requirements?", "options": ["A. Create an AWS Lambda function that has an Amazon EventBridge notification. Schedule the EventBridge event to run once a day.", "B. Create an AWS Lambda function. Create an Amazon API Gateway HTTP API, and integrate the API with the function. Create an Amazon EventBridge scheduled event that calls the API and invokes the function.", "C. Create an Amazon Elastic Container Service (Amazon ECS) cluster with an AWS Fargate launch type. Create an Amazon EventBridge scheduled event that launches an ECS task on the cluster to run the job.", "D. Create an Amazon Elastic Container Service (Amazon ECS) cluster with an Amazon EC2 launch type and an Auto Scaling group with at least one EC2 instance. Create an Amazon EventBridge scheduled event that launches an ECS task on the cluster to run the job. Selected Answer: C Based on the requirement, we can eliminate option A and B since they use AWS Lambda which has a limit of 15 minutes of execution time, which may not be sufficient for a job that can take up to an hour to complete. Between options C and D, option C is the better choice since it uses AWS Fargate which is a serverless compute engine for containers that eliminates the need to manage the underlying EC2 instances, making it a low operational effort solution. Additionally, Fargate also provides instant scale-up and scale-down capabilities to run the scheduled job as per the requirement. Therefore, the correct answer is:", "C. Question #: 398"], "explain": "", "answers": [], "resources": []}, {"_id": 230, "question": "230 # A company needs to transfer 600 TB of data from its on-premises network-attached storage (NAS) system to the AWS Cloud. The data transfer must be complete within 2 weeks. The data is sensitive and must be encrypted in transit. The company\u2019s internet connection can support an upload speed of 100 Mbps. Which solution meets these requirements MOST cost-effectively?", "options": ["A. Use Amazon S3 multi-part upload functionality to transfer the files over HTTPS.", "B. Create a VPN connection between the on-premises NAS system and the nearest AWS Region. Transfer the data over the VPN connection.", "C. Use the AWS Snow Family console to order several AWS Snowball Edge Storage Optimized devices. Use the devices to transfer the data to Amazon S3.", "D. Set up a 10 Gbps AWS Direct Connect connection between the company location and the nearest AWS Region. Transfer the data over a VPN connection into the Region to store the data in Amazon S3. Selected Answer: C With the existing data link the transfer takes ~ 600 days in the best case."], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248524216579&usg=AOvVaw0suupl1vSqYMrNDW9nhPvI", "https://www.google.com/url?q=https://docs.aws.amazon.com/waf/latest/developerguide/ddos-event-mitigation-logic-gax.html&sa=D&source=apps-viewer-frontend&ust=1720248524216633&usg=AOvVaw2mZ5Gmix0HkKdjgWBCIXg6", "https://docs.aws.amazon.com/waf/latest/developerguide/ddos-event-mitigation-logic-gax.html"]}, {"_id": 231, "question": "231 # A financial company hosts a web application on AWS. The application uses an Amazon API Gateway Regional API endpoint to give users the ability to retrieve current stock prices. The company\u2019s security team has noticed an increase in the number of API requests. The security team is concerned that HTTP flood attacks might take the application offline. A solutions architect must design a solution to protect the application from this type of attack. Which solution meets these requirements with the LEAST operational overhead?", "options": ["A. Create an Amazon CloudFront distribution in front of the API Gateway Regional API endpoint with a maximum TTL of 24 hours.", "B. Create a Regional AWS WAF web ACL with a rate-based rule. Associate the web ACL with the API Gateway stage.", "C. Use Amazon CloudWatch metrics to monitor the Count metric and alert the security team when the predefined rate is reached.", "D. Create an Amazon CloudFront distribution with Lambda@Edge in front of the API Gateway Regional API endpoint. Create an AWS Lambda function to block requests from IP addresses that exceed the predefined rate. Selected Answer: B A -"], "explain": "", "answers": [], "resources": ["https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html", "https://docs.aws.amazon.com/waf/latest/developerguide/web-acl.html"]}, {"_id": 232, "question": "232 # A meteorological startup company has a custom web application to sell weather data to its users online. The company uses Amazon DynamoDB to store its data and wants to build a new service that sends an alert to the managers of four internal teams every time a new weather event is recorded. The company does not want this new service to affect the performance of the current application. What should a solutions architect do to meet these requirements with the LEAST amount of operational overhead?", "options": ["A. Use DynamoDB transactions to write new event data to the table. Configure the transactions to notify internal teams.", "B. Have the current application publish a message to four Amazon Simple Notification Service (Amazon SNS) topics. Have each team subscribe to one topic.", "C. Enable Amazon DynamoDB Streams on the table. Use triggers to write to a single Amazon Simple Notification Service (Amazon SNS) topic to which the teams can subscribe.", "https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248524761963&usg=AOvVaw0l99tuEMm5n6cektPYttoC https://www.google.com/url?q=https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html&sa=D&source=apps-viewer-frontend&ust=1720248524762027&usg=AOvVaw27FH85kT5c4e3b2x9IxWFN https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html https://www.google.com/url?q=https://docs.aws.amazon.com/waf/latest/developerguide/web-acl.html&sa=D&source=apps-viewer-frontend&ust=1720248524762041&usg=AOvVaw1S7mbpqqiZ6nutXJfbEQe4 https://docs.aws.amazon.com/waf/latest/developerguide/web-acl.html 111", "D. Add a custom attribute to each record to flag new items. Write a cron job that scans the table every minute for items that are new and notifies an Amazon Simple Queue Service (Amazon SQS) queue to which the teams can subscribe. Selected Answer: C The best solution to meet these requirements with the least amount of operational overhead is to enable Amazon DynamoDB Streams on the table and use triggers to write to a single Amazon Simple Notification Service (Amazon SNS) topic to which the teams can subscribe. This solution requires minimal configuration and infrastructure setup, and Amazon DynamoDB Streams provide a low-latency way to capture changes to the DynamoDB table. The triggers automatically capture the changes and publish them to the SNS topic, which notifies the internal teams. Answer A is not a suitable solution because it requires additional configuration to notify the internal teams, and it could add operational overhead to the application. Answer B is not the best solution because it requires changes to the current application, which may affect its performance, and it creates additional work for the teams to subscribe to multiple topics. Answer D is not a good solution because it requires a cron job to scan the table every minute, which adds additional operational overhead to the system. Therefore, the correct answer is"], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248524761963&usg=AOvVaw0l99tuEMm5n6cektPYttoC", "https://www.google.com/url?q=https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html&sa=D&source=apps-viewer-frontend&ust=1720248524762027&usg=AOvVaw27FH85kT5c4e3b2x9IxWFN", "https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html", "https://www.google.com/url?q=https://docs.aws.amazon.com/waf/latest/developerguide/web-acl.html&sa=D&source=apps-viewer-frontend&ust=1720248524762041&usg=AOvVaw1S7mbpqqiZ6nutXJfbEQe4", "https://docs.aws.amazon.com/waf/latest/developerguide/web-acl.html"]}, {"_id": 233, "question": "233 # A university research laboratory needs to migrate 30 TB of data from an on-premises Windows file server to Amazon FSx for Windows File Server. The laboratory has a 1 Gbps network link that many other departments in the university share. The laboratory wants to implement a data migration service that will maximize the performance of the data transfer. However, the laboratory needs to be able to control the amount of bandwidth that the service uses to minimize the impact on other departments. The data migration must take place within the next 5 days. Which AWS solution will meet these requirements?", "options": ["A. AWS Snowcone", "B. Amazon FSx File Gateway", "C. AWS DataSync", "D. AWS Transfer Family Selected Answer: C AWS DataSync is a data transfer service that can copy large amounts of data between on-premises storage and Amazon FSx for Windows File Server at high speeds. It allows you to control the amount of bandwidth used during data transfer. DataSync uses agents at the source and destination to automatically copy files and file metadata over the network. This optimizes the data transfer and minimizes the impact on your network bandwidth. DataSync allows you to schedule data transfers and configure transfer rates to suit your needs. You can transfer 30 TB within 5 days while controlling bandwidth usage. DataSync can resume interrupted transfers and validate data to ensure integrity. It provides detailed monitoring and reporting on the progress and performance of data transfers. Option A - AWS Snowcone is more suitable for physically transporting data when network bandwidth is limited. It would not complete the transfer within 5 days. Option B - Amazon FSx File Gateway only provides access to files stored in Amazon FSx and does not perform the actual data migration from on-premises to FSx. Option D - AWS Transfer Family is for transferring files over FTP, FTPS and SFTP. It may require scripting to transfer 30 TB and monitor progress, and lacks bandwidth controls."], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248525430390&usg=AOvVaw0ovo_-BVnKkCBU6Nyqq2vK"]}, {"_id": 234, "question": "234 # A company wants to create a mobile app that allows users to stream slow-motion video clips on their mobile devices. Currently, the app captures video clips and uploads the video clips in raw format into an Amazon S3 bucket. The app retrieves these video clips directly from the S3 bucket. However, the videos are large in their raw format. Users are experiencing issues with buffering and playback on mobile devices. The company wants to implement solutions to maximize the performance and scalability of the app while minimizing operational overhead. Which combination of solutions will meet these requirements? (Choose two.)", "options": ["A. Deploy Amazon CloudFront for content delivery and caching.", "B. Use AWS DataSync to replicate the video files across AW'S Regions in other S3 buckets.", "C. Use Amazon Elastic Transcoder to convert the video files to more appropriate formats.", "D. Deploy an Auto Sealing group of Amazon EC2 instances in Local Zones for content delivery and caching.", "E. Deploy an Auto Scaling group of Amazon EC2 instances to convert the video files to more appropriate formats. A &", "C. A: Amazon CloudFront is a content delivery network (CDN) that can help improve the performance and scalability of the app by caching content at edge locations, reducing latency, and improving the delivery of video clips to users. CloudFront can also provide features such as DDoS protection, SSL/TLS encryption, and content compression to optimize the delivery of video clips. C: Amazon Elastic Transcoder is a service that can help optimize the video format for mobile devices, reducing the size of the video files, and improving the playback performance. Elastic Transcoder can also convert videos into multiple formats to support different devices and platforms. Question #: 303"], "explain": "", "answers": [], "resources": []}, {"_id": 235, "question": "235 # A company is launching a new application deployed on an Amazon Elastic Container Service (Amazon ECS) cluster and is using the Fargate launch type for ECS tasks. The company is monitoring CPU and memory usage because it is expecting high traffic to the application upon its launch. However, the company wants to reduce costs when utilization decreases. What should a solutions architect recommend?", "options": ["A. Use Amazon EC2 Auto Scaling to scale at certain periods based on previous traffic patterns.", "B. Use an AWS Lambda function to scale Amazon ECS based on metric breaches that trigger an Amazon CloudWatch alarm.", "C. Use Amazon EC2 Auto Scaling with simple scaling policies to scale when ECS metric breaches trigger an Amazon CloudWatch alarm.", "D. Use AWS Application Auto Scaling with target tracking policies to scale when ECS metric breaches trigger an Amazon CloudWatch alarm. Answer is D Application Auto Scaling is a web service for developers and system administrators who need a solution for automatically scaling their scalable resources for individual AWS services beyond Amazon EC2."], "explain": "", "answers": [], "resources": ["https://docs.aws.amazon.com/autoscaling/application/userguide/what-is-application-auto-scaling.html"]}, {"_id": 236, "question": "236 # A company recently created a disaster recovery site in a different AWS Region. The company needs to transfer large amounts of data back and forth between NFS file systems in the two Regions on a periodic basis. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Use AWS DataSync.", "B. Use AWS Snowball devices.", "https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248526062457&usg=AOvVaw0v5nRRpRM33kITOTtRDl4A https://www.google.com/url?q=https://docs.aws.amazon.com/autoscaling/application/userguide/what-is-application-auto-scaling.html&sa=D&source=apps-viewer-frontend&ust=1720248526062502&usg=AOvVaw1Kgs_LHLwmXw11ke6wpWyn https://docs.aws.amazon.com/autoscaling/application/userguide/what-is-application-auto-scaling.html 113", "C. Set up an SFTP server on Amazon EC2."], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248526062457&usg=AOvVaw0v5nRRpRM33kITOTtRDl4A", "https://www.google.com/url?q=https://docs.aws.amazon.com/autoscaling/application/userguide/what-is-application-auto-scaling.html&sa=D&source=apps-viewer-frontend&ust=1720248526062502&usg=AOvVaw1Kgs_LHLwmXw11ke6wpWyn", "https://docs.aws.amazon.com/autoscaling/application/userguide/what-is-application-auto-scaling.html"]}, {"_id": 237, "question": "237 # A company is designing a shared storage solution for a gaming application that is hosted in the AWS Cloud. The company needs the ability to use SMB clients to access data. The solution must be fully managed. Which AWS solution meets these requirements?", "options": ["A. Create an AWS DataSync task that shares the data as a mountable file system. Mount the file system to the application server.", "B. Create an Amazon EC2 Windows instance. Install and configure a Windows file share role on the instance. Connect the application server to the file share.", "C. Create an Amazon FSx for Windows File Server file system. Attach the file system to the origin server. Connect the application server to the file system.", "D. Create an Amazon S3 bucket. Assign an IAM role to the application to grant access to the S3 bucket. Mount the S3 bucket to the application server. Selected Answer: C Amazon FSx for Windows File Server provides a fully managed native Windows file system that can be accessed using the industry-standard SMB protocol. This allows Windows clients like the gaming application to directly access file data. FSx for Windows File Server handles time-consuming file system administration tasks like provisioning, setup, maintenance, file share management, backups, security, and software patching - reducing operational overhead. FSx for Windows File Server supports high file system throughput, IOPS, and consistent low latencies required for performance-sensitive workloads. This makes it suitable for a gaming application. The file system can be directly attached to EC2 instances, providing a performant shared storage solution for the gaming servers. Option A - DataSync is for data transfer, not providing a shared file system. It cannot be mounted or directly accessed. Option B - A self-managed EC2 file share would require manually installing, configuring and maintaining a Windows file system and share. This demands significant overhead to operate."], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248526680384&usg=AOvVaw3yqgFZQSPwL1XQhu_50WHH"]}, {"_id": 238, "question": "238 # A company wants to run an in-memory database for a latency-sensitive application that runs on Amazon EC2 instances. The application processes more than 100,000 transactions each minute and requires high network throughput. A solutions architect needs to provide a cost-effective network design that minimizes data transfer charges. Which solution meets these requirements?", "options": ["A. Launch all EC2 instances in the same Availability Zone within the same AWS Region. Specify a placement group with cluster strategy when launching EC2 instances.", "B. Launch all EC2 instances in different Availability Zones within the same AWS Region. Specify a placement group with partition strategy when launching EC2 instances.", "C. Deploy an Auto Scaling group to launch EC2 instances in different Availability Zones based on a network utilization target.", "D. Deploy an Auto Scaling group with a step scaling policy to launch EC2 instances in different Availability Zones. Selected Answer: A Reasons: Launching instances within a single AZ and using a cluster placement group provides the lowest network latency and highest bandwidth between instances. This maximizes performance for an in- memory database and high-throughput application. Communications between instances in the same AZ and placement group are free, minimizing data transfer charges. Inter-AZ and public IP traffic can incur charges. A cluster placement group enables the instances to be placed close together within the AZ, allowing the high network throughput required. Partition groups span AZs, reducing bandwidth. Auto Scaling across zones could launch instances in AZs that increase data transfer charges. It may reduce network throughput, impacting performance. Option B - A partition placement group spans AZs, reducing network bandwidth between instances and potentially increasing costs. Option C - Auto Scaling alone does not guarantee the network throughput and cost controls required for this use case. Launching across AZs could increase data transfer charges. Option D - Step scaling policies determine how many instances to launch based on metrics alone. They lack control over network connectivity and costs between instances after launch. Question #: 307"], "explain": "", "answers": [], "resources": []}, {"_id": 239, "question": "239 # A company that primarily runs its application servers on premises has decided to migrate to AWS. The company wants to minimize its need to scale its Internet Small Computer Systems Interface (iSCSI) storage on premises. The company wants only its recently accessed data to remain stored locally. Which AWS solution should the company use to meet these requirements?", "options": ["A. Amazon S3 File Gateway", "B. AWS Storage Gateway Tape Gateway", "C. AWS Storage Gateway Volume Gateway stored volumes", "D. AWS Storage Gateway Volume Gateway cached volumes Selected Answer: D Volume Gateway cached volumes store entire datasets on S3, while keeping a portion of recently accessed data on your local storage as a cache. This meets the goal of minimizing on-premises storage needs while keeping hot data local."], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248527668722&usg=AOvVaw1CSmgSSK2WvkX91oSZDMto"]}, {"_id": 240, "question": "240 # A company has multiple AWS accounts that use consolidated billing. The company runs several active high performance Amazon RDS for Oracle On-Demand DB instances for 90 days. The company\u2019s finance team has access to AWS Trusted Advisor in the consolidated billing account and all other AWS accounts. The finance team needs to use the appropriate AWS account to access the Trusted Advisor check recommendations for RDS. The finance team must review the appropriate Trusted Advisor check to reduce RDS costs. Which combination of steps should the finance team take to meet these requirements? (Choose two.)", "options": ["A. Use the Trusted Advisor recommendations from the account where the RDS instances are running.", "B. Use the Trusted Advisor recommendations from the consolidated billing account to see all RDS instance checks at the same time.", "C. Review the Trusted Advisor check for Amazon RDS Reserved Instance Optimization.", "D. Review the Trusted Advisor check for Amazon RDS Idle DB Instances.", "E. Review the Trusted Advisor check for Amazon Redshift Reserved Node Optimization. Selected Answer: BD"], "explain": "", "answers": [], "resources": ["https://docs.aws.amazon.com/awssupport/latest/user/organizational-view.html", "https://docs.aws.amazon.com/awssupport/latest/user/cost-optimization-checks.html#amazon-rds-idle-"]}, {"_id": 241, "question": "241 # A solutions architect needs to optimize storage costs. The solutions architect must identify any Amazon S3 buckets that are no longer being accessed or are rarely accessed. Which solution will accomplish this goal with the LEAST operational overhead?", "options": [], "explain": "", "answers": [], "resources": []}, {"_id": 241, "question": "241 # A solutions architect needs to optimize storage costs. The solutions architect must identify any Amazon S3 buckets that are no longer being accessed or are rarely accessed. Which solution will accomplish this goal with the LEAST operational overhead? A. Analyze bucket access patterns by using the S3 Storage Lens dashboard for advanced activity metrics. B. Analyze bucket access patterns by using the S3 dashboard in the AWS Management Console. C. Turn on the Amazon CloudWatch BucketSizeBytes metric for buckets. Analyze bucket access patterns by using the metrics data with Amazon Athena. D. Turn on AWS CloudTrail for S3 object monitoring. Analyze bucket access patterns by using CloudTrail logs that are integrated with Amazon CloudWatch Logs. Selected Answer: A The S3 Storage Lens dashboard provides visibility into storage metrics and activity patterns to help optimize storage costs. It shows metrics like objects added, objects deleted, storage consumed, and requests. It can filter by bucket, prefix, and tag to analyze specific subsets of data https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248528252980&usg=AOvVaw28cP_CqSrNsmq6okJAQ-lw https://www.google.com/url?q=https://docs.aws.amazon.com/awssupport/latest/user/organizational-view.html&sa=D&source=apps-viewer-frontend&ust=1720248528253043&usg=AOvVaw2UjFCOK9SEK6aAsjGsAUvr https://docs.aws.amazon.com/awssupport/latest/user/organizational-view.html https://www.google.com/url?q=https://docs.aws.amazon.com/awssupport/latest/user/cost-optimization-checks.html%23amazon-rds-idle-dbs-instances&sa=D&source=apps-viewer-frontend&ust=1720248528253062&usg=AOvVaw0sEzq7BtetRgHb1IVnCC_M https://docs.aws.amazon.com/awssupport/latest/user/cost-optimization-checks.html#amazon-rds-idle-dbs-instances 116 B) The standard S3 console dashboard provides basic info but would require manually analyzing metrics for each bucket. This does not scale well and requires significant overhead. C) Turning on the BucketSizeBytes metric and analyzing the data in Athena may provide insights but would require enabling metrics, building Athena queries, and analyzing the results. This requires more operational effort than option", "options": ["A. Analyze bucket access patterns by using the S3 Storage Lens dashboard for advanced activity metrics.", "B. Analyze bucket access patterns by using the S3 dashboard in the AWS Management Console.", "C. Turn on the Amazon CloudWatch BucketSizeBytes metric for buckets. Analyze bucket access patterns by using the metrics data with Amazon Athena.", "D. Turn on AWS CloudTrail for S3 object monitoring. Analyze bucket access patterns by using CloudTrail logs that are integrated with Amazon CloudWatch Logs. Selected Answer: A The S3 Storage Lens dashboard provides visibility into storage metrics and activity patterns to help optimize storage costs. It shows metrics like objects added, objects deleted, storage consumed, and requests. It can filter by bucket, prefix, and tag to analyze specific subsets of data", "A. D) Enabling CloudTrail logging and monitoring the logs in CloudWatch Logs could provide access pattern data but would require setting up CloudTrail, monitoring the logs, and analyzing the relevant info. This option has the highest operational overhead Question #: 310"], "explain": "", "answers": [], "resources": ["https://www.google.com/url?q=https://www.youtube.com/channel/UC1w7rLIVgDgMdI_ktBwAqww&sa=D&source=apps-viewer-frontend&ust=1720248528252980&usg=AOvVaw28cP_CqSrNsmq6okJAQ-lw", "https://www.google.com/url?q=https://docs.aws.amazon.com/awssupport/latest/user/organizational-view.html&sa=D&source=apps-viewer-frontend&ust=1720248528253043&usg=AOvVaw2UjFCOK9SEK6aAsjGsAUvr", "https://docs.aws.amazon.com/awssupport/latest/user/organizational-view.html", "https://www.google.com/url?q=https://docs.aws.amazon.com/awssupport/latest/user/cost-optimization-checks.html%23amazon-rds-idle-dbs-instances&sa=D&source=apps-viewer-frontend&ust=1720248528253062&usg=AOvVaw0sEzq7BtetRgHb1IVnCC_M", "https://docs.aws.amazon.com/awssupport/latest/user/cost-optimization-checks.html#amazon-rds-idle-dbs-instances"]}, {"_id": 242, "question": "242 # A company sells datasets to customers who do research in artificial intelligence and machine learning (AI/ML). The datasets are large, formatted files that are stored in an Amazon S3 bucket in the us-east-1 Region. The company hosts a web application that the customers use to purchase access to a given dataset. The web application is deployed on multiple Amazon EC2 instances behind an Application Load Balancer. After a purchase is made, customers receive an S3 signed URL that allows access to the files. The customers are distributed across North America and Europe. The company wants to reduce the cost that is associated with data transfers and wants to maintain or improve performance. What should a solutions architect do to meet these requirements?", "options": ["A. Configure S3 Transfer Acceleration on the existing S3 bucket. Direct customer requests to the S3 Transfer Acceleration endpoint. Continue to use S3 signed URLs for access control.", "B. Deploy an Amazon CloudFront distribution with the existing S3 bucket as the origin. Direct customer requests to the CloudFront URL. Switch to CloudFront signed URLs for access control.", "C. Set up a second S3 bucket in the eu-central-1 Region with S3 Cross-Region Replication between the buckets. Direct customer requests to the closest Region. Continue to use S3 signed URLs for access control.", "D. Modify the web application to enable streaming of the datasets to end users. Configure the web application to read the data from the existing S3 bucket. Implement access control directly in the application. Selected Answer:", "B. To reduce the cost associated with data transfers and maintain or improve performance, a solutions architect should use Amazon CloudFront, a content delivery network (CDN) service that securely delivers data, videos, applications, and APIs to customers globally with low latency and high transfer speeds. Deploying a CloudFront distribution with the existing S3 bucket as the origin will allow the company to serve the data to customers from edge locations that are closer to them, reducing data transfer costs and improving performance. Directing customer requests to the CloudFront URL and switching to CloudFront signed URLs for access control will enable customers to access the data securely and efficiently."], "explain": "", "answers": [], "resources": ["https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/PrivateContent.html"]}]