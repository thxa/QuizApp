[{"_id": 663, "question": "663# A gaming company is building an application with Voice over IP capabilities. The application will serve traffic to users across the world. The application needs to be highly available with an automated failover across AWS Regions. The company wants to minimize the latency of users without relying on IP address caching on user devices. What should a solutions architect do to meet these requirements?", "options": ["A. Use AWS Global Accelerator with health checks.", "B. Use Amazon Route 53 with a geolocation routing policy.", "C. Create an Amazon CloudFront distribution that includes multiple origins.", "D. Create an Application Load Balancer that uses path-based routing. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 663, "question": "663# A gaming company is building an application with Voice over IP capabilities. The application will serve traffic to users across the world. The application needs to be highly available with an automated failover across AWS Regions. The company wants to minimize the latency of users without relying on IP address caching on user devices. What should a solutions architect do to meet these requirements?", "options": ["A. Use AWS Global Accelerator with health checks.", "B. Use Amazon Route 53 with a geolocation routing policy.", "C. Create an Amazon CloudFront distribution that includes multiple origins.", "D. Create an Application Load Balancer that uses path-based routing. 389 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 664, "question": "664# A weather forecasting company needs to process hundreds of gigabytes of data with sub-millisecond latency. The company has a high performance computing (HPC) environment in its data center and wants to expand its forecasting capabilities. A solutions architect must identify a highly available cloud storage solution that can handle large amounts of sustained throughput. Files that are stored in the solution should be accessible to thousands of compute instances that will simultaneously access and process the entire dataset. What should the solutions architect do to meet these requirements?", "options": ["A. Use Amazon FSx for Lustre scratch file systems.", "B. Use Amazon FSx for Lustre persistent file systems.", "C. Use Amazon Elastic File System (Amazon EFS) with Bursting Throughput mode.", "D. Use Amazon Elastic File System (Amazon EFS) with Provisioned Throughput mode. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 664, "question": "664# A weather forecasting company needs to process hundreds of gigabytes of data with sub-millisecond latency. The company has a high performance computing (HPC) environment in its data center and wants to expand its forecasting capabilities. A solutions architect must identify a highly available cloud storage solution that can handle large amounts of sustained throughput. Files that are stored in the solution should be accessible to thousands of compute instances that will simultaneously access and process the entire dataset. What should the solutions architect do to meet these requirements?", "options": [], "explain": "", "answers": [], "resources": []}, {"_id": 664, "question": "664# A weather forecasting company needs to process hundreds of gigabytes of data with sub-millisecond latency. The company has a high performance computing (HPC) environment in its data center and wants to expand its forecasting capabilities. A solutions architect must identify a highly available cloud storage solution that can handle large amounts of sustained throughput. Files that are stored in the solution should be accessible to thousands of compute instances that will simultaneously access and process the entire dataset. What should the solutions architect do to meet these requirements? A. Use Amazon FSx for Lustre scratch file systems. B. Use Amazon FSx for Lustre persistent file systems. C. Use Amazon Elastic File System (Amazon EFS) with Bursting Throughput mode. D. Use Amazon Elastic File System (Amazon EFS) with Provisioned Throughput mode. 390 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com 665# An ecommerce company runs a PostgreSQL database on premises. The database stores data by using high IOPS Amazon Elastic Block Store (Amazon EBS) block storage. The daily peak I/O transactions per second do not exceed 15,000 IOPS. The company wants to migrate the database to Amazon RDS for PostgreSQL and provision disk IOPS performance independent of disk storage capacity. Which solution will meet these requirements MOST cost- effectively?", "options": [], "explain": "", "answers": [], "resources": []}, {"_id": 664, "question": "664# A weather forecasting company needs to process hundreds of gigabytes of data with sub-millisecond latency. The company has a high performance computing (HPC) environment in its data center and wants to expand its forecasting capabilities. A solutions architect must identify a highly available cloud storage solution that can handle large amounts of sustained throughput. Files that are stored in the solution should be accessible to thousands of compute instances that will simultaneously access and process the entire dataset. What should the solutions architect do to meet these requirements? A. Use Amazon FSx for Lustre scratch file systems. B. Use Amazon FSx for Lustre persistent file systems. C. Use Amazon Elastic File System (Amazon EFS) with Bursting Throughput mode. D. Use Amazon Elastic File System (Amazon EFS) with Provisioned Throughput mode. 390 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com 665# An ecommerce company runs a PostgreSQL database on premises. The database stores data by using high IOPS Amazon Elastic Block Store (Amazon EBS) block storage. The daily peak I/O transactions per second do not exceed 15,000 IOPS. The company wants to migrate the database to Amazon RDS for PostgreSQL and provision disk IOPS performance independent of disk storage capacity. Which solution will meet these requirements MOST cost- effectively? A. Configure the General Purpose SSD (gp2) EBS volume storage type and provision 15,000 IOPS. B. Configure the Provisioned IOPS SSD (io1) EBS volume storage type and provision 15,000 IOPS. C. Configure the General Purpose SSD (gp3) EBS volume storage type and provision 15,000 IOPS. D. Configure the EBS magnetic volume type to achieve maximum IOPS. sthithapragnasya@gmail.com 665# An ecommerce company runs a PostgreSQL database on premises. The database stores data by using high IOPS Amazon Elastic Block Store (Amazon EBS) block storage. The daily peak I/O transactions per second do not exceed 15,000 IOPS. The company wants to migrate the database to Amazon RDS for PostgreSQL and provision disk IOPS performance independent of disk storage capacity. Which solution will meet these requirements MOST cost- effectively?", "options": ["A. Use Amazon FSx for Lustre scratch file systems.", "B. Use Amazon FSx for Lustre persistent file systems.", "C. Use Amazon Elastic File System (Amazon EFS) with Bursting Throughput mode.", "A. Configure the General Purpose SSD (gp2) EBS volume storage type and provision 15,000 IOPS.", "B. Configure the Provisioned IOPS SSD (io1) EBS volume storage type and provision 15,000 IOPS.", "C. Configure the General Purpose SSD (gp3) EBS volume storage type and provision 15,000 IOPS.", "A. Configure the General Purpose SSD (gp2) EBS volume storage type and provision 15,000 IOPS.", "B. Configure the Provisioned IOPS SSD (io1) EBS volume storage type and provision 15,000 IOPS.", "C. Configure the General Purpose SSD (gp3) EBS volume storage type and provision 15,000 IOPS.", "D. Configure the EBS magnetic volume type to achieve maximum IOPS. 391 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 666, "question": "666# A company wants to migrate its on-premises Microsoft SQL Server Enterprise edition database to AWS. The company's online application uses the database to process transactions. The data analysis team uses the same production database to run reports for analytical processing. The company wants to reduce operational overhead by moving to managed services wherever possible. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Migrate to Amazon RDS for Microsoft SOL Server. Use read replicas for reporting purposes", "B. Migrate to Microsoft SQL Server on Amazon EC2. Use Always On read replicas for reporting purposes", "C. Migrate to Amazon DynamoDB. Use DynamoDB on-demand replicas for reporting purposes", "D. Migrate to Amazon Aurora MySQL. Use Aurora read replicas for reporting purposes sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 666, "question": "666# A company wants to migrate its on-premises Microsoft SQL Server Enterprise edition database to AWS. The company's online application uses the database to process transactions. The data analysis team uses the same production database to run reports for analytical processing. The company wants to reduce operational overhead by moving to managed services wherever possible. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Migrate to Amazon RDS for Microsoft SOL Server. Use read replicas for reporting purposes", "B. Migrate to Microsoft SQL Server on Amazon EC2. Use Always On read replicas for reporting purposes", "C. Migrate to Amazon DynamoDB. Use DynamoDB on-demand replicas for reporting purposes", "D. Migrate to Amazon Aurora MySQL. Use Aurora read replicas for reporting purposes 392 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 667, "question": "667# A company uses AWS CloudFormation to deploy an application that uses an Amazon API Gateway REST API with AWS Lambda function integration. The application uses Amazon DynamoDB for data persistence. The application has three stages: development, testing, and production. Each stage uses its own DynamoDB table. The company has encountered unexpected issues when promoting changes to the production stage. The changes were successful in the development and testing stages. A developer needs to route 20% of the traffic to the new production stage API with the next production release. The developer needs to route the remaining 80% of the traffic to the existing production stage. The solution must minimize the number of errors that any single customer experiences. Which approach should the developer take to meet these requirements?", "options": ["A. Update 20% of the planned changes to the production stage. Deploy the new production stage. Monitor the results. Repeat this process five times to test all planned changes.", "B. Update the Amazon Route 53 DNS record entry for the production stage API to use a weighted routing policy. Set the weight to a value of 80. Add a second record for the production domain name. Change the second routing policy to a weighted routing policy. Set the weight of the second policy to a value of 20. Change the alias of the second policy to use the testing stage API.", "C. Deploy an Application Load Balancer (ALB) in front of the REST API. Change the production API Amazon Route 53 record to point traffic to the ALB. Register the production and testing stages as targets of the ALB with weights of 80% and 20%, respectively.", "D. Configure canary settings for the production stage API. Change the percentage of traffic directed to canary deployment to 20%. Make the planned updates to the production stage. Deploy the changes sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 667, "question": "667# A company uses AWS CloudFormation to deploy an application that uses an Amazon API Gateway REST API with AWS Lambda function integration. The application uses Amazon DynamoDB for data persistence. The application has three stages: development, testing, and production. Each stage uses its own DynamoDB table. The company has encountered unexpected issues when promoting changes to the production stage. The changes were successful in the development and testing stages. A developer needs to route 20% of the traffic to the new production stage API with the next production release. The developer needs to route the remaining 80% of the traffic to the existing production stage. The solution must minimize the number of errors that any single customer experiences. Which approach should the developer take to meet these requirements?", "options": ["A. Update 20% of the planned changes to the production stage. Deploy the new production stage. Monitor the results. Repeat this process five times to test all planned changes.", "B. Update the Amazon Route 53 DNS record entry for the production stage API to use a weighted routing policy. Set the weight to a value of 80. Add a second record for the production domain name. Change the second routing policy to a weighted routing policy. Set the weight of the second policy to a value of 20. Change the alias of the second policy to use the testing stage API.", "C. Deploy an Application Load Balancer (ALB) in front of the REST API. Change the production API Amazon Route 53 record to point traffic to the ALB. Register the production and testing stages as targets of the ALB with weights of 80% and 20%, respectively.", "D. Configure canary settings for the production stage API. Change the percentage of traffic directed to canary deployment to 20%. Make the planned updates to the production stage. Deploy the changes 393 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 668, "question": "668 # A company has a large data workload that runs for 6 hours each day. The company cannot lose any data while the process is running. A solutions architect is designing an Amazon EMR cluster configuration to support this critical data workload. Which solution will meet these requirements MOST cost-effectively?", "options": ["A. Configure a long-running cluster that runs the primary node and core nodes on On-Demand Instances and the task nodes on Spot Instances.", "B. Configure a transient cluster that runs the primary node and core nodes on On-Demand Instances and the task nodes on Spot Instances.", "C. Configure a transient cluster that runs the primary node on an On-Demand Instance and the core nodes and task nodes on Spot Instances.", "D. Configure a long-running cluster that runs the primary node on an On-Demand Instance, the core nodes on Spot Instances, and the task nodes on Spot Instances."], "explain": "", "answers": [], "resources": []}, {"_id": 668, "question": "668 # A company has a large data workload that runs for 6 hours each day. The company cannot lose any data while the process is running. A solutions architect is designing an Amazon EMR cluster configuration to support this critical data workload. Which solution will meet these requirements MOST cost-effectively?", "options": ["A. Configure a long-running cluster that runs the primary node and core nodes on On-Demand Instances and the task nodes on Spot Instances.", "B. Configure a transient cluster that runs the primary node and core nodes on On-Demand Instances and the task nodes on Spot Instances.", "C. Configure a transient cluster that runs the primary node on an On-Demand Instance and the core nodes and task nodes on Spot Instances.", "D. Configure a long-running cluster that runs the primary node on an On-Demand Instance, the core nodes on Spot Instances, and the task nodes on Spot Instances. 394"], "explain": "", "answers": [], "resources": []}, {"_id": 669, "question": "669 # A company maintains an Amazon RDS database that maps users to cost centers. The company has accounts in an organization in AWS Organizations. The company needs a solution that will tag all resources that are created in a specific AWS account in the organization. The solution must tag each resource with the cost center ID of the user who created the resource. Which solution will meet these requirements?", "options": ["A. Move the specific AWS account to a new organizational unit (OU) in Organizations from the management account. Create a service control policy (SCP) that requires all existing resources to have the correct cost center tag before the resources are created. Apply the SCP to the new OU.", "B. Create an AWS Lambda function to tag the resources after the Lambda function looks up the appropriate cost center from the RDS database. Configure an Amazon EventBridge rule that reacts to AWS CloudTrail events to invoke the Lambda function.", "C. Create an AWS CloudFormation stack to deploy an AWS Lambda function. Configure the Lambda function to look up the appropriate cost center from the RDS database and to tag resources. Create an Amazon EventBridge scheduled rule to invoke the CloudFormation stack.", "D. Create an AWS Lambda function to tag the resources with a default value. Configure an Amazon EventBridge rule that reacts to AWS CloudTrail events to invoke the Lambda function when a resource is missing the cost center tag."], "explain": "", "answers": [], "resources": []}, {"_id": 669, "question": "669 # A company maintains an Amazon RDS database that maps users to cost centers. The company has accounts in an organization in AWS Organizations. The company needs a solution that will tag all resources that are created in a specific AWS account in the organization. The solution must tag each resource with the cost center ID of the user who created the resource. Which solution will meet these requirements?", "options": ["A. Move the specific AWS account to a new organizational unit (OU) in Organizations from the management account. Create a service control policy (SCP) that requires all existing resources to have the correct cost center tag before the resources are created. Apply the SCP to the new OU.", "B. Create an AWS Lambda function to tag the resources after the Lambda function looks up the appropriate cost center from the RDS database. Configure an Amazon EventBridge rule that reacts to AWS CloudTrail events to invoke the Lambda function.", "C. Create an AWS CloudFormation stack to deploy an AWS Lambda function. Configure the Lambda function to look up the appropriate cost center from the RDS database and to tag resources. Create an Amazon EventBridge scheduled rule to invoke the CloudFormation stack.", "D. Create an AWS Lambda function to tag the resources with a default value. Configure an Amazon EventBridge rule that reacts to AWS CloudTrail events to invoke the Lambda function when a resource is missing the cost center tag. 395"], "explain": "", "answers": [], "resources": []}, {"_id": 670, "question": "670 # A company recently migrated its web application to the AWS Cloud. The company uses an Amazon EC2 instance to run multiple processes to host the application. The processes include an Apache web server that serves static content. The Apache web server makes requests to a PHP application that uses a local Redis server for user sessions. The company wants to redesign the architecture to be highly available and to use AWS managed solutions. Which solution will meet these requirements?", "options": ["A. Use AWS Elastic Beanstalk to host the static content and the PHP application. Configure Elastic Beanstalk to deploy its EC2 instance into a public subnet. Assign a public IP address.", "B. Use AWS Lambda to host the static content and the PHP application. Use an Amazon API Gateway REST API to proxy requests to the Lambda function. Set the API Gateway CORS configuration to respond to the domain name. Configure Amazon ElastiCache for Redis to handle session information.", "C. Keep the backend code on the EC2 instance. Create an Amazon ElastiCache for Redis cluster that has Multi-AZ enabled. Configure the ElastiCache for Redis cluster in cluster mode. Copy the frontend resources to Amazon S3. Configure the backend code to reference the EC2 instance.", "D. Configure an Amazon CloudFront distribution with an Amazon S3 endpoint to an S3 bucket that is configured to host the static content. Configure an Application Load Balancer that targets an Amazon Elastic Container Service (Amazon ECS) service that runs AWS Fargate tasks for the PHP application. Configure the PHP application to use an Amazon ElastiCache for Redis cluster that runs in multiple Availability Zones."], "explain": "", "answers": [], "resources": []}, {"_id": 670, "question": "670 # A company recently migrated its web application to the AWS Cloud. The company uses an Amazon EC2 instance to run multiple processes to host the application. The processes include an Apache web server that serves static content. The Apache web server makes requests to a PHP application that uses a local Redis server for user sessions. The company wants to redesign the architecture to be highly available and to use AWS managed solutions. Which solution will meet these requirements?", "options": ["A. Use AWS Elastic Beanstalk to host the static content and the PHP application. Configure Elastic Beanstalk to deploy its EC2 instance into a public subnet. Assign a public IP address.", "B. Use AWS Lambda to host the static content and the PHP application. Use an Amazon API Gateway REST API to proxy requests to the Lambda function. Set the API Gateway CORS configuration to respond to the domain name. Configure Amazon ElastiCache for Redis to handle session information.", "C. Keep the backend code on the EC2 instance. Create an Amazon ElastiCache for Redis cluster that has Multi-AZ enabled. Configure the ElastiCache for Redis cluster in cluster mode. Copy the frontend resources to Amazon S3. Configure the backend code to reference the EC2 instance.", "D. Configure an Amazon CloudFront distribution with an Amazon S3 endpoint to an S3 bucket that is configured to host the static content. Configure an Application Load Balancer that targets an Amazon Elastic Container Service (Amazon ECS) service that runs AWS Fargate tasks for the PHP application. Configure the PHP application to use an Amazon ElastiCache for Redis cluster that runs in multiple Availability Zones. 396"], "explain": "", "answers": [], "resources": []}, {"_id": 671, "question": "671 # A company runs a web application on Amazon EC2 instances in an Auto Scaling group that has a target group. The company designed the application to work with session affinity (sticky sessions) for a better user experience. The application must be available publicly over the internet as an endpoint. A WAF must be applied to the endpoint for additional security. Session affinity (sticky sessions) must be configured on the endpoint. Which combination of steps will meet these requirements? (Choose two.)", "options": ["A. Create a public Network Load Balancer. Specify the application target group.", "B. Create a Gateway Load Balancer. Specify the application target group.", "C. Create a public Application Load Balancer. Specify the application target group.", "D. Create a second target group. Add Elastic IP addresses to the EC2 instances.", "E. Create a web ACL in AWS WAF. Associate the web ACL with the endpoint"], "explain": "", "answers": [], "resources": []}, {"_id": 671, "question": "671 # A company runs a web application on Amazon EC2 instances in an Auto Scaling group that has a target group. The company designed the application to work with session affinity (sticky sessions) for a better user experience. The application must be available publicly over the internet as an endpoint. A WAF must be applied to the endpoint for additional security. Session affinity (sticky sessions) must be configured on the endpoint. Which combination of steps will meet these requirements? (Choose two.)", "options": ["A. Create a public Network Load Balancer. Specify the application target group.", "B. Create a Gateway Load Balancer. Specify the application target group.", "C. Create a public Application Load Balancer. Specify the application target group.", "D. Create a second target group. Add Elastic IP addresses to the EC2 instances.", "E. Create a web ACL in AWS WAF. Associate the web ACL with the endpoint 397"], "explain": "", "answers": [], "resources": []}, {"_id": 672, "question": "672 # A company runs a website that stores images of historical events. Website users need the ability to search and view images based on the year that the event in the image occurred. On average, users request each image only once or twice a year. The company wants a highly available solution to store and deliver the images to users. Which solution will meet these requirements MOST cost-effectively?", "options": ["A. Store images in Amazon Elastic Block Store (Amazon EBS). Use a web server that runs on Amazon EC2.", "B. Store images in Amazon Elastic File System (Amazon EFS). Use a web server that runs on Amazon EC2.", "C. Store images in Amazon S3 Standard. Use S3 Standard to directly deliver images by using a static website.", "D. Store images in Amazon S3 Standard-Infrequent Access (S3 Standard-IA). Use S3 Standard-IA to directly deliver images by using a static website."], "explain": "", "answers": [], "resources": []}, {"_id": 672, "question": "672 # A company runs a website that stores images of historical events. Website users need the ability to search and view images based on the year that the event in the image occurred. On average, users request each image only once or twice a year. The company wants a highly available solution to store and deliver the images to users. Which solution will meet these requirements MOST cost-effectively?", "options": ["A. Store images in Amazon Elastic Block Store (Amazon EBS). Use a web server that runs on Amazon EC2.", "B. Store images in Amazon Elastic File System (Amazon EFS). Use a web server that runs on Amazon EC2.", "C. Store images in Amazon S3 Standard. Use S3 Standard to directly deliver images by using a static website.", "D. Store images in Amazon S3 Standard-Infrequent Access (S3 Standard-IA). Use S3 Standard-IA to directly deliver images by using a static website. 398"], "explain": "", "answers": [], "resources": []}, {"_id": 673, "question": "673 # A company has multiple AWS accounts in an organization in AWS Organizations that different business units use. The company has multiple offices around the world. The company needs to update security group rules to allow new office CIDR ranges or to remove old CIDR ranges across the organization. The company wants to centralize the management of security group rules to minimize the administrative overhead that updating CIDR ranges requires. Which solution will meet these requirements MOST cost-effectively?", "options": ["A. Create VPC security groups in the organization's management account. Update the security groups when a CIDR range update is necessary.", "B. Create a VPC customer managed prefix list that contains the list of CIDRs. Use AWS Resource Access Manager (AWS RAM) to share the prefix list across the organization. Use the prefix list in the security groups across the organization.", "C. Create an AWS managed prefix list. Use an AWS Security Hub policy to enforce the security group update across the organization. Use an AWS Lambda function to update the prefix list automatically when the CIDR ranges change.", "D. Create security groups in a central administrative AWS account. Create an AWS Firewall Manager common security group policy for the whole organization. Select the previously created security groups as primary groups in the policy."], "explain": "", "answers": [], "resources": []}, {"_id": 673, "question": "673 # A company has multiple AWS accounts in an organization in AWS Organizations that different business units use. The company has multiple offices around the world. The company needs to update security group rules to allow new office CIDR ranges or to remove old CIDR ranges across the organization. The company wants to centralize the management of security group rules to minimize the administrative overhead that updating CIDR ranges requires. Which solution will meet these requirements MOST cost-effectively?", "options": ["A. Create VPC security groups in the organization's management account. Update the security groups when a CIDR range update is necessary.", "B. Create a VPC customer managed prefix list that contains the list of CIDRs. Use AWS Resource Access Manager (AWS RAM) to share the prefix list across the organization. Use the prefix list in the security groups across the organization.", "C. Create an AWS managed prefix list. Use an AWS Security Hub policy to enforce the security group update across the organization. Use an AWS Lambda function to update the prefix list automatically when the CIDR ranges change.", "D. Create security groups in a central administrative AWS account. Create an AWS Firewall Manager common security group policy for the whole organization. Select the previously created security groups as primary groups in the policy. 399"], "explain": "", "answers": [], "resources": []}, {"_id": 674, "question": "674 # A company uses an on-premises network-attached storage (NAS) system to provide file shares to its high performance computing (HPC) workloads. The company wants to migrate its latency-sensitive HPC workloads and its storage to the AWS Cloud. The company must be able to provide NFS and SMB multi-protocol access from the file system. Which solution will meet these requirements with the LEAST latency? (Choose two.)", "options": ["A. Deploy compute optimized EC2 instances into a cluster placement group.Most Voted", "B. Deploy compute optimized EC2 instances into a partition placement group.", "C. Attach the EC2 instances to an Amazon FSx for Lustre file system.", "D. Attach the EC2 instances to an Amazon FSx for OpenZFS file system.", "E. Attach the EC2 instances to an Amazon FSx for NetApp ONTAP file system."], "explain": "", "answers": [], "resources": []}, {"_id": 674, "question": "674 # A company uses an on-premises network-attached storage (NAS) system to provide file shares to its high performance computing (HPC) workloads. The company wants to migrate its latency-sensitive HPC workloads and its storage to the AWS Cloud. The company must be able to provide NFS and SMB multi-protocol access from the file system. Which solution will meet these requirements with the LEAST latency? (Choose two.)", "options": ["A. Deploy compute optimized EC2 instances into a cluster placement group.Most Voted", "B. Deploy compute optimized EC2 instances into a partition placement group.", "C. Attach the EC2 instances to an Amazon FSx for Lustre file system.", "D. Attach the EC2 instances to an Amazon FSx for OpenZFS file system.", "E. Attach the EC2 instances to an Amazon FSx for NetApp ONTAP file system. 400"], "explain": "", "answers": [], "resources": []}, {"_id": 675, "question": "675 # A company is relocating its data center and wants to securely transfer 50 TB of data to AWS within 2 weeks. The existing data center has a Site-to-Site VPN connection to AWS that is 90% utilized. Which AWS service should a solutions architect use to meet these requirements?", "options": ["A. AWS DataSync with a VPC endpoint", "B. AWS Direct Connect", "C. AWS Snowball Edge Storage Optimized", "D. AWS Storage Gateway"], "explain": "", "answers": [], "resources": []}, {"_id": 675, "question": "675 # A company is relocating its data center and wants to securely transfer 50 TB of data to AWS within 2 weeks. The existing data center has a Site-to-Site VPN connection to AWS that is 90% utilized. Which AWS service should a solutions architect use to meet these requirements?", "options": ["A. AWS DataSync with a VPC endpoint", "B. AWS Direct Connect", "C. AWS Snowball Edge Storage Optimized", "D. AWS Storage Gateway 401"], "explain": "", "answers": [], "resources": []}, {"_id": 676, "question": "676 # A company hosts an application on Amazon EC2 On-Demand Instances in an Auto Scaling group. Application peak hours occur at the same time each day. Application users report slow application performance at the start of peak hours. The application performs normally 2-3 hours after peak hours begin. The company wants to ensure that the application works properly at the start of peak hours. Which solution will meet these requirements?", "options": ["A. Configure an Application Load Balancer to distribute traffic properly to the instances.", "B. Configure a dynamic scaling policy for the Auto Scaling group to launch new instances based on memory utilization.", "C. Configure a dynamic scaling policy for the Auto Scaling group to launch new instances based on CPU utilization.", "D. Configure a scheduled scaling policy for the Auto Scaling group to launch new instances before peak hours."], "explain": "", "answers": [], "resources": []}, {"_id": 676, "question": "676 # A company hosts an application on Amazon EC2 On-Demand Instances in an Auto Scaling group. Application peak hours occur at the same time each day. Application users report slow application performance at the start of peak hours. The application performs normally 2-3 hours after peak hours begin. The company wants to ensure that the application works properly at the start of peak hours. Which solution will meet these requirements?", "options": ["A. Configure an Application Load Balancer to distribute traffic properly to the instances.", "B. Configure a dynamic scaling policy for the Auto Scaling group to launch new instances based on memory utilization.", "C. Configure a dynamic scaling policy for the Auto Scaling group to launch new instances based on CPU utilization.", "D. Configure a scheduled scaling policy for the Auto Scaling group to launch new instances before peak hours. 402"], "explain": "", "answers": [], "resources": []}, {"_id": 677, "question": "677 # A company runs applications on AWS that connect to the company's Amazon RDS database. The applications scale on weekends and at peak times of the year. The company wants to scale the database more effectively for its applications that connect to the database. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Use Amazon DynamoDB with connection pooling with a target group configuration for the database. Change the applications to use the DynamoDB endpoint.", "B. Use Amazon RDS Proxy with a target group for the database. Change the applications to use the RDS Proxy endpoint.", "C. Use a custom proxy that runs on Amazon EC2 as an intermediary to the database. Change the applications to use the custom proxy endpoint.", "D. Use an AWS Lambda function to provide connection pooling with a target group configuration for the database. Change the applications to use the Lambda function."], "explain": "", "answers": [], "resources": []}, {"_id": 677, "question": "677 # A company runs applications on AWS that connect to the company's Amazon RDS database. The applications scale on weekends and at peak times of the year. The company wants to scale the database more effectively for its applications that connect to the database. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Use Amazon DynamoDB with connection pooling with a target group configuration for the database. Change the applications to use the DynamoDB endpoint.", "B. Use Amazon RDS Proxy with a target group for the database. Change the applications to use the RDS Proxy endpoint.", "C. Use a custom proxy that runs on Amazon EC2 as an intermediary to the database. Change the applications to use the custom proxy endpoint.", "D. Use an AWS Lambda function to provide connection pooling with a target group configuration for the database. Change the applications to use the Lambda function. 403"], "explain": "", "answers": [], "resources": []}, {"_id": 678, "question": "678 # A company uses AWS Cost Explorer to monitor its AWS costs. The company notices that Amazon Elastic Block Store (Amazon EBS) storage and snapshot costs increase every month. However, the company does not purchase additional EBS storage every month. The company wants to optimize monthly costs for its current storage usage. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Use logs in Amazon CloudWatch Logs to monitor the storage utilization of Amazon EBS. Use Amazon EBS Elastic Volumes to reduce the size of the EBS volumes.", "B. Use a custom script to monitor space usage. Use Amazon EBS Elastic Volumes to reduce the size of the EBS volumes.", "C. Delete all expired and unused snapshots to reduce snapshot costs.", "D. Delete all nonessential snapshots. Use Amazon Data Lifecycle Manager to create and manage the snapshots according to the company's snapshot policy requirements."], "explain": "", "answers": [], "resources": []}, {"_id": 678, "question": "678 # A company uses AWS Cost Explorer to monitor its AWS costs. The company notices that Amazon Elastic Block Store (Amazon EBS) storage and snapshot costs increase every month. However, the company does not purchase additional EBS storage every month. The company wants to optimize monthly costs for its current storage usage. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Use logs in Amazon CloudWatch Logs to monitor the storage utilization of Amazon EBS. Use Amazon EBS Elastic Volumes to reduce the size of the EBS volumes.", "B. Use a custom script to monitor space usage. Use Amazon EBS Elastic Volumes to reduce the size of the EBS volumes.", "C. Delete all expired and unused snapshots to reduce snapshot costs.", "D. Delete all nonessential snapshots. Use Amazon Data Lifecycle Manager to create and manage the snapshots according to the company's snapshot policy requirements. 404"], "explain": "", "answers": [], "resources": []}, {"_id": 679, "question": "679 # A company is developing a new application on AWS. The application consists of an Amazon Elastic Container Service (Amazon ECS) cluster, an Amazon S3 bucket that contains assets for the application, and an Amazon RDS for MySQL database that contains the dataset for the application. The dataset contains sensitive information. The company wants to ensure that only the ECS cluster can access the data in the RDS for MySQL database and the data in the S3 bucket. Which solution will meet these requirements?", "options": ["A. Create a new AWS Key Management Service (AWS KMS) customer managed key to encrypt both the S3 bucket and the RDS for MySQL database. Ensure that the KMS key policy includes encrypt and decrypt permissions for the ECS task execution role.", "B. Create an AWS Key Management Service (AWS KMS) AWS managed key to encrypt both the S3 bucket and the RDS for MySQL database. Ensure that the S3 bucket policy specifies the ECS task execution role as a user.", "C. Create an S3 bucket policy that restricts bucket access to the ECS task execution role. Create a VPC endpoint for Amazon RDS for MySQL. Update the RDS for MySQL security group to allow access from only the subnets that the ECS cluster will generate tasks in.", "D. Create a VPC endpoint for Amazon RDS for MySQL. Update the RDS for MySQL security group to allow access from only the subnets that the ECS cluster will generate tasks in. Create a VPC endpoint for Amazon S3. Update the S3 bucket policy to allow access from only the S3 VPC endpoint."], "explain": "", "answers": [], "resources": []}, {"_id": 679, "question": "679 # A company is developing a new application on AWS. The application consists of an Amazon Elastic Container Service (Amazon ECS) cluster, an Amazon S3 bucket that contains assets for the application, and an Amazon RDS for MySQL database that contains the dataset for the application. The dataset contains sensitive information. The company wants to ensure that only the ECS cluster can access the data in the RDS for MySQL database and the data in the S3 bucket. Which solution will meet these requirements?", "options": ["A. Create a new AWS Key Management Service (AWS KMS) customer managed key to encrypt both the S3 bucket and the RDS for MySQL database. Ensure that the KMS key policy includes encrypt and decrypt permissions for the ECS task execution role.", "B. Create an AWS Key Management Service (AWS KMS) AWS managed key to encrypt both the S3 bucket and the RDS for MySQL database. Ensure that the S3 bucket policy specifies the ECS task execution role as a user.", "C. Create an S3 bucket policy that restricts bucket access to the ECS task execution role. Create a VPC endpoint for Amazon RDS for MySQL. Update the RDS for MySQL security group to allow access from only the subnets that the ECS cluster will generate tasks in.", "D. Create a VPC endpoint for Amazon RDS for MySQL. Update the RDS for MySQL security group to allow access from only the subnets that the ECS cluster will generate tasks in. Create a VPC endpoint for Amazon S3. Update the S3 bucket policy to allow access from only the S3 VPC endpoint. 405"], "explain": "", "answers": [], "resources": []}, {"_id": 680, "question": "680 # A company has a web application that runs on premises. The application experiences latency issues during peak hours. The latency issues occur twice each month. At the start of a latency issue, the application's CPU utilization immediately increases to 10 times its normal amount. The company wants to migrate the application to AWS to improve latency. The company also wants to scale the application automatically when application demand increases. The company will use AWS Elastic Beanstalk for application deployment. Which solution will meet these requirements?", "options": ["A. Configure an Elastic Beanstalk environment to use burstable performance instances in unlimited mode. Configure the environment to scale based on requests.", "B. Configure an Elastic Beanstalk environment to use compute optimized instances. Configure the environment to scale based on requests.", "C. Configure an Elastic Beanstalk environment to use compute optimized instances. Configure the environment to scale on a schedule.", "D. Configure an Elastic Beanstalk environment to use burstable performance instances in unlimited mode. Configure the environment to scale on predictive metrics."], "explain": "", "answers": [], "resources": []}, {"_id": 680, "question": "680 # A company has a web application that runs on premises. The application experiences latency issues during peak hours. The latency issues occur twice each month. At the start of a latency issue, the application's CPU utilization immediately increases to 10 times its normal amount. The company wants to migrate the application to AWS to improve latency. The company also wants to scale the application automatically when application demand increases. The company will use AWS Elastic Beanstalk for application deployment. Which solution will meet these requirements?", "options": ["A. Configure an Elastic Beanstalk environment to use burstable performance instances in unlimited mode. Configure the environment to scale based on requests.", "B. Configure an Elastic Beanstalk environment to use compute optimized instances. Configure the environment to scale based on requests.", "C. Configure an Elastic Beanstalk environment to use compute optimized instances. Configure the environment to scale on a schedule.", "D. Configure an Elastic Beanstalk environment to use burstable performance instances in unlimited mode. Configure the environment to scale on predictive metrics. 406"], "explain": "", "answers": [], "resources": []}, {"_id": 681, "question": "681 # A company has customers located across the world. The company wants to use automation to secure its systems and network infrastructure. The company's security team must be able to track and audit all incremental changes to the infrastructure. Which solution will meet these requirements?", "options": ["A. Use AWS Organizations to set up the infrastructure. Use AWS Config to track changes.", "B. Use AWS CloudFormation to set up the infrastructure. Use AWS Config to track changes.", "C. Use AWS Organizations to set up the infrastructure. Use AWS Service Catalog to track changes.", "D. Use AWS CloudFormation to set up the infrastructure. Use AWS Service Catalog to track changes."], "explain": "", "answers": [], "resources": []}, {"_id": 681, "question": "681 # A company has customers located across the world. The company wants to use automation to secure its systems and network infrastructure. The company's security team must be able to track and audit all incremental changes to the infrastructure. Which solution will meet these requirements?", "options": ["A. Use AWS Organizations to set up the infrastructure. Use AWS Config to track changes.", "B. Use AWS CloudFormation to set up the infrastructure. Use AWS Config to track changes.", "C. Use AWS Organizations to set up the infrastructure. Use AWS Service Catalog to track changes.", "D. Use AWS CloudFormation to set up the infrastructure. Use AWS Service Catalog to track changes. 407"], "explain": "", "answers": [], "resources": []}, {"_id": 682, "question": "682 # A startup company is hosting a website for its customers on an Amazon EC2 instance. The website consists of a stateless Python application and a MySQL database. The website serves only a small amount of traffic. The company is concerned about the reliability of the instance and needs to migrate to a highly available architecture. The company cannot modify the application code. Which combination of actions should a solutions architect take to achieve high availability for the website? (Choose two.)", "options": ["A. Provision an internet gateway in each Availability Zone in use.", "B. Migrate the database to an Amazon RDS for MySQL Multi-AZ DB instance.", "C. Migrate the database to Amazon DynamoDB, and enable DynamoDB auto scaling.", "D. Use AWS DataSync to synchronize the database data across multiple EC2 instances.", "E. Create an Application Load Balancer to distribute traffic to an Auto Scaling group of EC2 instances that are distributed across two Availability Zones."], "explain": "", "answers": [], "resources": []}, {"_id": 682, "question": "682 # A startup company is hosting a website for its customers on an Amazon EC2 instance. The website consists of a stateless Python application and a MySQL database. The website serves only a small amount of traffic. The company is concerned about the reliability of the instance and needs to migrate to a highly available architecture. The company cannot modify the application code. Which combination of actions should a solutions architect take to achieve high availability for the website? (Choose two.)", "options": ["A. Provision an internet gateway in each Availability Zone in use.", "B. Migrate the database to an Amazon RDS for MySQL Multi-AZ DB instance.", "C. Migrate the database to Amazon DynamoDB, and enable DynamoDB auto scaling.", "D. Use AWS DataSync to synchronize the database data across multiple EC2 instances.", "E. Create an Application Load Balancer to distribute traffic to an Auto Scaling group of EC2 instances that are distributed across two Availability Zones. 408"], "explain": "", "answers": [], "resources": []}, {"_id": 683, "question": "683 # A company is moving its data and applications to AWS during a multiyear migration project. The company wants to securely access data on Amazon S3 from the company's AWS Region and from the company's on-premises location. The data must not traverse the internet. The company has established an AWS Direct Connect connection between its Region and its on-premises location. Which solution will meet these requirements?", "options": ["A. Create gateway endpoints for Amazon S3. Use the gateway endpoints to securely access the data from the Region and the on-premises location.", "B. Create a gateway in AWS Transit Gateway to access Amazon S3 securely from the Region and the on-premises location.", "C. Create interface endpoints for Amazon S3. Use the interface endpoints to securely access the data from the Region and the on-premises location.", "D. Use an AWS Key Management Service (AWS KMS) key to access the data securely from the Region and the on-premises location."], "explain": "", "answers": [], "resources": []}, {"_id": 683, "question": "683 # A company is moving its data and applications to AWS during a multiyear migration project. The company wants to securely access data on Amazon S3 from the company's AWS Region and from the company's on-premises location. The data must not traverse the internet. The company has established an AWS Direct Connect connection between its Region and its on-premises location. Which solution will meet these requirements?", "options": ["A. Create gateway endpoints for Amazon S3. Use the gateway endpoints to securely access the data from the Region and the on-premises location.", "B. Create a gateway in AWS Transit Gateway to access Amazon S3 securely from the Region and the on-premises location.", "C. Create interface endpoints for Amazon S3. Use the interface endpoints to securely access the data from the Region and the on-premises location.", "D. Use an AWS Key Management Service (AWS KMS) key to access the data securely from the Region and the on-premises location. 409"], "explain": "", "answers": [], "resources": []}, {"_id": 684, "question": "684 # A company created a new organization in AWS Organizations. The organization has multiple accounts for the company's development teams. The development team members use AWS IAM Identity Center (AWS Single Sign-On) to access the accounts. For each of the company's applications, the development teams must use a predefined application name to tag resources that are created. A solutions architect needs to design a solution that gives the development team the ability to create resources only if the application name tag has an approved value. Which solution will meet these requirements?", "options": ["A. Create an IAM group that has a conditional Allow policy that requires the application name tag to be specified for resources to be created.", "B. Create a cross-account role that has a Deny policy for any resource that has the application name tag.", "C. Create a resource group in AWS Resource Groups to validate that the tags are applied to all resources in all accounts.", "D. Create a tag policy in Organizations that has a list of allowed application names."], "explain": "", "answers": [], "resources": []}, {"_id": 684, "question": "684 # A company created a new organization in AWS Organizations. The organization has multiple accounts for the company's development teams. The development team members use AWS IAM Identity Center (AWS Single Sign-On) to access the accounts. For each of the company's applications, the development teams must use a predefined application name to tag resources that are created. A solutions architect needs to design a solution that gives the development team the ability to create resources only if the application name tag has an approved value. Which solution will meet these requirements?", "options": ["A. Create an IAM group that has a conditional Allow policy that requires the application name tag to be specified for resources to be created.", "B. Create a cross-account role that has a Deny policy for any resource that has the application name tag.", "C. Create a resource group in AWS Resource Groups to validate that the tags are applied to all resources in all accounts.", "D. Create a tag policy in Organizations that has a list of allowed application names. 410"], "explain": "", "answers": [], "resources": []}, {"_id": 685, "question": "685 # A company runs its databases on Amazon RDS for PostgreSQL. The company wants a secure solution to manage the master user password by rotating the password every 30 days. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Use Amazon EventBridge to schedule a custom AWS Lambda function to rotate the password every 30 days.", "B. Use the modify-db-instance command in the AWS CLI to change the password.", "C. Integrate AWS Secrets Manager with Amazon RDS for PostgreSQL to automate password rotation.", "D. Integrate AWS Systems Manager Parameter Store with Amazon RDS for PostgreSQL to automate password rotation."], "explain": "", "answers": [], "resources": []}, {"_id": 685, "question": "685 # A company runs its databases on Amazon RDS for PostgreSQL. The company wants a secure solution to manage the master user password by rotating the password every 30 days. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Use Amazon EventBridge to schedule a custom AWS Lambda function to rotate the password every 30 days.", "B. Use the modify-db-instance command in the AWS CLI to change the password.", "C. Integrate AWS Secrets Manager with Amazon RDS for PostgreSQL to automate password rotation.", "D. Integrate AWS Systems Manager Parameter Store with Amazon RDS for PostgreSQL to automate password rotation. 411"], "explain": "", "answers": [], "resources": []}, {"_id": 686, "question": "686 # A company performs tests on an application that uses an Amazon DynamoDB table. The tests run for 4 hours once a week. The company knows how many read and write operations the application performs to the table each second during the tests. The company does not currently use DynamoDB for any other use case. A solutions architect needs to optimize the costs for the table. Which solution will meet these requirements?", "options": ["A. Choose on-demand mode. Update the read and write capacity units appropriately.", "B. Choose provisioned mode. Update the read and write capacity units appropriately.", "C. Purchase DynamoDB reserved capacity for a 1-year term.", "D. Purchase DynamoDB reserved capacity for a 3-year term."], "explain": "", "answers": [], "resources": []}, {"_id": 686, "question": "686 # A company performs tests on an application that uses an Amazon DynamoDB table. The tests run for 4 hours once a week. The company knows how many read and write operations the application performs to the table each second during the tests. The company does not currently use DynamoDB for any other use case. A solutions architect needs to optimize the costs for the table. Which solution will meet these requirements?", "options": ["A. Choose on-demand mode. Update the read and write capacity units appropriately.", "B. Choose provisioned mode. Update the read and write capacity units appropriately.", "C. Purchase DynamoDB reserved capacity for a 1-year term.", "D. Purchase DynamoDB reserved capacity for a 3-year term. 412"], "explain": "", "answers": [], "resources": []}, {"_id": 687, "question": "687 # A company runs its applications on Amazon EC2 instances. The company performs periodic financial assessments of its AWS costs. The company recently identified unusual spending. The company needs a solution to prevent unusual spending. The solution must monitor costs and notify responsible stakeholders in the event of unusual spending. Which solution will meet these requirements?", "options": ["A. Use an AWS Budgets template to create a zero spend budget.", "B. Create an AWS Cost Anomaly Detection monitor in the AWS Billing and Cost Management console.", "C. Create AWS Pricing Calculator estimates for the current running workload pricing details.", "D. Use Amazon CloudWatch to monitor costs and to identify unusual spending."], "explain": "", "answers": [], "resources": []}, {"_id": 687, "question": "687 # A company runs its applications on Amazon EC2 instances. The company performs periodic financial assessments of its AWS costs. The company recently identified unusual spending. The company needs a solution to prevent unusual spending. The solution must monitor costs and notify responsible stakeholders in the event of unusual spending. Which solution will meet these requirements?", "options": ["A. Use an AWS Budgets template to create a zero spend budget.", "B. Create an AWS Cost Anomaly Detection monitor in the AWS Billing and Cost Management console.", "C. Create AWS Pricing Calculator estimates for the current running workload pricing details.", "D. Use Amazon CloudWatch to monitor costs and to identify unusual spending. 413"], "explain": "", "answers": [], "resources": []}, {"_id": 688, "question": "688 # A marketing company receives a large amount of new clickstream data in Amazon S3 from a marketing campaign. The company needs to analyze the clickstream data in Amazon S3 quickly. Then the company needs to determine whether to process the data further in the data pipeline. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Create external tables in a Spark catalog. Configure jobs in AWS Glue to query the data.", "B. Configure an AWS Glue crawler to crawl the data. Configure Amazon Athena to query the data.", "C. Create external tables in a Hive metastore. Configure Spark jobs in Amazon EMR to query the data.", "D. Configure an AWS Glue crawler to crawl the data. Configure Amazon Kinesis Data Analytics to use SQL to query the data."], "explain": "", "answers": [], "resources": []}, {"_id": 688, "question": "688 # A marketing company receives a large amount of new clickstream data in Amazon S3 from a marketing campaign. The company needs to analyze the clickstream data in Amazon S3 quickly. Then the company needs to determine whether to process the data further in the data pipeline. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Create external tables in a Spark catalog. Configure jobs in AWS Glue to query the data.", "B. Configure an AWS Glue crawler to crawl the data. Configure Amazon Athena to query the data.", "C. Create external tables in a Hive metastore. Configure Spark jobs in Amazon EMR to query the data.", "D. Configure an AWS Glue crawler to crawl the data. Configure Amazon Kinesis Data Analytics to use SQL to query the data. 414"], "explain": "", "answers": [], "resources": []}, {"_id": 689, "question": "689 # A company runs an SMB file server in its data center. The file server stores large files that the company frequently accesses for up to 7 days after the file creation date. After 7 days, the company needs to be able to access the files with a maximum retrieval time of 24 hours. Which solution will meet these requirements?", "options": ["A. Use AWS DataSync to copy data that is older than 7 days from the SMB file server to AWS.", "B. Create an Amazon S3 File Gateway to increase the company's storage space. Create an S3 Lifecycle policy to transition the data to S3 Glacier Deep Archive after 7 days.", "C. Create an Amazon FSx File Gateway to increase the company's storage space. Create an Amazon S3 Lifecycle policy to transition the data after 7 days.", "D. Configure access to Amazon S3 for each user. Create an S3 Lifecycle policy to transition the data to S3 Glacier Flexible Retrieval after 7 days."], "explain": "", "answers": [], "resources": []}, {"_id": 689, "question": "689 # A company runs an SMB file server in its data center. The file server stores large files that the company frequently accesses for up to 7 days after the file creation date. After 7 days, the company needs to be able to access the files with a maximum retrieval time of 24 hours. Which solution will meet these requirements?", "options": ["A. Use AWS DataSync to copy data that is older than 7 days from the SMB file server to AWS.", "B. Create an Amazon S3 File Gateway to increase the company's storage space. Create an S3 Lifecycle policy to transition the data to S3 Glacier Deep Archive after 7 days.", "C. Create an Amazon FSx File Gateway to increase the company's storage space. Create an Amazon S3 Lifecycle policy to transition the data after 7 days.", "D. Configure access to Amazon S3 for each user. Create an S3 Lifecycle policy to transition the data to S3 Glacier Flexible Retrieval after 7 days. 415"], "explain": "", "answers": [], "resources": []}, {"_id": 690, "question": "690 # A company runs a web application on Amazon EC2 instances in an Auto Scaling group. The application uses a database that runs on an Amazon RDS for PostgreSQL DB instance. The application performs slowly when traffic increases. The database experiences a heavy read load during periods of high traffic. Which actions should a solutions architect take to resolve these performance issues? (Choose two.)", "options": ["A. Turn on auto scaling for the DB instance.", "B. Create a read replica for the DB instance. Configure the application to send read traffic to the read replica.", "C. Convert the DB instance to a Multi-AZ DB instance deployment. Configure the application to send read traffic to the standby DB instance.", "D. Create an Amazon ElastiCache cluster. Configure the application to cache query results in the ElastiCache cluster.", "E. Configure the Auto Scaling group subnets to ensure that the EC2 instances are provisioned in the same Availability Zone as the DB instance."], "explain": "", "answers": [], "resources": []}, {"_id": 690, "question": "690 # A company runs a web application on Amazon EC2 instances in an Auto Scaling group. The application uses a database that runs on an Amazon RDS for PostgreSQL DB instance. The application performs slowly when traffic increases. The database experiences a heavy read load during periods of high traffic. Which actions should a solutions architect take to resolve these performance issues? (Choose two.)", "options": ["A. Turn on auto scaling for the DB instance.", "B. Create a read replica for the DB instance. Configure the application to send read traffic to the read replica.", "C. Convert the DB instance to a Multi-AZ DB instance deployment. Configure the application to send read traffic to the standby DB instance.", "D. Create an Amazon ElastiCache cluster. Configure the application to cache query results in the ElastiCache cluster.", "E. Configure the Auto Scaling group subnets to ensure that the EC2 instances are provisioned in the same Availability Zone as the DB instance. 416"], "explain": "", "answers": [], "resources": []}, {"_id": 691, "question": "691 # A company uses Amazon EC2 instances and Amazon Elastic Block Store (Amazon EBS) volumes to run an application. The company creates one snapshot of each EBS volume every day to meet compliance requirements. The company wants to implement an architecture that prevents the accidental deletion of EBS volume snapshots. The solution must not change the administrative rights of the storage administrator user. Which solution will meet these requirements with the LEAST administrative effort?", "options": ["A. Create an IAM role that has permission to delete snapshots. Attach the role to a new EC2 instance. Use the AWS CLI from the new EC2 instance to delete snapshots.", "B. Create an IAM policy that denies snapshot deletion. Attach the policy to the storage administrator user.", "C. Add tags to the snapshots. Create retention rules in Recycle Bin for EBS snapshots that have the tags.", "D. Lock the EBS snapshots to prevent deletion."], "explain": "", "answers": [], "resources": []}, {"_id": 691, "question": "691 # A company uses Amazon EC2 instances and Amazon Elastic Block Store (Amazon EBS) volumes to run an application. The company creates one snapshot of each EBS volume every day to meet compliance requirements. The company wants to implement an architecture that prevents the accidental deletion of EBS volume snapshots. The solution must not change the administrative rights of the storage administrator user. Which solution will meet these requirements with the LEAST administrative effort?", "options": ["A. Create an IAM role that has permission to delete snapshots. Attach the role to a new EC2 instance. Use the AWS CLI from the new EC2 instance to delete snapshots.", "B. Create an IAM policy that denies snapshot deletion. Attach the policy to the storage administrator user.", "C. Add tags to the snapshots. Create retention rules in Recycle Bin for EBS snapshots that have the tags.", "D. Lock the EBS snapshots to prevent deletion. 417"], "explain": "", "answers": [], "resources": []}, {"_id": 692, "question": "692 # A company's application uses Network Load Balancers, Auto Scaling groups, Amazon EC2 instances, and databases that are deployed in an Amazon VPC. The company wants to capture information about traffic to and from the network interfaces in near real time in its Amazon VPC. The company wants to send the information to Amazon OpenSearch Service for analysis. Which solution will meet these requirements?", "options": ["A. Create a log group in Amazon CloudWatch Logs. Configure VPC Flow Logs to send the log data to the log group. Use Amazon Kinesis Data Streams to stream the logs from the log group to OpenSearch Service.", "B. Create a log group in Amazon CloudWatch Logs. Configure VPC Flow Logs to send the log data to the log group. Use Amazon Kinesis Data Firehose to stream the logs from the log group to OpenSearch Service.", "C. Create a trail in AWS CloudTrail. Configure VPC Flow Logs to send the log data to the trail. Use Amazon Kinesis Data Streams to stream the logs from the trail to OpenSearch Service.", "D. Create a trail in AWS CloudTrail. Configure VPC Flow Logs to send the log data to the trail. Use Amazon Kinesis Data Firehose to stream the logs from the trail to OpenSearch Service."], "explain": "", "answers": [], "resources": []}, {"_id": 692, "question": "692 # A company's application uses Network Load Balancers, Auto Scaling groups, Amazon EC2 instances, and databases that are deployed in an Amazon VPC. The company wants to capture information about traffic to and from the network interfaces in near real time in its Amazon VPC. The company wants to send the information to Amazon OpenSearch Service for analysis. Which solution will meet these requirements?", "options": ["A. Create a log group in Amazon CloudWatch Logs. Configure VPC Flow Logs to send the log data to the log group. Use Amazon Kinesis Data Streams to stream the logs from the log group to OpenSearch Service.", "B. Create a log group in Amazon CloudWatch Logs. Configure VPC Flow Logs to send the log data to the log group. Use Amazon Kinesis Data Firehose to stream the logs from the log group to OpenSearch Service.", "C. Create a trail in AWS CloudTrail. Configure VPC Flow Logs to send the log data to the trail. Use Amazon Kinesis Data Streams to stream the logs from the trail to OpenSearch Service.", "D. Create a trail in AWS CloudTrail. Configure VPC Flow Logs to send the log data to the trail. Use Amazon Kinesis Data Firehose to stream the logs from the trail to OpenSearch Service. 418"], "explain": "", "answers": [], "resources": []}, {"_id": 693, "question": "693 # A company is developing an application that will run on a production Amazon Elastic Kubernetes Service (Amazon EKS) cluster. The EKS cluster has managed node groups that are provisioned with On-Demand Instances. The company needs a dedicated EKS cluster for development work. The company will use the development cluster infrequently to test the resiliency of the application. The EKS cluster must manage all the nodes. Which solution will meet these requirements MOST cost-effectively?", "options": ["A. Create a managed node group that contains only Spot Instances.", "B. Create two managed node groups. Provision one node group with On-Demand Instances. Provision the second node group with Spot Instances.", "C. Create an Auto Scaling group that has a launch configuration that uses Spot Instances. Configure the user data to add the nodes to the EKS cluster.", "D. Create a managed node group that contains only On-Demand Instances."], "explain": "", "answers": [], "resources": []}, {"_id": 693, "question": "693 # A company is developing an application that will run on a production Amazon Elastic Kubernetes Service (Amazon EKS) cluster. The EKS cluster has managed node groups that are provisioned with On-Demand Instances. The company needs a dedicated EKS cluster for development work. The company will use the development cluster infrequently to test the resiliency of the application. The EKS cluster must manage all the nodes. Which solution will meet these requirements MOST cost-effectively?", "options": ["A. Create a managed node group that contains only Spot Instances.", "B. Create two managed node groups. Provision one node group with On-Demand Instances. Provision the second node group with Spot Instances.", "C. Create an Auto Scaling group that has a launch configuration that uses Spot Instances. Configure the user data to add the nodes to the EKS cluster.", "D. Create a managed node group that contains only On-Demand Instances. 419"], "explain": "", "answers": [], "resources": []}, {"_id": 694, "question": "694 # A company stores sensitive data in Amazon S3. A solutions architect needs to create an encryption solution. The company needs to fully control the ability of users to create, rotate, and disable encryption keys with minimal effort for any data that must be encrypted. Which solution will meet these requirements?", "options": ["A. Use default server-side encryption with Amazon S3 managed encryption keys (SSE-S3) to store the sensitive data.", "B. Create a customer managed key by using AWS Key Management Service (AWS KMS). Use the new key to encrypt the S3 objects by using server-side encryption with AWS KMS keys (SSE-KMS).", "C. Create an AWS managed key by using AWS Key Management Service (AWS KMS). Use the new key to encrypt the S3 objects by using server-side encryption with AWS KMS keys (SSE-KMS).", "D. Download S3 objects to an Amazon EC2 instance. Encrypt the objects by using customer managed keys. Upload the encrypted objects back into Amazon S3."], "explain": "", "answers": [], "resources": []}, {"_id": 694, "question": "694 # A company stores sensitive data in Amazon S3. A solutions architect needs to create an encryption solution. The company needs to fully control the ability of users to create, rotate, and disable encryption keys with minimal effort for any data that must be encrypted. Which solution will meet these requirements?", "options": ["A. Use default server-side encryption with Amazon S3 managed encryption keys (SSE-S3) to store the sensitive data.", "B. Create a customer managed key by using AWS Key Management Service (AWS KMS). Use the new key to encrypt the S3 objects by using server-side encryption with AWS KMS keys (SSE-KMS).", "C. Create an AWS managed key by using AWS Key Management Service (AWS KMS). Use the new key to encrypt the S3 objects by using server-side encryption with AWS KMS keys (SSE-KMS).", "D. Download S3 objects to an Amazon EC2 instance. Encrypt the objects by using customer managed keys. Upload the encrypted objects back into Amazon S3. 420"], "explain": "", "answers": [], "resources": []}, {"_id": 695, "question": "695 # A company wants to back up its on-premises virtual machines (VMs) to AWS. The company's backup solution exports on-premises backups to an Amazon S3 bucket as objects. The S3 backups must be retained for 30 days and must be automatically deleted after 30 days. Which combination of steps will meet these requirements? (Choose three.)", "options": ["A. Create an S3 bucket that has S3 Object Lock enabled.", "B. Create an S3 bucket that has object versioning enabled.", "C. Configure a default retention period of 30 days for the objects.", "D. Configure an S3 Lifecycle policy to protect the objects for 30 days.", "E. Configure an S3 Lifecycle policy to expire the objects after 30 days.", "F. Configure the backup solution to tag the objects with a 30-day retention period"], "explain": "", "answers": [], "resources": []}]