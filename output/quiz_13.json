[{"_id": 630, "question": "630# A company is designing a new multi-tier web application that consists of the following components: \u2022 Web and application servers that run on Amazon EC2 instances as part of Auto Scaling groups. \u2022 An Amazon RDS DB instance for data storage. A solutions architect needs to limit access to the application servers so that only the web servers can access them. Which solution will meet these requirements?", "options": ["A. Deploy AWS PrivateLink in front of the application servers. Configure the network ACL to allow only the web servers to access the application servers.", "B. Deploy a VPC endpoint in front of the application servers. Configure the security group to allow only the web servers to access the application servers.", "C. Deploy a Network Load Balancer with a target group that contains the application servers' Auto Scaling group. Configure the network ACL to allow only the web servers to access the application servers.", "D. Deploy an Application Load Balancer with a target group that contains the application servers' Auto Scaling group. Configure the security group to allow only the web servers to access the application servers. 356 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 631, "question": "631# A company runs a critical, customer-facing application on Amazon Elastic Kubernetes Service (Amazon EKS). The application has a microservices architecture. The company needs to implement a solution that collects, aggregates, and summarizes metrics and logs from the application in a centralized location. Which solution meets these requirements?", "options": ["A. Run the Amazon CloudWatch agent in the existing EKS cluster. View the metrics and logs in the CloudWatch console.", "B. Run AWS App Mesh in the existing EKS cluster. View the metrics and logs in the App Mesh console.", "C. Configure AWS CloudTrail to capture data events. Query CloudTrail by using Amazon OpenSearch Service.", "D. Configure Amazon CloudWatch Container Insights in the existing EKS cluster. View the metrics and logs in the CloudWatch console. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 631, "question": "631# A company runs a critical, customer-facing application on Amazon Elastic Kubernetes Service (Amazon EKS). The application has a microservices architecture. The company needs to implement a solution that collects, aggregates, and summarizes metrics and logs from the application in a centralized location. Which solution meets these requirements?", "options": ["A. Run the Amazon CloudWatch agent in the existing EKS cluster. View the metrics and logs in the CloudWatch console.", "B. Run AWS App Mesh in the existing EKS cluster. View the metrics and logs in the App Mesh console.", "C. Configure AWS CloudTrail to capture data events. Query CloudTrail by using Amazon OpenSearch Service.", "D. Configure Amazon CloudWatch Container Insights in the existing EKS cluster. View the metrics and logs in the CloudWatch console. 357 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 632, "question": "632# A company has deployed its newest product on AWS. The product runs in an Auto Scaling group behind a Network Load Balancer. The company stores the product\u2019s objects in an Amazon S3 bucket. The company recently experienced malicious attacks against its systems. The company needs a solution that continuously monitors for malicious activity in the AWS account, workloads, and access patterns to the S3 bucket. The solution must also report suspicious activity and display the information on a dashboard. Which solution will meet these requirements?", "options": ["A. Configure Amazon Macie to monitor and report findings to AWS Config.", "B. Configure Amazon Inspector to monitor and report findings to AWS CloudTrail.", "C. Configure Amazon GuardDuty to monitor and report findings to AWS Security Hub.", "D. Configure AWS Config to monitor and report findings to Amazon EventBridge. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 632, "question": "632# A company has deployed its newest product on AWS. The product runs in an Auto Scaling group behind a Network Load Balancer. The company stores the product\u2019s objects in an Amazon S3 bucket. The company recently experienced malicious attacks against its systems. The company needs a solution that continuously monitors for malicious activity in the AWS account, workloads, and access patterns to the S3 bucket. The solution must also report suspicious activity and display the information on a dashboard. Which solution will meet these requirements?", "options": ["A. Configure Amazon Macie to monitor and report findings to AWS Config.", "B. Configure Amazon Inspector to monitor and report findings to AWS CloudTrail.", "C. Configure Amazon GuardDuty to monitor and report findings to AWS Security Hub.", "D. Configure AWS Config to monitor and report findings to Amazon EventBridge. 358 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 633, "question": "633# A company wants to migrate an on-premises data center to AWS. The data center hosts a storage server that stores data in an NFS-based file system. The storage server holds 200 GB of data. The company needs to migrate the data without interruption to existing services. Multiple resources in AWS must be able to access the data by using the NFS protocol. Which combination of steps will meet these requirements MOST cost- effectively? (Choose two.)", "options": ["A. Create an Amazon FSx for Lustre file system.", "B. Create an Amazon Elastic File System (Amazon EFS) file system.", "C. Create an Amazon S3 bucket to receive the data.", "D. Manually use an operating system copy command to push the data into the AWS destination.", "E. Install an AWS DataSync agent in the on-premises data center. Use a DataSync task between the on-premises location and AWS. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 633, "question": "633# A company wants to migrate an on-premises data center to AWS. The data center hosts a storage server that stores data in an NFS-based file system. The storage server holds 200 GB of data. The company needs to migrate the data without interruption to existing services. Multiple resources in AWS must be able to access the data by using the NFS protocol. Which combination of steps will meet these requirements MOST cost- effectively? (Choose two.)", "options": ["A. Create an Amazon FSx for Lustre file system.", "B. Create an Amazon Elastic File System (Amazon EFS) file system.", "C. Create an Amazon S3 bucket to receive the data.", "D. Manually use an operating system copy command to push the data into the AWS destination.", "E. Install an AWS DataSync agent in the on-premises data center. Use a DataSync task between the on-premises location and AWS. 359 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 634, "question": "634# A company wants to use Amazon FSx for Windows File Server for its Amazon EC2 instances that have an SMB file share mounted as a volume in the us-east-1 Region. The company has a recovery point objective (RPO) of 5 minutes for planned system maintenance or unplanned service disruptions. The company needs to replicate the file system to the us-west-2 Region. The replicated data must not be deleted by any user for 5 years. Which solution will meet these requirements?", "options": ["A. Create an FSx for Windows File Server file system in us-east-1 that has a Single-AZ 2 deployment type. Use AWS Backup to create a daily backup plan that includes a backup rule that copies the backup to us-west-2. Configure AWS Backup Vault Lock in compliance mode for a target vault in us-west-2. Configure a minimum duration of 5 years.", "B. Create an FSx for Windows File Server file system in us-east-1 that has a Multi-AZ deployment type. Use AWS Backup to create a daily backup plan that includes a backup rule that copies the backup to us-west-2. Configure AWS Backup Vault Lock in governance mode for a target vault in us-west-2. Configure a minimum duration of 5 years.", "C. Create an FSx for Windows File Server file system in us-east-1 that has a Multi-AZ deployment type. Use AWS Backup to create a daily backup plan that includes a backup rule that copies the backup to us-west-2. Configure AWS Backup Vault Lock in compliance mode for a target vault in us-west-2. Configure a minimum duration of 5 years.", "D. Create an FSx for Windows File Server file system in us-east-1 that has a Single-AZ 2 deployment type. Use AWS Backup to create a daily backup plan that includes a backup rule that copies the backup to us-west-2. Configure AWS Backup Vault Lock in governance mode for a target vault in us-west-2. Configure a minimum duration of 5 years. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 634, "question": "634# A company wants to use Amazon FSx for Windows File Server for its Amazon EC2 instances that have an SMB file share mounted as a volume in the us-east-1 Region. The company has a recovery point objective (RPO) of 5 minutes for planned system maintenance or unplanned service disruptions. The company needs to replicate the file system to the us-west-2 Region. The replicated data must not be deleted by any user for 5 years. Which solution will meet these requirements?", "options": ["A. Create an FSx for Windows File Server file system in us-east-1 that has a Single-AZ 2 deployment type. Use AWS Backup to create a daily backup plan that includes a backup rule that copies the backup to us-west-2. Configure AWS Backup Vault Lock in compliance mode for a target vault in us-west-2. Configure a minimum duration of 5 years.", "B. Create an FSx for Windows File Server file system in us-east-1 that has a Multi-AZ deployment type. Use AWS Backup to create a daily backup plan that includes a backup rule that copies the backup to us-west-2. Configure AWS Backup Vault Lock in governance mode for a target vault in us-west-2. Configure a minimum duration of 5 years.", "C. Create an FSx for Windows File Server file system in us-east-1 that has a Multi-AZ deployment type. Use AWS Backup to create a daily backup plan that includes a backup rule that copies the backup to us-west-2. Configure AWS Backup Vault Lock in compliance mode for a target vault in us-west-2. Configure a minimum duration of 5 years.", "D. Create an FSx for Windows File Server file system in us-east-1 that has a Single-AZ 2 deployment type. Use AWS Backup to create a daily backup plan that includes a backup rule that copies the backup to us-west-2. Configure AWS Backup Vault Lock in governance mode for a target vault in us-west-2. Configure a minimum duration of 5 years. 360 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 635, "question": "635# A solutions architect is designing a security solution for a company that wants to provide developers with individual AWS accounts through AWS Organizations, while also maintaining standard security controls. Because the individual developers will have AWS account root user-level access to their own accounts, the solutions architect wants to ensure that the mandatory AWS CloudTrail configuration that is applied to new developer accounts is not modified. Which action meets these requirements?", "options": ["A. Create an IAM policy that prohibits changes to CloudTrail. and attach it to the root user.", "B. Create a new trail in CloudTrail from within the developer accounts with the organization trails option enabled.", "C. Create a service control policy (SCP) that prohibits changes to CloudTrail, and attach it the developer accounts.", "D. Create a service-linked role for CloudTrail with a policy condition that allows changes only from an Amazon Resource Name (ARN) in the management account. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 635, "question": "635# A solutions architect is designing a security solution for a company that wants to provide developers with individual AWS accounts through AWS Organizations, while also maintaining standard security controls. Because the individual developers will have AWS account root user-level access to their own accounts, the solutions architect wants to ensure that the mandatory AWS CloudTrail configuration that is applied to new developer accounts is not modified. Which action meets these requirements?", "options": ["A. Create an IAM policy that prohibits changes to CloudTrail. and attach it to the root user.", "B. Create a new trail in CloudTrail from within the developer accounts with the organization trails option enabled.", "C. Create a service control policy (SCP) that prohibits changes to CloudTrail, and attach it the developer accounts.", "D. Create a service-linked role for CloudTrail with a policy condition that allows changes only from an Amazon Resource Name (ARN) in the management account. 361 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 636, "question": "636# A company is planning to deploy a business-critical application in the AWS Cloud. The application requires durable storage with consistent, low- latency performance. Which type of storage should a solutions architect recommend to meet these requirements?", "options": ["A. Instance store volume", "B. Amazon ElastiCache for Memcached cluster", "C. Provisioned IOPS SSD Amazon Elastic Block Store (Amazon EBS) volume", "D. Throughput Optimized HDD Amazon Elastic Block Store (Amazon EBS) volume sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 636, "question": "636# A company is planning to deploy a business-critical application in the AWS Cloud. The application requires durable storage with consistent, low- latency performance. Which type of storage should a solutions architect recommend to meet these requirements?", "options": [], "explain": "", "answers": [], "resources": []}, {"_id": 636, "question": "636# A company is planning to deploy a business-critical application in the AWS Cloud. The application requires durable storage with consistent, low- latency performance. Which type of storage should a solutions architect recommend to meet these requirements? A. Instance store volume B. Amazon ElastiCache for Memcached cluster C. Provisioned IOPS SSD Amazon Elastic Block Store (Amazon EBS) volume D. Throughput Optimized HDD Amazon Elastic Block Store (Amazon EBS) volume 362 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com 637# An online photo-sharing company stores its photos in an Amazon S3 bucket that exists in the us-west-1 Region. The company needs to store a copy of all new photos in the us-east-1 Region. Which solution will meet this requirement with the LEAST operational effort?", "options": [], "explain": "", "answers": [], "resources": []}, {"_id": 636, "question": "636# A company is planning to deploy a business-critical application in the AWS Cloud. The application requires durable storage with consistent, low- latency performance. Which type of storage should a solutions architect recommend to meet these requirements? A. Instance store volume B. Amazon ElastiCache for Memcached cluster C. Provisioned IOPS SSD Amazon Elastic Block Store (Amazon EBS) volume D. Throughput Optimized HDD Amazon Elastic Block Store (Amazon EBS) volume 362 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com 637# An online photo-sharing company stores its photos in an Amazon S3 bucket that exists in the us-west-1 Region. The company needs to store a copy of all new photos in the us-east-1 Region. Which solution will meet this requirement with the LEAST operational effort? A. Create a second S3 bucket in us-east-1. Use S3 Cross-Region Replication to copy photos from the existing S3 bucket to the second S3 bucket. B. Create a cross-origin resource sharing (CORS) configuration of the existing S3 bucket. Specify us-east-1 in the CORS rule's AllowedOrigin element. C. Create a second S3 bucket in us-east-1 across multiple Availability Zones. Create an S3 Lifecycle rule to save photos into the second S3 bucket. D. Create a second S3 bucket in us-east-1. Configure S3 event notifications on object creation and update events to invoke an AWS Lambda function to copy photos from the existing S3 bucket to the second S3 bucket. sthithapragnasya@gmail.com 637# An online photo-sharing company stores its photos in an Amazon S3 bucket that exists in the us-west-1 Region. The company needs to store a copy of all new photos in the us-east-1 Region. Which solution will meet this requirement with the LEAST operational effort?", "options": ["A. Instance store volume", "B. Amazon ElastiCache for Memcached cluster", "C. Provisioned IOPS SSD Amazon Elastic Block Store (Amazon EBS) volume", "A. Create a second S3 bucket in us-east-1. Use S3 Cross-Region Replication to copy photos from the existing S3 bucket to the second S3 bucket.", "B. Create a cross-origin resource sharing (CORS) configuration of the existing S3 bucket. Specify us-east-1 in the CORS rule's AllowedOrigin element.", "C. Create a second S3 bucket in us-east-1 across multiple Availability Zones. Create an S3 Lifecycle rule to save photos into the second S3 bucket.", "A. Create a second S3 bucket in us-east-1. Use S3 Cross-Region Replication to copy photos from the existing S3 bucket to the second S3 bucket.", "B. Create a cross-origin resource sharing (CORS) configuration of the existing S3 bucket. Specify us-east-1 in the CORS rule's AllowedOrigin element.", "C. Create a second S3 bucket in us-east-1 across multiple Availability Zones. Create an S3 Lifecycle rule to save photos into the second S3 bucket.", "D. Create a second S3 bucket in us-east-1. Configure S3 event notifications on object creation and update events to invoke an AWS Lambda function to copy photos from the existing S3 bucket to the second S3 bucket. 363 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 638, "question": "638# A company is creating a new web application for its subscribers. The application will consist of a static single page and a persistent database layer. The application will have millions of users for 4 hours in the morning, but the application will have only a few thousand users during the rest of the day. The company's data architects have requested the ability to rapidly evolve their schema. Which solutions will meet these requirements and provide the MOST scalability? (Choose two.)", "options": ["A. Deploy Amazon DynamoDB as the database solution. Provision on-demand capacity.", "B. Deploy Amazon Aurora as the database solution. Choose the serverless DB engine mode.", "C. Deploy Amazon DynamoDB as the database solution. Ensure that DynamoDB auto scaling is enabled.", "D. Deploy the static content into an Amazon S3 bucket. Provision an Amazon CloudFront distribution with the S3 bucket as the origin.", "E. Deploy the web servers for static content across a fleet of Amazon EC2 instances in Auto Scaling groups. Configure the instances to periodically refresh the content from an Amazon Elastic File System (Amazon EFS) volume. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 638, "question": "638# A company is creating a new web application for its subscribers. The application will consist of a static single page and a persistent database layer. The application will have millions of users for 4 hours in the morning, but the application will have only a few thousand users during the rest of the day. The company's data architects have requested the ability to rapidly evolve their schema. Which solutions will meet these requirements and provide the MOST scalability? (Choose two.)", "options": ["A. Deploy Amazon DynamoDB as the database solution. Provision on-demand capacity.", "B. Deploy Amazon Aurora as the database solution. Choose the serverless DB engine mode.", "C. Deploy Amazon DynamoDB as the database solution. Ensure that DynamoDB auto scaling is enabled.", "D. Deploy the static content into an Amazon S3 bucket. Provision an Amazon CloudFront distribution with the S3 bucket as the origin.", "E. Deploy the web servers for static content across a fleet of Amazon EC2 instances in Auto Scaling groups. Configure the instances to periodically refresh the content from an Amazon Elastic File System (Amazon EFS) volume. 364 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 639, "question": "639# A company uses Amazon API Gateway to manage its REST APIs that third-party service providers access. The company must protect the REST APIs from SQL injection and cross-site scripting attacks. What is the MOST operationally efficient solution that meets these requirements?", "options": ["A. Configure AWS Shield.", "B. Configure AWS WAF.", "C. Set up API Gateway with an Amazon CloudFront distribution. Configure AWS Shield in CloudFront.", "D. Set up API Gateway with an Amazon CloudFront distribution. Configure AWS WAF in CloudFront. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 639, "question": "639# A company uses Amazon API Gateway to manage its REST APIs that third-party service providers access. The company must protect the REST APIs from SQL injection and cross-site scripting attacks. What is the MOST operationally efficient solution that meets these requirements?", "options": ["A. Configure AWS Shield.", "B. Configure AWS WAF.", "C. Set up API Gateway with an Amazon CloudFront distribution. Configure AWS Shield in CloudFront.", "D. Set up API Gateway with an Amazon CloudFront distribution. Configure AWS WAF in CloudFront. 365 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 640, "question": "640# A company wants to provide users with access to AWS resources. The company has 1,500 users and manages their access to on-premises resources through Active Directory user groups on the corporate network. However, the company does not want users to have to maintain another identity to access the resources. A solutions architect must manage user access to the AWS resources while preserving access to the on-premises resources. What should the solutions architect do to meet these requirements?", "options": ["A. Create an IAM user for each user in the company. Attach the appropriate policies to each user.", "B. Use Amazon Cognito with an Active Directory user pool. Create roles with the appropriate policies attached.", "C. Define cross-account roles with the appropriate policies attached. Map the roles to the Active Directory groups.", "D. Configure Security Assertion Markup Language (SAML) 2 0-based federation. Create roles with the appropriate policies attached Map the roles to the Active Directory groups. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 640, "question": "640# A company wants to provide users with access to AWS resources. The company has 1,500 users and manages their access to on-premises resources through Active Directory user groups on the corporate network. However, the company does not want users to have to maintain another identity to access the resources. A solutions architect must manage user access to the AWS resources while preserving access to the on-premises resources. What should the solutions architect do to meet these requirements?", "options": ["A. Create an IAM user for each user in the company. Attach the appropriate policies to each user.", "B. Use Amazon Cognito with an Active Directory user pool. Create roles with the appropriate policies attached.", "C. Define cross-account roles with the appropriate policies attached. Map the roles to the Active Directory groups.", "D. Configure Security Assertion Markup Language (SAML) 2 0-based federation. Create roles with the appropriate policies attached Map the roles to the Active Directory groups. 366 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 641, "question": "641# A company is hosting a website behind multiple Application Load Balancers. The company has different distribution rights for its content around the world. A solutions architect needs to ensure that users are served the correct content without violating distribution rights.Which configuration should the solutions architect choose to meet these requirements?", "options": ["A. Configure Amazon CloudFront with AWS WAF.", "B. Configure Application Load Balancers with AWS WAF", "C. Configure Amazon Route 53 with a geolocation policy", "D. Configure Amazon Route 53 with a geoproximity routing policy sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 641, "question": "641# A company is hosting a website behind multiple Application Load Balancers. The company has different distribution rights for its content around the world. A solutions architect needs to ensure that users are served the correct content without violating distribution rights.Which configuration should the solutions architect choose to meet these requirements?", "options": ["A. Configure Amazon CloudFront with AWS WAF.", "B. Configure Application Load Balancers with AWS WAF", "C. Configure Amazon Route 53 with a geolocation policy", "D. Configure Amazon Route 53 with a geoproximity routing policy 367 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 642, "question": "642# A company stores its data on premises. The amount of data is growing beyond the company's available capacity. The company wants to migrate its data from the on-premises location to an Amazon S3 bucket. The company needs a solution that will automatically validate the integrity of the data after the transfer. Which solution will meet these requirements?", "options": ["A. Order an AWS Snowball Edge device. Configure the Snowball Edge device to perform the online data transfer to an S3 bucket", "B. Deploy an AWS DataSync agent on premises. Configure the DataSync agent to perform the online data transfer to an S3 bucket.", "C. Create an Amazon S3 File Gateway on premises Configure the S3 File Gateway to perform the online data transfer to an S3 bucket", "D. Configure an accelerator in Amazon S3 Transfer Acceleration on premises. Configure the accelerator to perform the online data transfer to an S3 bucket. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 642, "question": "642# A company stores its data on premises. The amount of data is growing beyond the company's available capacity. The company wants to migrate its data from the on-premises location to an Amazon S3 bucket. The company needs a solution that will automatically validate the integrity of the data after the transfer. Which solution will meet these requirements?", "options": ["A. Order an AWS Snowball Edge device. Configure the Snowball Edge device to perform the online data transfer to an S3 bucket", "B. Deploy an AWS DataSync agent on premises. Configure the DataSync agent to perform the online data transfer to an S3 bucket.", "C. Create an Amazon S3 File Gateway on premises Configure the S3 File Gateway to perform the online data transfer to an S3 bucket", "D. Configure an accelerator in Amazon S3 Transfer Acceleration on premises. Configure the accelerator to perform the online data transfer to an S3 bucket. 368 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 643, "question": "643# A company wants to migrate two DNS servers to AWS. The servers host a total of approximately 200 zones and receive 1 million requests each day on average. The company wants to maximize availability while minimizing the operational overhead that is related to the management of the two servers. What should a solutions architect recommend to meet these requirements?", "options": ["A. Create 200 new hosted zones in the Amazon Route 53 console Import zone files.", "B. Launch a single large Amazon EC2 instance Import zone tiles. Configure Amazon CloudWatch alarms and notifications to alert the company about any downtime.", "C. Migrate the servers to AWS by using AWS Server Migration Service (AWS SMS). Configure Amazon CloudWatch alarms and notifications to alert the company about any downtime.", "D. Launch an Amazon EC2 instance in an Auto Scaling group across two Availability Zones. Import zone files. Set the desired capacity to 1 and the maximum capacity to 3 for the Auto Scaling group. Configure scaling alarms to scale based on CPU utilization. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 643, "question": "643# A company wants to migrate two DNS servers to AWS. The servers host a total of approximately 200 zones and receive 1 million requests each day on average. The company wants to maximize availability while minimizing the operational overhead that is related to the management of the two servers. What should a solutions architect recommend to meet these requirements?", "options": ["A. Create 200 new hosted zones in the Amazon Route 53 console Import zone files.", "B. Launch a single large Amazon EC2 instance Import zone tiles. Configure Amazon CloudWatch alarms and notifications to alert the company about any downtime.", "C. Migrate the servers to AWS by using AWS Server Migration Service (AWS SMS). Configure Amazon CloudWatch alarms and notifications to alert the company about any downtime.", "D. Launch an Amazon EC2 instance in an Auto Scaling group across two Availability Zones. Import zone files. Set the desired capacity to 1 and the maximum capacity to 3 for the Auto Scaling group. Configure scaling alarms to scale based on CPU utilization. 369 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 644, "question": "644# A global company runs its applications in multiple AWS accounts in AWS Organizations. The company's applications use multipart uploads to upload data to multiple Amazon S3 buckets across AWS Regions. The company wants to report on incomplete multipart uploads for cost compliance purposes. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Configure AWS Config with a rule to report the incomplete multipart upload object count.", "B. Create a service control policy (SCP) to report the incomplete multipart upload object count.", "C. Configure S3 Storage Lens to report the incomplete multipart upload object count.", "D. Create an S3 Multi-Region Access Point to report the incomplete multipart upload object count. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 644, "question": "644# A global company runs its applications in multiple AWS accounts in AWS Organizations. The company's applications use multipart uploads to upload data to multiple Amazon S3 buckets across AWS Regions. The company wants to report on incomplete multipart uploads for cost compliance purposes. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Configure AWS Config with a rule to report the incomplete multipart upload object count.", "B. Create a service control policy (SCP) to report the incomplete multipart upload object count.", "C. Configure S3 Storage Lens to report the incomplete multipart upload object count.", "D. Create an S3 Multi-Region Access Point to report the incomplete multipart upload object count. 370 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 645, "question": "645# A company runs a production database on Amazon RDS for MySQL. The company wants to upgrade the database version for security compliance reasons. Because the database contains critical data, the company wants a quick solution to upgrade and test functionality without losing any data. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Create an RDS manual snapshot. Upgrade to the new version of Amazon RDS for MySQL.", "B. Use native backup and restore. Restore the data to the upgraded new version of Amazon RDS for MySQL.", "C. Use AWS Database Migration Service (AWS DMS) to replicate the data to the upgraded new version of Amazon RDS for MySQL.", "D. Use Amazon RDS Blue/Green Deployments to deploy and test production changes. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 645, "question": "645# A company runs a production database on Amazon RDS for MySQL. The company wants to upgrade the database version for security compliance reasons. Because the database contains critical data, the company wants a quick solution to upgrade and test functionality without losing any data. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Create an RDS manual snapshot. Upgrade to the new version of Amazon RDS for MySQL.", "B. Use native backup and restore. Restore the data to the upgraded new version of Amazon RDS for MySQL.", "C. Use AWS Database Migration Service (AWS DMS) to replicate the data to the upgraded new version of Amazon RDS for MySQL.", "D. Use Amazon RDS Blue/Green Deployments to deploy and test production changes. 371 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 646, "question": "646# A solutions architect is creating a data processing job that runs once daily and can take up to 2 hours to complete. If the job is interrupted, it has to restart from the beginning. How should the solutions architect address this issue in the MOST cost-effective manner?", "options": ["A. Create a script that runs locally on an Amazon EC2 Reserved Instance that is triggered by a cron job.", "B. Create an AWS Lambda function triggered by an Amazon EventBridge scheduled event.", "C. Use an Amazon Elastic Container Service (Amazon ECS) Fargate task triggered by an Amazon EventBridge scheduled event.", "D. Use an Amazon Elastic Container Service (Amazon ECS) task running on Amazon EC2 triggered by an Amazon EventBridge scheduled event. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 646, "question": "646# A solutions architect is creating a data processing job that runs once daily and can take up to 2 hours to complete. If the job is interrupted, it has to restart from the beginning. How should the solutions architect address this issue in the MOST cost-effective manner?", "options": ["A. Create a script that runs locally on an Amazon EC2 Reserved Instance that is triggered by a cron job.", "B. Create an AWS Lambda function triggered by an Amazon EventBridge scheduled event.", "C. Use an Amazon Elastic Container Service (Amazon ECS) Fargate task triggered by an Amazon EventBridge scheduled event.", "D. Use an Amazon Elastic Container Service (Amazon ECS) task running on Amazon EC2 triggered by an Amazon EventBridge scheduled event. 372 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 647, "question": "647# A social media company wants to store its database of user profiles, relationships, and interactions in the AWS Cloud. The company needs an application to monitor any changes in the database. The application needs to analyze the relationships between the data entities and to provide recommendations to users. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Use Amazon Neptune to store the information. Use Amazon Kinesis Data Streams to process changes in the database.", "B. Use Amazon Neptune to store the information. Use Neptune Streams to process changes in the database.", "C. Use Amazon Quantum Ledger Database (Amazon QLDB) to store the information. Use Amazon Kinesis Data Streams to process changes in the database.", "D. Use Amazon Quantum Ledger Database (Amazon QLDB) to store the information. Use Neptune Streams to process changes in the database. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 647, "question": "647# A social media company wants to store its database of user profiles, relationships, and interactions in the AWS Cloud. The company needs an application to monitor any changes in the database. The application needs to analyze the relationships between the data entities and to provide recommendations to users. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Use Amazon Neptune to store the information. Use Amazon Kinesis Data Streams to process changes in the database.", "B. Use Amazon Neptune to store the information. Use Neptune Streams to process changes in the database.", "C. Use Amazon Quantum Ledger Database (Amazon QLDB) to store the information. Use Amazon Kinesis Data Streams to process changes in the database.", "D. Use Amazon Quantum Ledger Database (Amazon QLDB) to store the information. Use Neptune Streams to process changes in the database. 373 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 648, "question": "648# A company is creating a new application that will store a large amount of data. The data will be analyzed hourly and will be modified by several Amazon EC2 Linux instances that are deployed across multiple Availability Zones. The needed amount of storage space will continue to grow for the next 6 months. Which storage solution should a solutions architect recommend to meet these requirements?", "options": ["A. Store the data in Amazon S3 Glacier. Update the S3 Glacier vault policy to allow access to the application instances.", "B. Store the data in an Amazon Elastic Block Store (Amazon EBS) volume. Mount the EBS volume on the application instances.", "C. Store the data in an Amazon Elastic File System (Amazon EFS) file system. Mount the file system on the application instances.", "D. Store the data in an Amazon Elastic Block Store (Amazon EBS) Provisioned IOPS volume shared between the application instances. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 648, "question": "648# A company is creating a new application that will store a large amount of data. The data will be analyzed hourly and will be modified by several Amazon EC2 Linux instances that are deployed across multiple Availability Zones. The needed amount of storage space will continue to grow for the next 6 months. Which storage solution should a solutions architect recommend to meet these requirements?", "options": ["A. Store the data in Amazon S3 Glacier. Update the S3 Glacier vault policy to allow access to the application instances.", "B. Store the data in an Amazon Elastic Block Store (Amazon EBS) volume. Mount the EBS volume on the application instances.", "C. Store the data in an Amazon Elastic File System (Amazon EFS) file system. Mount the file system on the application instances.", "D. Store the data in an Amazon Elastic Block Store (Amazon EBS) Provisioned IOPS volume shared between the application instances. 374 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 649, "question": "649# A company manages an application that stores data on an Amazon RDS for PostgreSQL Multi-AZ DB instance. Increases in traffic are causing performance problems. The company determines that database queries are the primary reason for the slow performance. What should a solutions architect do to improve the application's performance?", "options": ["A. Serve read traffic from the Multi-AZ standby replica.", "B. Configure the DB instance to use Transfer Acceleration.", "C. Create a read replica from the source DB instance. Serve read traffic from the read replica.", "D. Use Amazon Kinesis Data Firehose between the application and Amazon RDS to increase the concurrency of database requests. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 649, "question": "649# A company manages an application that stores data on an Amazon RDS for PostgreSQL Multi-AZ DB instance. Increases in traffic are causing performance problems. The company determines that database queries are the primary reason for the slow performance. What should a solutions architect do to improve the application's performance?", "options": ["A. Serve read traffic from the Multi-AZ standby replica.", "B. Configure the DB instance to use Transfer Acceleration.", "C. Create a read replica from the source DB instance. Serve read traffic from the read replica.", "D. Use Amazon Kinesis Data Firehose between the application and Amazon RDS to increase the concurrency of database requests. 375 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 650, "question": "650# A company collects 10 GB of telemetry data daily from various machines. The company stores the data in an Amazon S3 bucket in a source data account. The company has hired several consulting agencies to use this data for analysis. Each agency needs read access to the data for its analysts. The company must share the data from the source data account by choosing a solution that maximizes security and operational efficiency. Which solution will meet these requirements?", "options": ["A. Configure S3 global tables to replicate data for each agency.", "B. Make the S3 bucket public for a limited time. Inform only the agencies.", "C. Configure cross-account access for the S3 bucket to the accounts that the agencies own.", "D. Set up an IAM user for each analyst in the source data account. Grant each user access to the S3 bucket. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 650, "question": "650# A company collects 10 GB of telemetry data daily from various machines. The company stores the data in an Amazon S3 bucket in a source data account. The company has hired several consulting agencies to use this data for analysis. Each agency needs read access to the data for its analysts. The company must share the data from the source data account by choosing a solution that maximizes security and operational efficiency. Which solution will meet these requirements?", "options": ["A. Configure S3 global tables to replicate data for each agency.", "B. Make the S3 bucket public for a limited time. Inform only the agencies.", "C. Configure cross-account access for the S3 bucket to the accounts that the agencies own.", "D. Set up an IAM user for each analyst in the source data account. Grant each user access to the S3 bucket. 376 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 651, "question": "651# A company uses Amazon FSx for NetApp ONTAP in its primary AWS Region for CIFS and NFS file shares. Applications that run on Amazon EC2 instances access the file shares. The company needs a storage disaster recovery (DR) solution in a secondary Region. The data that is replicated in the secondary Region needs to be accessed by using the same protocols as the primary Region. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Create an AWS Lambda function to copy the data to an Amazon S3 bucket. Replicate the S3 bucket to the secondary Region.", "B. Create a backup of the FSx for ONTAP volumes by using AWS Backup. Copy the volumes to the secondary Region. Create a new FSx for ONTAP instance from the backup.", "C. Create an FSx for ONTAP instance in the secondary Region. Use NetApp SnapMirror to replicate data from the primary Region to the secondary Region.", "D. Create an Amazon Elastic File System (Amazon EFS) volume. Migrate the current data to the volume. Replicate the volume to the secondary Region. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 651, "question": "651# A company uses Amazon FSx for NetApp ONTAP in its primary AWS Region for CIFS and NFS file shares. Applications that run on Amazon EC2 instances access the file shares. The company needs a storage disaster recovery (DR) solution in a secondary Region. The data that is replicated in the secondary Region needs to be accessed by using the same protocols as the primary Region. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Create an AWS Lambda function to copy the data to an Amazon S3 bucket. Replicate the S3 bucket to the secondary Region.", "B. Create a backup of the FSx for ONTAP volumes by using AWS Backup. Copy the volumes to the secondary Region. Create a new FSx for ONTAP instance from the backup.", "C. Create an FSx for ONTAP instance in the secondary Region. Use NetApp SnapMirror to replicate data from the primary Region to the secondary Region.", "D. Create an Amazon Elastic File System (Amazon EFS) volume. Migrate the current data to the volume. Replicate the volume to the secondary Region. 377 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 652, "question": "652# A development team is creating an event-based application that uses AWS Lambda functions. Events will be generated when files are added to an Amazon S3 bucket. The development team currently has Amazon Simple Notification Service (Amazon SNS) configured as the event target from Amazon S3. What should a solutions architect do to process the events from Amazon S3 in a scalable way?", "options": ["A. Create an SNS subscription that processes the event in Amazon Elastic Container Service (Amazon ECS) before the event runs in Lambda.", "B. Create an SNS subscription that processes the event in Amazon Elastic Kubernetes Service (Amazon EKS) before the event runs in Lambda", "C. Create an SNS subscription that sends the event to Amazon Simple Queue Service (Amazon SQS). Configure the SOS queue to trigger a Lambda function.", "D. Create an SNS subscription that sends the event to AWS Server Migration Service (AWS SMS). Configure the Lambda function to poll from the SMS event. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 652, "question": "652# A development team is creating an event-based application that uses AWS Lambda functions. Events will be generated when files are added to an Amazon S3 bucket. The development team currently has Amazon Simple Notification Service (Amazon SNS) configured as the event target from Amazon S3. What should a solutions architect do to process the events from Amazon S3 in a scalable way?", "options": ["A. Create an SNS subscription that processes the event in Amazon Elastic Container Service (Amazon ECS) before the event runs in Lambda.", "B. Create an SNS subscription that processes the event in Amazon Elastic Kubernetes Service (Amazon EKS) before the event runs in Lambda", "C. Create an SNS subscription that sends the event to Amazon Simple Queue Service (Amazon SQS). Configure the SOS queue to trigger a Lambda function.", "D. Create an SNS subscription that sends the event to AWS Server Migration Service (AWS SMS). Configure the Lambda function to poll from the SMS event. 378 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 653, "question": "653# A solutions architect is designing a new service behind Amazon API Gateway. The request patterns for the service will be unpredictable and can change suddenly from 0 requests to over 500 per second. The total size of the data that needs to be persisted in a backend database is currently less than 1 GB with unpredictable future growth. Data can be queried using simple key- value requests. Which combination of AWS services would meet these requirements? (Choose two.)", "options": ["A. AWS Fargate", "B. AWS Lambda", "C. Amazon DynamoDB", "D. Amazon EC2 Auto Scaling", "E. MySQL-compatible Amazon Aurora sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 653, "question": "653# A solutions architect is designing a new service behind Amazon API Gateway. The request patterns for the service will be unpredictable and can change suddenly from 0 requests to over 500 per second. The total size of the data that needs to be persisted in a backend database is currently less than 1 GB with unpredictable future growth. Data can be queried using simple key- value requests. Which combination of AWS services would meet these requirements? (Choose two.)", "options": ["A. AWS Fargate", "B. AWS Lambda", "C. Amazon DynamoDB", "D. Amazon EC2 Auto Scaling", "E. MySQL-compatible Amazon Aurora 379 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 654, "question": "654# A company collects and shares research data with the company's employees all over the world. The company wants to collect and store the data in an Amazon S3 bucket and process the data in the AWS Cloud. The company will share the data with the company's employees. The company needs a secure solution in the AWS Cloud that minimizes operational overhead. Which solution will meet these requirements?", "options": ["A. Use an AWS Lambda function to create an S3 presigned URL. Instruct employees to use the URL.", "B. Create an IAM user for each employee. Create an IAM policy for each employee to allow S3 access. Instruct employees to use the AWS Management Console.", "C. Create an S3 File Gateway. Create a share for uploading and a share for downloading. Allow employees to mount shares on their local computers to use S3 File Gateway.", "D. Configure AWS Transfer Family SFTP endpoints. Select the custom identity provider options. Use AWS Secrets Manager to manage the user credentials Instruct employees to use Transfer Family. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 654, "question": "654# A company collects and shares research data with the company's employees all over the world. The company wants to collect and store the data in an Amazon S3 bucket and process the data in the AWS Cloud. The company will share the data with the company's employees. The company needs a secure solution in the AWS Cloud that minimizes operational overhead. Which solution will meet these requirements?", "options": ["A. Use an AWS Lambda function to create an S3 presigned URL. Instruct employees to use the URL.", "B. Create an IAM user for each employee. Create an IAM policy for each employee to allow S3 access. Instruct employees to use the AWS Management Console.", "C. Create an S3 File Gateway. Create a share for uploading and a share for downloading. Allow employees to mount shares on their local computers to use S3 File Gateway.", "D. Configure AWS Transfer Family SFTP endpoints. Select the custom identity provider options. Use AWS Secrets Manager to manage the user credentials Instruct employees to use Transfer Family. 380 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 655, "question": "655# A company is building a new furniture inventory application. The company has deployed the application on a fleet of Amazon EC2 instances across multiple Availability Zones. The EC2 instances run behind an Application Load Balancer (ALB) in their VPC. A solutions architect has observed that incoming traffic seems to favor one EC2 instance, resulting in latency for some requests. What should the solutions architect do to resolve this issue?", "options": ["A. Disable session affinity (sticky sessions) on the ALB", "B. Replace the ALB with a Network Load Balancer", "C. Increase the number of EC2 instances in each Availability Zone", "D. Adjust the frequency of the health checks on the ALB's target group sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 655, "question": "655# A company is building a new furniture inventory application. The company has deployed the application on a fleet of Amazon EC2 instances across multiple Availability Zones. The EC2 instances run behind an Application Load Balancer (ALB) in their VPC. A solutions architect has observed that incoming traffic seems to favor one EC2 instance, resulting in latency for some requests. What should the solutions architect do to resolve this issue?", "options": ["A. Disable session affinity (sticky sessions) on the ALB", "B. Replace the ALB with a Network Load Balancer", "C. Increase the number of EC2 instances in each Availability Zone", "D. Adjust the frequency of the health checks on the ALB's target group 381 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 656, "question": "656# A company has an application workflow that uses an AWS Lambda function to download and decrypt files from Amazon S3. These files are encrypted using AWS Key Management Service (AWS KMS) keys. A solutions architect needs to design a solution that will ensure the required permissions are set correctly. Which combination of actions accomplish this? (Choose two.)", "options": ["A. Attach the kms:decrypt permission to the Lambda function\u2019s resource policy", "B. Grant the decrypt permission for the Lambda IAM role in the KMS key's policy", "C. Grant the decrypt permission for the Lambda resource policy in the KMS key's policy.", "D. Create a new IAM policy with the kms:decrypt permission and attach the policy to the Lambda function.", "E. Create a new IAM role with the kms:decrypt permission and attach the execution role to the Lambda function. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 656, "question": "656# A company has an application workflow that uses an AWS Lambda function to download and decrypt files from Amazon S3. These files are encrypted using AWS Key Management Service (AWS KMS) keys. A solutions architect needs to design a solution that will ensure the required permissions are set correctly. Which combination of actions accomplish this? (Choose two.)", "options": ["A. Attach the kms:decrypt permission to the Lambda function\u2019s resource policy", "B. Grant the decrypt permission for the Lambda IAM role in the KMS key's policy", "C. Grant the decrypt permission for the Lambda resource policy in the KMS key's policy.", "D. Create a new IAM policy with the kms:decrypt permission and attach the policy to the Lambda function.", "E. Create a new IAM role with the kms:decrypt permission and attach the execution role to the Lambda function. 382 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 657, "question": "657# A company wants to monitor its AWS costs for financial review. The cloud operations team is designing an architecture in the AWS Organizations management account to query AWS Cost and Usage Reports for all member accounts. The team must run this query once a month and provide a detailed analysis of the bill. Which solution is the MOST scalable and cost-effective way to meet these requirements?", "options": ["A. Enable Cost and Usage Reports in the management account. Deliver reports to Amazon Kinesis. Use Amazon EMR for analysis.", "B. Enable Cost and Usage Reports in the management account. Deliver the reports to Amazon S3 Use Amazon Athena for analysis.", "C. Enable Cost and Usage Reports for member accounts. Deliver the reports to Amazon S3 Use Amazon Redshift for analysis.", "D. Enable Cost and Usage Reports for member accounts. Deliver the reports to Amazon Kinesis. Use Amazon QuickSight tor analysis. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 657, "question": "657# A company wants to monitor its AWS costs for financial review. The cloud operations team is designing an architecture in the AWS Organizations management account to query AWS Cost and Usage Reports for all member accounts. The team must run this query once a month and provide a detailed analysis of the bill. Which solution is the MOST scalable and cost-effective way to meet these requirements?", "options": ["A. Enable Cost and Usage Reports in the management account. Deliver reports to Amazon Kinesis. Use Amazon EMR for analysis.", "B. Enable Cost and Usage Reports in the management account. Deliver the reports to Amazon S3 Use Amazon Athena for analysis.", "C. Enable Cost and Usage Reports for member accounts. Deliver the reports to Amazon S3 Use Amazon Redshift for analysis.", "D. Enable Cost and Usage Reports for member accounts. Deliver the reports to Amazon Kinesis. Use Amazon QuickSight tor analysis. 383 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 658, "question": "658# A company wants to run a gaming application on Amazon EC2 instances that are part of an Auto Scaling group in the AWS Cloud. The application will transmit data by using UDP packets. The company wants to ensure that the application can scale out and in as traffic increases and decreases. What should a solutions architect do to meet these requirements?", "options": ["A. Attach a Network Load Balancer to the Auto Scaling group.", "B. Attach an Application Load Balancer to the Auto Scaling group.", "C. Deploy an Amazon Route 53 record set with a weighted policy to route traffic appropriately.", "D. Deploy a NAT instance that is configured with port forwarding to the EC2 instances in the Auto Scaling group. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 658, "question": "658# A company wants to run a gaming application on Amazon EC2 instances that are part of an Auto Scaling group in the AWS Cloud. The application will transmit data by using UDP packets. The company wants to ensure that the application can scale out and in as traffic increases and decreases. What should a solutions architect do to meet these requirements?", "options": ["A. Attach a Network Load Balancer to the Auto Scaling group.", "B. Attach an Application Load Balancer to the Auto Scaling group.", "C. Deploy an Amazon Route 53 record set with a weighted policy to route traffic appropriately.", "D. Deploy a NAT instance that is configured with port forwarding to the EC2 instances in the Auto Scaling group. 384 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 659, "question": "659# A company runs several websites on AWS for its different brands. Each website generates tens of gigabytes of web traffic logs each day. A solutions architect needs to design a scalable solution to give the company's developers the ability to analyze traffic patterns across all the company's websites. This analysis by the developers will occur on demand once a week over the course of several months. The solution must support queries with standard SQL. Which solution will meet these requirements MOST cost-effectively?", "options": ["A. Store the logs in Amazon S3. Use Amazon Athena tor analysis.", "B. Store the logs in Amazon RDS. Use a database client for analysis.", "C. Store the logs in Amazon OpenSearch Service. Use OpenSearch Service for analysis.", "D. Store the logs in an Amazon EMR cluster Use a supported open-source framework for SQL- based analysis. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 659, "question": "659# A company runs several websites on AWS for its different brands. Each website generates tens of gigabytes of web traffic logs each day. A solutions architect needs to design a scalable solution to give the company's developers the ability to analyze traffic patterns across all the company's websites. This analysis by the developers will occur on demand once a week over the course of several months. The solution must support queries with standard SQL. Which solution will meet these requirements MOST cost-effectively?", "options": [], "explain": "", "answers": [], "resources": []}, {"_id": 659, "question": "659# A company runs several websites on AWS for its different brands. Each website generates tens of gigabytes of web traffic logs each day. A solutions architect needs to design a scalable solution to give the company's developers the ability to analyze traffic patterns across all the company's websites. This analysis by the developers will occur on demand once a week over the course of several months. The solution must support queries with standard SQL. Which solution will meet these requirements MOST cost-effectively? A. Store the logs in Amazon S3. Use Amazon Athena tor analysis. B. Store the logs in Amazon RDS. Use a database client for analysis. C. Store the logs in Amazon OpenSearch Service. Use OpenSearch Service for analysis. D. Store the logs in an Amazon EMR cluster Use a supported open-source framework for SQL- based analysis. 385 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com 660# An international company has a subdomain for each country that the company operates in. The subdomains are formatted as example.com, country1.example.com, and country2.example.com. The company's workloads are behind an Application Load Balancer. The company wants to encrypt the website data that is in transit. Which combination of steps will meet these requirements? (Choose two.)", "options": [], "explain": "", "answers": [], "resources": []}, {"_id": 659, "question": "659# A company runs several websites on AWS for its different brands. Each website generates tens of gigabytes of web traffic logs each day. A solutions architect needs to design a scalable solution to give the company's developers the ability to analyze traffic patterns across all the company's websites. This analysis by the developers will occur on demand once a week over the course of several months. The solution must support queries with standard SQL. Which solution will meet these requirements MOST cost-effectively? A. Store the logs in Amazon S3. Use Amazon Athena tor analysis. B. Store the logs in Amazon RDS. Use a database client for analysis. C. Store the logs in Amazon OpenSearch Service. Use OpenSearch Service for analysis. D. Store the logs in an Amazon EMR cluster Use a supported open-source framework for SQL- based analysis. 385 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com 660# An international company has a subdomain for each country that the company operates in. The subdomains are formatted as example.com, country1.example.com, and country2.example.com. The company's workloads are behind an Application Load Balancer. The company wants to encrypt the website data that is in transit. Which combination of steps will meet these requirements? (Choose two.) A. Use the AWS Certificate Manager (ACM) console to request a public certificate for the apex top domain example com and a wildcard certificate for *.example.com. B. Use the AWS Certificate Manager (ACM) console to request a private certificate for the apex top domain example.com and a wildcard certificate for *.example.com. C. Use the AWS Certificate Manager (ACM) console to request a public and private certificate for the apex top domain example.com. D. Validate domain ownership by email address. Switch to DNS validation by adding the required DNS records to the DNS provider. E. Validate domain ownership for the domain by adding the required DNS records to the DNS provider. sthithapragnasya@gmail.com 660# An international company has a subdomain for each country that the company operates in. The subdomains are formatted as example.com, country1.example.com, and country2.example.com. The company's workloads are behind an Application Load Balancer. The company wants to encrypt the website data that is in transit. Which combination of steps will meet these requirements? (Choose two.)", "options": ["A. Store the logs in Amazon S3. Use Amazon Athena tor analysis.", "B. Store the logs in Amazon RDS. Use a database client for analysis.", "C. Store the logs in Amazon OpenSearch Service. Use OpenSearch Service for analysis.", "A. Use the AWS Certificate Manager (ACM) console to request a public certificate for the apex top domain example com and a wildcard certificate for *.example.com.", "B. Use the AWS Certificate Manager (ACM) console to request a private certificate for the apex top domain example.com and a wildcard certificate for *.example.com.", "C. Use the AWS Certificate Manager (ACM) console to request a public and private certificate for the apex top domain example.com.", "D. Validate domain ownership by email address. Switch to DNS validation by adding the required DNS records to the DNS provider.", "A. Use the AWS Certificate Manager (ACM) console to request a public certificate for the apex top domain example com and a wildcard certificate for *.example.com.", "B. Use the AWS Certificate Manager (ACM) console to request a private certificate for the apex top domain example.com and a wildcard certificate for *.example.com.", "C. Use the AWS Certificate Manager (ACM) console to request a public and private certificate for the apex top domain example.com.", "D. Validate domain ownership by email address. Switch to DNS validation by adding the required DNS records to the DNS provider.", "E. Validate domain ownership for the domain by adding the required DNS records to the DNS provider. 386 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 661, "question": "661# A company is required to use cryptographic keys in its on-premises key manager. The key manager is outside of the AWS Cloud because of regulatory and compliance requirements. The company wants to manage encryption and decryption by using cryptographic keys that are retained outside of the AWS Cloud and that support a variety of external key managers from different vendors. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Use AWS CloudHSM key store backed by a CloudHSM cluster.", "B. Use an AWS Key Management Service (AWS KMS) external key store backed by an external key manager.", "C. Use the default AWS Key Management Service (AWS KMS) managed key store.", "D. Use a custom key store backed by an AWS CloudHSM cluster. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 661, "question": "661# A company is required to use cryptographic keys in its on-premises key manager. The key manager is outside of the AWS Cloud because of regulatory and compliance requirements. The company wants to manage encryption and decryption by using cryptographic keys that are retained outside of the AWS Cloud and that support a variety of external key managers from different vendors. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Use AWS CloudHSM key store backed by a CloudHSM cluster.", "B. Use an AWS Key Management Service (AWS KMS) external key store backed by an external key manager.", "C. Use the default AWS Key Management Service (AWS KMS) managed key store.", "D. Use a custom key store backed by an AWS CloudHSM cluster. 387 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 662, "question": "662# A solutions architect needs to host a high performance computing (HPC) workload in the AWS Cloud. The workload will run on hundreds of Amazon EC2 instances and will require parallel access to a shared file system to enable distributed processing of large datasets. Datasets will be accessed across multiple instances simultaneously. The workload requires access latency within 1 ms. After processing has completed, engineers will need access to the dataset for manual postprocessing. Which solution will meet these requirements?", "options": ["A. Use Amazon Elastic File System (Amazon EFS) as a shared file system. Access the dataset from Amazon EFS.", "B. Mount an Amazon S3 bucket to serve as the shared file system. Perform postprocessing directly from the S3 bucket.", "C. Use Amazon FSx for Lustre as a shared file system. Link the file system to an Amazon S3 bucket for postprocessing.", "D. Configure AWS Resource Access Manager to share an Amazon S3 bucket so that it can be mounted to all instances for processing and postprocessing. sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}, {"_id": 662, "question": "662# A solutions architect needs to host a high performance computing (HPC) workload in the AWS Cloud. The workload will run on hundreds of Amazon EC2 instances and will require parallel access to a shared file system to enable distributed processing of large datasets. Datasets will be accessed across multiple instances simultaneously. The workload requires access latency within 1 ms. After processing has completed, engineers will need access to the dataset for manual postprocessing. Which solution will meet these requirements?", "options": ["A. Use Amazon Elastic File System (Amazon EFS) as a shared file system. Access the dataset from Amazon EFS.", "B. Mount an Amazon S3 bucket to serve as the shared file system. Perform postprocessing directly from the S3 bucket.", "C. Use Amazon FSx for Lustre as a shared file system. Link the file system to an Amazon S3 bucket for postprocessing.", "D. Configure AWS Resource Access Manager to share an Amazon S3 bucket so that it can be mounted to all instances for processing and postprocessing. 388 mailto:sthithapragnasya@gmail.com mailto:sthithapragnasya@gmail.com sthithapragnasya@gmail.com"], "explain": "", "answers": [], "resources": []}]