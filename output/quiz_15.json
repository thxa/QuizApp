[{"_id": 695, "question": "695 # A company wants to back up its on-premises virtual machines (VMs) to AWS. The company's backup solution exports on-premises backups to an Amazon S3 bucket as objects. The S3 backups must be retained for 30 days and must be automatically deleted after 30 days. Which combination of steps will meet these requirements? (Choose three.)", "options": ["A. Create an S3 bucket that has S3 Object Lock enabled.", "B. Create an S3 bucket that has object versioning enabled.", "C. Configure a default retention period of 30 days for the objects.", "D. Configure an S3 Lifecycle policy to protect the objects for 30 days.", "E. Configure an S3 Lifecycle policy to expire the objects after 30 days.", "F. Configure the backup solution to tag the objects with a 30-day retention period 421"], "explain": "", "answers": [], "resources": []}, {"_id": 696, "question": "696 # A solutions architect needs to copy files from an Amazon S3 bucket to an Amazon Elastic File System (Amazon EFS) file system and another S3 bucket. The files must be copied continuously. New files are added to the original S3 bucket consistently. The copied files should be overwritten only if the source file changes. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Create an AWS DataSync location for both the destination S3 bucket and the EFS file system. Create a task for the destination S3 bucket and the EFS file system. Set the transfer mode to transfer only data that has changed.", "B. Create an AWS Lambda function. Mount the file system to the function. Set up an S3 event notification to invoke the function when files are created and changed in Amazon S3. Configure the function to copy files to the file system and the destination S3 bucket.", "C. Create an AWS DataSync location for both the destination S3 bucket and the EFS file system. Create a task for the destination S3 bucket and the EFS file system. Set the transfer mode to transfer all data.", "D. Launch an Amazon EC2 instance in the same VPC as the file system. Mount the file system. Create a script to routinely synchronize all objects that changed in the origin S3 bucket to the destination S3 bucket and the mounted file system."], "explain": "", "answers": [], "resources": []}, {"_id": 696, "question": "696 # A solutions architect needs to copy files from an Amazon S3 bucket to an Amazon Elastic File System (Amazon EFS) file system and another S3 bucket. The files must be copied continuously. New files are added to the original S3 bucket consistently. The copied files should be overwritten only if the source file changes. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Create an AWS DataSync location for both the destination S3 bucket and the EFS file system. Create a task for the destination S3 bucket and the EFS file system. Set the transfer mode to transfer only data that has changed.", "B. Create an AWS Lambda function. Mount the file system to the function. Set up an S3 event notification to invoke the function when files are created and changed in Amazon S3. Configure the function to copy files to the file system and the destination S3 bucket.", "C. Create an AWS DataSync location for both the destination S3 bucket and the EFS file system. Create a task for the destination S3 bucket and the EFS file system. Set the transfer mode to transfer all data.", "D. Launch an Amazon EC2 instance in the same VPC as the file system. Mount the file system. Create a script to routinely synchronize all objects that changed in the origin S3 bucket to the destination S3 bucket and the mounted file system. 422"], "explain": "", "answers": [], "resources": []}, {"_id": 697, "question": "697 # A company uses Amazon EC2 instances and stores data on Amazon Elastic Block Store (Amazon EBS) volumes. The company must ensure that all data is encrypted at rest by using AWS Key Management Service (AWS KMS). The company must be able to control rotation of the encryption keys. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Create a customer managed key. Use the key to encrypt the EBS volumes.", "B. Use an AWS managed key to encrypt the EBS volumes. Use the key to configure automatic key rotation.", "C. Create an external KMS key with imported key material. Use the key to encrypt the EBS volumes.", "D. Use an AWS owned key to encrypt the EBS volumes."], "explain": "", "answers": [], "resources": []}, {"_id": 697, "question": "697 # A company uses Amazon EC2 instances and stores data on Amazon Elastic Block Store (Amazon EBS) volumes. The company must ensure that all data is encrypted at rest by using AWS Key Management Service (AWS KMS). The company must be able to control rotation of the encryption keys. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Create a customer managed key. Use the key to encrypt the EBS volumes.", "B. Use an AWS managed key to encrypt the EBS volumes. Use the key to configure automatic key rotation.", "C. Create an external KMS key with imported key material. Use the key to encrypt the EBS volumes.", "D. Use an AWS owned key to encrypt the EBS volumes. 423"], "explain": "", "answers": [], "resources": []}, {"_id": 698, "question": "698 # A company needs a solution to enforce data encryption at rest on Amazon EC2 instances. The solution must automatically identify noncompliant resources and enforce compliance policies on findings. Which solution will meet these requirements with the LEAST administrative overhead?", "options": ["A. Use an IAM policy that allows users to create only encrypted Amazon Elastic Block Store (Amazon EBS) volumes. Use AWS Config and AWS Systems Manager to automate the detection and remediation of unencrypted EBS volumes.", "B. Use AWS Key Management Service (AWS KMS) to manage access to encrypted Amazon Elastic Block Store (Amazon EBS) volumes. Use AWS Lambda and Amazon EventBridge to automate the detection and remediation of unencrypted EBS volumes.", "C. Use Amazon Macie to detect unencrypted Amazon Elastic Block Store (Amazon EBS) volumes. Use AWS Systems Manager Automation rules to automatically encrypt existing and new EBS volumes.", "D. Use Amazon inspector to detect unencrypted Amazon Elastic Block Store (Amazon EBS) volumes. Use AWS Systems Manager Automation rules to automatically encrypt existing and new EBS volumes."], "explain": "", "answers": [], "resources": []}, {"_id": 698, "question": "698 # A company needs a solution to enforce data encryption at rest on Amazon EC2 instances. The solution must automatically identify noncompliant resources and enforce compliance policies on findings. Which solution will meet these requirements with the LEAST administrative overhead?", "options": ["A. Use an IAM policy that allows users to create only encrypted Amazon Elastic Block Store (Amazon EBS) volumes. Use AWS Config and AWS Systems Manager to automate the detection and remediation of unencrypted EBS volumes.", "B. Use AWS Key Management Service (AWS KMS) to manage access to encrypted Amazon Elastic Block Store (Amazon EBS) volumes. Use AWS Lambda and Amazon EventBridge to automate the detection and remediation of unencrypted EBS volumes.", "C. Use Amazon Macie to detect unencrypted Amazon Elastic Block Store (Amazon EBS) volumes. Use AWS Systems Manager Automation rules to automatically encrypt existing and new EBS volumes.", "D. Use Amazon inspector to detect unencrypted Amazon Elastic Block Store (Amazon EBS) volumes. Use AWS Systems Manager Automation rules to automatically encrypt existing and new EBS volumes. 424"], "explain": "", "answers": [], "resources": []}, {"_id": 699, "question": "699 # A company wants to migrate its web applications from on premises to AWS. The company is located close to the eu-central-1 Region. Because of regulations, the company cannot launch some of its applications in eu-central-1. The company wants to achieve single-digit millisecond latency. Which solution will meet these requirements?", "options": ["A. Deploy the applications in eu-central-1. Extend the company\u2019s VPC from eu-central-1 to an edge location in Amazon CloudFront.", "B. Deploy the applications in AWS Local Zones by extending the company's VPC from eu-central-1 to the chosen Local Zone.", "C. Deploy the applications in eu-central-1. Extend the company\u2019s VPC from eu-central-1 to the regional edge caches in Amazon CloudFront.", "D. Deploy the applications in AWS Wavelength Zones by extending the company\u2019s VPC from eu- central-1 to the chosen Wavelength Zone."], "explain": "", "answers": [], "resources": []}, {"_id": 699, "question": "699 # A company wants to migrate its web applications from on premises to AWS. The company is located close to the eu-central-1 Region. Because of regulations, the company cannot launch some of its applications in eu-central-1. The company wants to achieve single-digit millisecond latency. Which solution will meet these requirements?", "options": ["A. Deploy the applications in eu-central-1. Extend the company\u2019s VPC from eu-central-1 to an edge location in Amazon CloudFront.", "B. Deploy the applications in AWS Local Zones by extending the company's VPC from eu-central-1 to the chosen Local Zone.", "C. Deploy the applications in eu-central-1. Extend the company\u2019s VPC from eu-central-1 to the regional edge caches in Amazon CloudFront.", "D. Deploy the applications in AWS Wavelength Zones by extending the company\u2019s VPC from eu- central-1 to the chosen Wavelength Zone. 425"], "explain": "", "answers": [], "resources": []}, {"_id": 700, "question": "700 # A company is migrating its multi-tier on-premises application to AWS. The application consists of a single-node MySQL database and a multi-node web tier. The company must minimize changes to the application during the migration. The company wants to improve application resiliency after the migration. Which combination of steps will meet these requirements? (Choose two.)", "options": ["A. Migrate the web tier to Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer.", "B. Migrate the database to Amazon EC2 instances in an Auto Scaling group behind a Network Load Balancer.", "C. Migrate the database to an Amazon RDS Multi-AZ deployment.", "D. Migrate the web tier to an AWS Lambda function.", "E. Migrate the database to an Amazon DynamoDB table."], "explain": "", "answers": [], "resources": []}, {"_id": 700, "question": "700 # A company is migrating its multi-tier on-premises application to AWS. The application consists of a single-node MySQL database and a multi-node web tier. The company must minimize changes to the application during the migration. The company wants to improve application resiliency after the migration. Which combination of steps will meet these requirements? (Choose two.)", "options": ["A. Migrate the web tier to Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer.", "B. Migrate the database to Amazon EC2 instances in an Auto Scaling group behind a Network Load Balancer.", "C. Migrate the database to an Amazon RDS Multi-AZ deployment.", "D. Migrate the web tier to an AWS Lambda function.", "E. Migrate the database to an Amazon DynamoDB table. 426"], "explain": "", "answers": [], "resources": []}, {"_id": 701, "question": "701 # A company\u2019s ecommerce website has unpredictable traffic and uses AWS Lambda functions to directly access a private Amazon RDS for PostgreSQL DB instance. The company wants to maintain predictable database performance and ensure that the Lambda invocations do not overload the database with too many connections. What should a solutions architect do to meet these requirements?", "options": ["A. Point the client driver at an RDS custom endpoint. Deploy the Lambda functions inside a VPC.", "B. Point the client driver at an RDS proxy endpoint. Deploy the Lambda functions inside a VPC.", "C. Point the client driver at an RDS custom endpoint. Deploy the Lambda functions outside a VPC.", "D. Point the client driver at an RDS proxy endpoint. Deploy the Lambda functions outside a VPC."], "explain": "", "answers": [], "resources": []}, {"_id": 701, "question": "701 # A company\u2019s ecommerce website has unpredictable traffic and uses AWS Lambda functions to directly access a private Amazon RDS for PostgreSQL DB instance. The company wants to maintain predictable database performance and ensure that the Lambda invocations do not overload the database with too many connections. What should a solutions architect do to meet these requirements?", "options": ["A. Point the client driver at an RDS custom endpoint. Deploy the Lambda functions inside a VPC.", "B. Point the client driver at an RDS proxy endpoint. Deploy the Lambda functions inside a VPC.", "C. Point the client driver at an RDS custom endpoint. Deploy the Lambda functions outside a VPC.", "D. Point the client driver at an RDS proxy endpoint. Deploy the Lambda functions outside a VPC. 427"], "explain": "", "answers": [], "resources": []}, {"_id": 702, "question": "702 # A company is creating an application. The company stores data from tests of the application in multiple on-premises locations. The company needs to connect the on-premises locations to VPCs in an AWS Region in the AWS Cloud. The number of accounts and VPCs will increase during the next year. The network architecture must simplify the administration of new connections and must provide the ability to scale. Which solution will meet these requirements with the LEAST administrative overhead?", "options": ["A. Create a peering connection between the VPCs. Create a VPN connection between the VPCs and the on-premises locations.", "B. Launch an Amazon EC2 instance. On the instance, include VPN software that uses a VPN connection to connect all VPCs and on-premises locations.", "C. Create a transit gateway. Create VPC attachments for the VPC connections. Create VPN attachments for the on-premises connections.", "D. Create an AWS Direct Connect connection between the on-premises locations and a central VPC. Connect the central VPC to other VPCs by using peering connections."], "explain": "", "answers": [], "resources": []}, {"_id": 702, "question": "702 # A company is creating an application. The company stores data from tests of the application in multiple on-premises locations. The company needs to connect the on-premises locations to VPCs in an AWS Region in the AWS Cloud. The number of accounts and VPCs will increase during the next year. The network architecture must simplify the administration of new connections and must provide the ability to scale. Which solution will meet these requirements with the LEAST administrative overhead?", "options": ["A. Create a peering connection between the VPCs. Create a VPN connection between the VPCs and the on-premises locations.", "B. Launch an Amazon EC2 instance. On the instance, include VPN software that uses a VPN connection to connect all VPCs and on-premises locations.", "C. Create a transit gateway. Create VPC attachments for the VPC connections. Create VPN attachments for the on-premises connections.", "D. Create an AWS Direct Connect connection between the on-premises locations and a central VPC. Connect the central VPC to other VPCs by using peering connections. 428"], "explain": "", "answers": [], "resources": []}, {"_id": 703, "question": "703 # A company that uses AWS needs a solution to predict the resources needed for manufacturing processes each month. The solution must use historical values that are currently stored in an Amazon S3 bucket. The company has no machine learning (ML) experience and wants to use a managed service for the training and predictions. Which combination of steps will meet these requirements? (Choose two.)", "options": ["A. Deploy an Amazon SageMaker model. Create a SageMaker endpoint for inference.", "B. Use Amazon SageMaker to train a model by using the historical data in the S3 bucket.", "C. Configure an AWS Lambda function with a function URL that uses Amazon SageMaker endpoints to create predictions based on the inputs.", "D. Configure an AWS Lambda function with a function URL that uses an Amazon Forecast predictor to create a prediction based on the inputs.", "E. Train an Amazon Forsecast predictor by using the historical data in the S3 bucket."], "explain": "", "answers": [], "resources": []}, {"_id": 703, "question": "703 # A company that uses AWS needs a solution to predict the resources needed for manufacturing processes each month. The solution must use historical values that are currently stored in an Amazon S3 bucket. The company has no machine learning (ML) experience and wants to use a managed service for the training and predictions. Which combination of steps will meet these requirements? (Choose two.)", "options": ["A. Deploy an Amazon SageMaker model. Create a SageMaker endpoint for inference.", "B. Use Amazon SageMaker to train a model by using the historical data in the S3 bucket.", "C. Configure an AWS Lambda function with a function URL that uses Amazon SageMaker endpoints to create predictions based on the inputs.", "D. Configure an AWS Lambda function with a function URL that uses an Amazon Forecast predictor to create a prediction based on the inputs.", "E. Train an Amazon Forsecast predictor by using the historical data in the S3 bucket. 429"], "explain": "", "answers": [], "resources": []}, {"_id": 704, "question": "704 # A company manages AWS accounts in AWS Organizations. AWS IAM Identity Center (AWS Single Sign-On) and AWS Control Tower are configured for the accounts. The company wants to manage multiple user permissions across all the accounts. The permissions will be used by multiple IAM users and must be split between the developer and administrator teams. Each team requires different permissions. The company wants a solution that includes new users that are hired on both teams. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Create individual users in IAM Identity Center for each account. Create separate developer and administrator groups in IAM Identity Center. Assign the users to the appropriate groups. Create a custom IAM policy for each group to set fine-grained permissions.", "B. Create individual users in IAM Identity Center for each account. Create separate developer and administrator groups in IAM Identity Center. Assign the users to the appropriate groups. Attach AWS managed IAM policies to each user as needed for fine-grained permissions.", "C. Create individual users in IAM Identity Center. Create new developer and administrator groups in IAM Identity Center. Create new permission sets that include the appropriate IAM policies for each group. Assign the new groups to the appropriate accounts. Assign the new permission sets to the new groups. When new users are hired, add them to the appropriate group.", "D. Create individual users in IAM Identity Center. Create new permission sets that include the appropriate IAM policies for each user. Assign the users to the appropriate accounts. Grant additional IAM permissions to the users from within specific accounts. When new users are hired, add them to IAM Identity Center and assign them to the accounts."], "explain": "", "answers": [], "resources": []}, {"_id": 704, "question": "704 # A company manages AWS accounts in AWS Organizations. AWS IAM Identity Center (AWS Single Sign-On) and AWS Control Tower are configured for the accounts. The company wants to manage multiple user permissions across all the accounts. The permissions will be used by multiple IAM users and must be split between the developer and administrator teams. Each team requires different permissions. The company wants a solution that includes new users that are hired on both teams. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Create individual users in IAM Identity Center for each account. Create separate developer and administrator groups in IAM Identity Center. Assign the users to the appropriate groups. Create a custom IAM policy for each group to set fine-grained permissions.", "B. Create individual users in IAM Identity Center for each account. Create separate developer and administrator groups in IAM Identity Center. Assign the users to the appropriate groups. Attach AWS managed IAM policies to each user as needed for fine-grained permissions.", "C. Create individual users in IAM Identity Center. Create new developer and administrator groups in IAM Identity Center. Create new permission sets that include the appropriate IAM policies for each group. Assign the new groups to the appropriate accounts. Assign the new permission sets to the new groups. When new users are hired, add them to the appropriate group.", "D. Create individual users in IAM Identity Center. Create new permission sets that include the appropriate IAM policies for each user. Assign the users to the appropriate accounts. Grant additional IAM permissions to the users from within specific accounts. When new users are hired, add them to IAM Identity Center and assign them to the accounts. 430"], "explain": "", "answers": [], "resources": []}, {"_id": 705, "question": "705 # A company wants to standardize its Amazon Elastic Block Store (Amazon EBS) volume encryption strategy. The company also wants to minimize the cost and configuration effort required to operate the volume encryption check. Which solution will meet these requirements?", "options": ["A. Write API calls to describe the EBS volumes and to confirm the EBS volumes are encrypted. Use Amazon EventBridge to schedule an AWS Lambda function to run the API calls.", "B. Write API calls to describe the EBS volumes and to confirm the EBS volumes are encrypted. Run the API calls on an AWS Fargate task.", "C. Create an AWS Identity and Access Management (IAM) policy that requires the use of tags on EBS volumes. Use AWS Cost Explorer to display resources that are not properly tagged. Encrypt the untagged resources manually.", "D. Create an AWS Config rule for Amazon EBS to evaluate if a volume is encrypted and to flag the volume if it is not encrypted."], "explain": "", "answers": [], "resources": []}, {"_id": 705, "question": "705 # A company wants to standardize its Amazon Elastic Block Store (Amazon EBS) volume encryption strategy. The company also wants to minimize the cost and configuration effort required to operate the volume encryption check. Which solution will meet these requirements?", "options": ["A. Write API calls to describe the EBS volumes and to confirm the EBS volumes are encrypted. Use Amazon EventBridge to schedule an AWS Lambda function to run the API calls.", "B. Write API calls to describe the EBS volumes and to confirm the EBS volumes are encrypted. Run the API calls on an AWS Fargate task.", "C. Create an AWS Identity and Access Management (IAM) policy that requires the use of tags on EBS volumes. Use AWS Cost Explorer to display resources that are not properly tagged. Encrypt the untagged resources manually.", "D. Create an AWS Config rule for Amazon EBS to evaluate if a volume is encrypted and to flag the volume if it is not encrypted. 431"], "explain": "", "answers": [], "resources": []}, {"_id": 706, "question": "706 # A company regularly uploads GB-sized files to Amazon S3. After the company uploads the files, the company uses a fleet of Amazon EC2 Spot Instances to transcode the file format. The company needs to scale throughput when the company uploads data from the on-premises data center to Amazon S3 and when the company downloads data from Amazon S3 to the EC2 instances. Which solutions will meet these requirements? (Choose two.)", "options": ["A. Use the S3 bucket access point instead of accessing the S3 bucket directly.", "B. Upload the files into multiple S3 buckets.", "C. Use S3 multipart uploads.", "D. Fetch multiple byte-ranges of an object in parallel.", "E. Add a random prefix to each object when uploading the files."], "explain": "", "answers": [], "resources": []}, {"_id": 706, "question": "706 # A company regularly uploads GB-sized files to Amazon S3. After the company uploads the files, the company uses a fleet of Amazon EC2 Spot Instances to transcode the file format. The company needs to scale throughput when the company uploads data from the on-premises data center to Amazon S3 and when the company downloads data from Amazon S3 to the EC2 instances. Which solutions will meet these requirements? (Choose two.)", "options": ["A. Use the S3 bucket access point instead of accessing the S3 bucket directly.", "B. Upload the files into multiple S3 buckets.", "C. Use S3 multipart uploads.", "D. Fetch multiple byte-ranges of an object in parallel.", "E. Add a random prefix to each object when uploading the files. 432"], "explain": "", "answers": [], "resources": []}, {"_id": 707, "question": "707 # A solutions architect is designing a shared storage solution for a web application that is deployed across multiple Availability Zones. The web application runs on Amazon EC2 instances that are in an Auto Scaling group. The company plans to make frequent changes to the content. The solution must have strong consistency in returning the new content as soon as the changes occur. Which solutions meet these requirements? (Choose two.)", "options": ["A. Use AWS Storage Gateway Volume Gateway Internet Small Computer Systems Interface (iSCSI) block storage that is mounted to the individual EC2 instances.", "B. Create an Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system on the individual EC2 instances.", "C. Create a shared Amazon Elastic Block Store (Amazon EBS) volume. Mount the EBS volume on the individual EC2 instances.", "D. Use AWS DataSync to perform continuous synchronization of data between EC2 hosts in the Auto Scaling group.", "E. Create an Amazon S3 bucket to store the web content. Set the metadata for the Cache-Control header to no-cache. Use Amazon CloudFront to deliver the content."], "explain": "", "answers": [], "resources": []}, {"_id": 707, "question": "707 # A solutions architect is designing a shared storage solution for a web application that is deployed across multiple Availability Zones. The web application runs on Amazon EC2 instances that are in an Auto Scaling group. The company plans to make frequent changes to the content. The solution must have strong consistency in returning the new content as soon as the changes occur. Which solutions meet these requirements? (Choose two.)", "options": ["A. Use AWS Storage Gateway Volume Gateway Internet Small Computer Systems Interface (iSCSI) block storage that is mounted to the individual EC2 instances.", "B. Create an Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system on the individual EC2 instances.", "C. Create a shared Amazon Elastic Block Store (Amazon EBS) volume. Mount the EBS volume on the individual EC2 instances.", "D. Use AWS DataSync to perform continuous synchronization of data between EC2 hosts in the Auto Scaling group.", "E. Create an Amazon S3 bucket to store the web content. Set the metadata for the Cache-Control header to no-cache. Use Amazon CloudFront to deliver the content. 433"], "explain": "", "answers": [], "resources": []}, {"_id": 708, "question": "708 # A company is deploying an application in three AWS Regions using an Application Load Balancer. Amazon Route 53 will be used to distribute traffic between these Regions. Which Route 53 configuration should a solutions architect use to provide the MOST high-performing experience?", "options": ["A. Create an A record with a latency policy.", "B. Create an A record with a geolocation policy.", "C. Create a CNAME record with a failover policy.", "D. Create a CNAME record with a geoproximity policy."], "explain": "", "answers": [], "resources": []}, {"_id": 708, "question": "708 # A company is deploying an application in three AWS Regions using an Application Load Balancer. Amazon Route 53 will be used to distribute traffic between these Regions. Which Route 53 configuration should a solutions architect use to provide the MOST high-performing experience?", "options": ["A. Create an A record with a latency policy.", "B. Create an A record with a geolocation policy.", "C. Create a CNAME record with a failover policy.", "D. Create a CNAME record with a geoproximity policy. 434"], "explain": "", "answers": [], "resources": []}, {"_id": 709, "question": "709 # A company has a web application that includes an embedded NoSQL database. The application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The instances run in an Amazon EC2 Auto Scaling group in a single Availability Zone. A recent increase in traffic requires the application to be highly available and for the database to be eventually consistent. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Replace the ALB with a Network Load Balancer. Maintain the embedded NoSQL database with its replication service on the EC2 instances.", "B. Replace the ALB with a Network Load Balancer. Migrate the embedded NoSQL database to Amazon DynamoDB by using AWS Database Migration Service (AWS DMS).", "C. Modify the Auto Scaling group to use EC2 instances across three Availability Zones. Maintain the embedded NoSQL database with its replication service on the EC2 instances.", "D. Modify the Auto Scaling group to use EC2 instances across three Availability Zones. Migrate the embedded NoSQL database to Amazon DynamoDB by using AWS Database Migration Service (AWS DMS)."], "explain": "", "answers": [], "resources": []}, {"_id": 709, "question": "709 # A company has a web application that includes an embedded NoSQL database. The application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The instances run in an Amazon EC2 Auto Scaling group in a single Availability Zone. A recent increase in traffic requires the application to be highly available and for the database to be eventually consistent. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Replace the ALB with a Network Load Balancer. Maintain the embedded NoSQL database with its replication service on the EC2 instances.", "B. Replace the ALB with a Network Load Balancer. Migrate the embedded NoSQL database to Amazon DynamoDB by using AWS Database Migration Service (AWS DMS).", "C. Modify the Auto Scaling group to use EC2 instances across three Availability Zones. Maintain the embedded NoSQL database with its replication service on the EC2 instances.", "D. Modify the Auto Scaling group to use EC2 instances across three Availability Zones. Migrate the embedded NoSQL database to Amazon DynamoDB by using AWS Database Migration Service (AWS DMS). 435"], "explain": "", "answers": [], "resources": []}, {"_id": 710, "question": "710 # A company is building a shopping application on AWS. The application offers a catalog that changes once each month and needs to scale with traffic volume. The company wants the lowest possible latency from the application. Data from each user's shopping cart needs to be highly available. User session data must be available even if the user is disconnected and reconnects. What should a solutions architect do to ensure that the shopping cart data is preserved at all times?", "options": ["A. Configure an Application Load Balancer to enable the sticky sessions feature (session affinity) for access to the catalog in Amazon Aurora.", "B. Configure Amazon ElastiCache for Redis to cache catalog data from Amazon DynamoDB and shopping cart data from the user's session.", "C. Configure Amazon OpenSearch Service to cache catalog data from Amazon DynamoDB and shopping cart data from the user's session.", "D. Configure an Amazon EC2 instance with Amazon Elastic Block Store (Amazon EBS) storage for the catalog and shopping cart. Configure automated snapshots."], "explain": "", "answers": [], "resources": []}, {"_id": 710, "question": "710 # A company is building a shopping application on AWS. The application offers a catalog that changes once each month and needs to scale with traffic volume. The company wants the lowest possible latency from the application. Data from each user's shopping cart needs to be highly available. User session data must be available even if the user is disconnected and reconnects. What should a solutions architect do to ensure that the shopping cart data is preserved at all times?", "options": ["A. Configure an Application Load Balancer to enable the sticky sessions feature (session affinity) for access to the catalog in Amazon Aurora.", "B. Configure Amazon ElastiCache for Redis to cache catalog data from Amazon DynamoDB and shopping cart data from the user's session.", "C. Configure Amazon OpenSearch Service to cache catalog data from Amazon DynamoDB and shopping cart data from the user's session.", "D. Configure an Amazon EC2 instance with Amazon Elastic Block Store (Amazon EBS) storage for the catalog and shopping cart. Configure automated snapshots. 436"], "explain": "", "answers": [], "resources": []}, {"_id": 711, "question": "711 # A company is building a microservices-based application that will be deployed on Amazon Elastic Kubernetes Service (Amazon EKS). The microservices will interact with each other. The company wants to ensure that the application is observable to identify performance issues in the future. Which solution will meet these requirements?", "options": ["A. Configure the application to use Amazon ElastiCache to reduce the number of requests that are sent to the microservices.", "B. Configure Amazon CloudWatch Container Insights to collect metrics from the EKS clusters. Configure AWS X-Ray to trace the requests between the microservices.", "C. Configure AWS CloudTrail to review the API calls. Build an Amazon QuickSight dashboard to observe the microservice interactions.", "D. Use AWS Trusted Advisor to understand the performance of the application."], "explain": "", "answers": [], "resources": []}, {"_id": 711, "question": "711 # A company is building a microservices-based application that will be deployed on Amazon Elastic Kubernetes Service (Amazon EKS). The microservices will interact with each other. The company wants to ensure that the application is observable to identify performance issues in the future. Which solution will meet these requirements?", "options": ["A. Configure the application to use Amazon ElastiCache to reduce the number of requests that are sent to the microservices.", "B. Configure Amazon CloudWatch Container Insights to collect metrics from the EKS clusters. Configure AWS X-Ray to trace the requests between the microservices.", "C. Configure AWS CloudTrail to review the API calls. Build an Amazon QuickSight dashboard to observe the microservice interactions.", "D. Use AWS Trusted Advisor to understand the performance of the application. 437"], "explain": "", "answers": [], "resources": []}, {"_id": 712, "question": "712 # A company needs to provide customers with secure access to its data. The company processes customer data and stores the results in an Amazon S3 bucket. All the data is subject to strong regulations and security requirements. The data must be encrypted at rest. Each customer must be able to access only their data from their AWS account. Company employees must not be able to access the data. Which solution will meet these requirements?", "options": ["A. Provision an AWS Certificate Manager (ACM) certificate for each customer. Encrypt the data client-side. In the private certificate policy, deny access to the certificate for all principals except an IAM role that the customer provides.", "B. Provision a separate AWS Key Management Service (AWS KMS) key for each customer. Encrypt the data server-side. In the S3 bucket policy, deny decryption of data for all principals except an IAM role that the customer provides.", "C. Provision a separate AWS Key Management Service (AWS KMS) key for each customer. Encrypt the data server-side. In each KMS key policy, deny decryption of data for all principals except an IAM role that the customer provides.", "D. Provision an AWS Certificate Manager (ACM) certificate for each customer. Encrypt the data client-side. In the public certificate policy, deny access to the certificate for all principals except an IAM role that the customer provides."], "explain": "", "answers": [], "resources": []}, {"_id": 712, "question": "712 # A company needs to provide customers with secure access to its data. The company processes customer data and stores the results in an Amazon S3 bucket. All the data is subject to strong regulations and security requirements. The data must be encrypted at rest. Each customer must be able to access only their data from their AWS account. Company employees must not be able to access the data. Which solution will meet these requirements?", "options": ["A. Provision an AWS Certificate Manager (ACM) certificate for each customer. Encrypt the data client-side. In the private certificate policy, deny access to the certificate for all principals except an IAM role that the customer provides.", "B. Provision a separate AWS Key Management Service (AWS KMS) key for each customer. Encrypt the data server-side. In the S3 bucket policy, deny decryption of data for all principals except an IAM role that the customer provides.", "C. Provision a separate AWS Key Management Service (AWS KMS) key for each customer. Encrypt the data server-side. In each KMS key policy, deny decryption of data for all principals except an IAM role that the customer provides.", "D. Provision an AWS Certificate Manager (ACM) certificate for each customer. Encrypt the data client-side. In the public certificate policy, deny access to the certificate for all principals except an IAM role that the customer provides. 438"], "explain": "", "answers": [], "resources": []}, {"_id": 713, "question": "713 # A solutions architect creates a VPC that includes two public subnets and two private subnets. A corporate security mandate requires the solutions architect to launch all Amazon EC2 instances in a private subnet. However, when the solutions architect launches an EC2 instance that runs a web server on ports 80 and 443 in a private subnet, no external internet traffic can connect to the server. What should the solutions architect do to resolve this issue?", "options": ["A. Attach the EC2 instance to an Auto Scaling group in a private subnet. Ensure that the DNS record for the website resolves to the Auto Scaling group identifier.", "B. Provision an internet-facing Application Load Balancer (ALB) in a public subnet. Add the EC2 instance to the target group that is associated with the ALEnsure that the DNS record for the website resolves to the ALB.", "C. Launch a NAT gateway in a private subnet. Update the route table for the private subnets to add a default route to the NAT gateway. Attach a public Elastic IP address to the NAT gateway.", "D. Ensure that the security group that is attached to the EC2 instance allows HTTP traffic on port 80 and HTTPS traffic on port 443. Ensure that the DNS record for the website resolves to the public IP address of the EC2 instance."], "explain": "", "answers": [], "resources": []}, {"_id": 713, "question": "713 # A solutions architect creates a VPC that includes two public subnets and two private subnets. A corporate security mandate requires the solutions architect to launch all Amazon EC2 instances in a private subnet. However, when the solutions architect launches an EC2 instance that runs a web server on ports 80 and 443 in a private subnet, no external internet traffic can connect to the server. What should the solutions architect do to resolve this issue?", "options": ["A. Attach the EC2 instance to an Auto Scaling group in a private subnet. Ensure that the DNS record for the website resolves to the Auto Scaling group identifier.", "B. Provision an internet-facing Application Load Balancer (ALB) in a public subnet. Add the EC2 instance to the target group that is associated with the ALEnsure that the DNS record for the website resolves to the ALB.", "C. Launch a NAT gateway in a private subnet. Update the route table for the private subnets to add a default route to the NAT gateway. Attach a public Elastic IP address to the NAT gateway.", "D. Ensure that the security group that is attached to the EC2 instance allows HTTP traffic on port 80 and HTTPS traffic on port 443. Ensure that the DNS record for the website resolves to the public IP address of the EC2 instance. 439"], "explain": "", "answers": [], "resources": []}, {"_id": 714, "question": "714 # A company is deploying a new application to Amazon Elastic Kubernetes Service (Amazon EKS) with an AWS Fargate cluster. The application needs a storage solution for data persistence. The solution must be highly available and fault tolerant. The solution also must be shared between multiple application containers. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Create Amazon Elastic Block Store (Amazon EBS) volumes in the same Availability Zones where EKS worker nodes are placed. Register the volumes in a StorageClass object on an EKS cluster. Use EBS Multi-Attach to share the data between containers.", "B. Create an Amazon Elastic File System (Amazon EFS) file system. Register the file system in a StorageClass object on an EKS cluster. Use the same file system for all containers.", "C. Create an Amazon Elastic Block Store (Amazon EBS) volume. Register the volume in a StorageClass object on an EKS cluster. Use the same volume for all containers.", "D. Create Amazon Elastic File System (Amazon EFS) file systems in the same Availability Zones where EKS worker nodes are placed. Register the file systems in a StorageClass object on an EKS cluster. Create an AWS Lambda function to synchronize the data between file systems."], "explain": "", "answers": [], "resources": []}, {"_id": 714, "question": "714 # A company is deploying a new application to Amazon Elastic Kubernetes Service (Amazon EKS) with an AWS Fargate cluster. The application needs a storage solution for data persistence. The solution must be highly available and fault tolerant. The solution also must be shared between multiple application containers. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Create Amazon Elastic Block Store (Amazon EBS) volumes in the same Availability Zones where EKS worker nodes are placed. Register the volumes in a StorageClass object on an EKS cluster. Use EBS Multi-Attach to share the data between containers.", "B. Create an Amazon Elastic File System (Amazon EFS) file system. Register the file system in a StorageClass object on an EKS cluster. Use the same file system for all containers.", "C. Create an Amazon Elastic Block Store (Amazon EBS) volume. Register the volume in a StorageClass object on an EKS cluster. Use the same volume for all containers.", "D. Create Amazon Elastic File System (Amazon EFS) file systems in the same Availability Zones where EKS worker nodes are placed. Register the file systems in a StorageClass object on an EKS cluster. Create an AWS Lambda function to synchronize the data between file systems. 440"], "explain": "", "answers": [], "resources": []}, {"_id": 715, "question": "715 # A company has an application that uses Docker containers in its local data center. The application runs on a container host that stores persistent data in a volume on the host. The container instances use the stored persistent data. The company wants to move the application to a fully managed service because the company does not want to manage any servers or storage infrastructure. Which solution will meet these requirements?", "options": ["A. Use Amazon Elastic Kubernetes Service (Amazon EKS) with self-managed nodes. Create an Amazon Elastic Block Store (Amazon EBS) volume attached to an Amazon EC2 instance. Use the EBS volume as a persistent volume mounted in the containers.", "B. Use Amazon Elastic Container Service (Amazon ECS) with an AWS Fargate launch type. Create an Amazon Elastic File System (Amazon EFS) volume. Add the EFS volume as a persistent storage volume mounted in the containers.", "C. Use Amazon Elastic Container Service (Amazon ECS) with an AWS Fargate launch type. Create an Amazon S3 bucket. Map the S3 bucket as a persistent storage volume mounted in the containers.", "D. Use Amazon Elastic Container Service (Amazon ECS) with an Amazon EC2 launch type. Create an Amazon Elastic File System (Amazon EFS) volume. Add the EFS volume as a persistent storage volume mounted in the containers."], "explain": "", "answers": [], "resources": []}, {"_id": 715, "question": "715 # A company has an application that uses Docker containers in its local data center. The application runs on a container host that stores persistent data in a volume on the host. The container instances use the stored persistent data. The company wants to move the application to a fully managed service because the company does not want to manage any servers or storage infrastructure. Which solution will meet these requirements?", "options": ["A. Use Amazon Elastic Kubernetes Service (Amazon EKS) with self-managed nodes. Create an Amazon Elastic Block Store (Amazon EBS) volume attached to an Amazon EC2 instance. Use the EBS volume as a persistent volume mounted in the containers.", "B. Use Amazon Elastic Container Service (Amazon ECS) with an AWS Fargate launch type. Create an Amazon Elastic File System (Amazon EFS) volume. Add the EFS volume as a persistent storage volume mounted in the containers.", "C. Use Amazon Elastic Container Service (Amazon ECS) with an AWS Fargate launch type. Create an Amazon S3 bucket. Map the S3 bucket as a persistent storage volume mounted in the containers.", "D. Use Amazon Elastic Container Service (Amazon ECS) with an Amazon EC2 launch type. Create an Amazon Elastic File System (Amazon EFS) volume. Add the EFS volume as a persistent storage volume mounted in the containers. 441"], "explain": "", "answers": [], "resources": []}, {"_id": 716, "question": "716 # A gaming company wants to launch a new internet-facing application in multiple AWS Regions. The application will use the TCP and UDP protocols for communication. The company needs to provide high availability and minimum latency for global users. Which combination of actions should A solutions architect take to meet these requirements? (Choose two.)", "options": ["A. Create internal Network Load Balancers in front of the application in each Region.", "B. Create external Application Load Balancers in front of the application in each Region.", "C. Create an AWS Global Accelerator accelerator to route traffic to the load balancers in each Region.", "D. Configure Amazon Route 53 to use a geolocation routing policy to distribute the traffic.", "E. Configure Amazon CloudFront to handle the traffic and route requests to the application in each Region"], "explain": "", "answers": [], "resources": []}, {"_id": 716, "question": "716 # A gaming company wants to launch a new internet-facing application in multiple AWS Regions. The application will use the TCP and UDP protocols for communication. The company needs to provide high availability and minimum latency for global users. Which combination of actions should A solutions architect take to meet these requirements? (Choose two.)", "options": ["A. Create internal Network Load Balancers in front of the application in each Region.", "B. Create external Application Load Balancers in front of the application in each Region.", "C. Create an AWS Global Accelerator accelerator to route traffic to the load balancers in each Region.", "D. Configure Amazon Route 53 to use a geolocation routing policy to distribute the traffic.", "E. Configure Amazon CloudFront to handle the traffic and route requests to the application in each Region 442"], "explain": "", "answers": [], "resources": []}, {"_id": 717, "question": "717 # A city has deployed a web application running on Amazon EC2 instances behind an Application Load Balancer (ALB). The application's users have reported sporadic performance, which appears to be related to DDoS attacks originating from random IP addresses. The city needs a solution that requires minimal configuration changes and provides an audit trail for the DDoS sources. Which solution meets these requirements?", "options": ["A. Enable an AWS WAF web ACL on the ALB, and configure rules to block traffic from unknown sources.", "B. Subscribe to Amazon Inspector. Engage the AWS DDoS Response Team (DRT) to integrate mitigating controls into the service.", "C. Subscribe to AWS Shield Advanced. Engage the AWS DDoS Response Team (DRT) to integrate mitigating controls into the service.", "D. Create an Amazon CloudFront distribution for the application, and set the ALB as the origin. Enable an AWS WAF web ACL on the distribution, and configure rules to block traffic from unknown sources"], "explain": "", "answers": [], "resources": []}, {"_id": 717, "question": "717 # A city has deployed a web application running on Amazon EC2 instances behind an Application Load Balancer (ALB). The application's users have reported sporadic performance, which appears to be related to DDoS attacks originating from random IP addresses. The city needs a solution that requires minimal configuration changes and provides an audit trail for the DDoS sources. Which solution meets these requirements?", "options": ["A. Enable an AWS WAF web ACL on the ALB, and configure rules to block traffic from unknown sources.", "B. Subscribe to Amazon Inspector. Engage the AWS DDoS Response Team (DRT) to integrate mitigating controls into the service.", "C. Subscribe to AWS Shield Advanced. Engage the AWS DDoS Response Team (DRT) to integrate mitigating controls into the service.", "D. Create an Amazon CloudFront distribution for the application, and set the ALB as the origin. Enable an AWS WAF web ACL on the distribution, and configure rules to block traffic from unknown sources 443"], "explain": "", "answers": [], "resources": []}, {"_id": 718, "question": "718 # A company copies 200 TB of data from a recent ocean survey onto AWS Snowball Edge Storage Optimized devices. The company has a high performance computing (HPC) cluster that is hosted on AWS to look for oil and gas deposits. A solutions architect must provide the cluster with consistent sub-millisecond latency and high-throughput access to the data on the Snowball Edge Storage Optimized devices. The company is sending the devices back to AWS. Which solution will meet these requirements?", "options": ["A. Create an Amazon S3 bucket. Import the data into the S3 bucket. Configure an AWS Storage Gateway file gateway to use the S3 bucket. Access the file gateway from the HPC cluster instances.", "B. Create an Amazon S3 bucket. Import the data into the S3 bucket. Configure an Amazon FSx for Lustre file system, and integrate it with the S3 bucket. Access the FSx for Lustre file system from the HPC cluster instances.", "C. Create an Amazon S3 bucket and an Amazon Elastic File System (Amazon EFS) file system. Import the data into the S3 bucket. Copy the data from the S3 bucket to the EFS file system. Access the EFS file system from the HPC cluster instances.", "D. Create an Amazon FSx for Lustre file system. Import the data directly into the FSx for Lustre file system. Access the FSx for Lustre file system from the HPC cluster instances."], "explain": "", "answers": [], "resources": []}, {"_id": 718, "question": "718 # A company copies 200 TB of data from a recent ocean survey onto AWS Snowball Edge Storage Optimized devices. The company has a high performance computing (HPC) cluster that is hosted on AWS to look for oil and gas deposits. A solutions architect must provide the cluster with consistent sub-millisecond latency and high-throughput access to the data on the Snowball Edge Storage Optimized devices. The company is sending the devices back to AWS. Which solution will meet these requirements?", "options": ["A. Create an Amazon S3 bucket. Import the data into the S3 bucket. Configure an AWS Storage Gateway file gateway to use the S3 bucket. Access the file gateway from the HPC cluster instances.", "B. Create an Amazon S3 bucket. Import the data into the S3 bucket. Configure an Amazon FSx for Lustre file system, and integrate it with the S3 bucket. Access the FSx for Lustre file system from the HPC cluster instances.", "C. Create an Amazon S3 bucket and an Amazon Elastic File System (Amazon EFS) file system. Import the data into the S3 bucket. Copy the data from the S3 bucket to the EFS file system. Access the EFS file system from the HPC cluster instances.", "D. Create an Amazon FSx for Lustre file system. Import the data directly into the FSx for Lustre file system. Access the FSx for Lustre file system from the HPC cluster instances. 444"], "explain": "", "answers": [], "resources": []}, {"_id": 719, "question": "719 # A company has NFS servers in an on-premises data center that need to periodically back up small amounts of data to Amazon S3. Which solution meets these requirements and is MOST cost-effective?", "options": ["A. Set up AWS Glue to copy the data from the on-premises servers to Amazon S3.", "B. Set up an AWS DataSync agent on the on-premises servers, and sync the data to Amazon S3.", "C. Set up an SFTP sync using AWS Transfer for SFTP to sync data from on premises to Amazon S3.", "D. Set up an AWS Direct Connect connection between the on-premises data center and a VPC, and copy the data to Amazon S3."], "explain": "", "answers": [], "resources": []}, {"_id": 719, "question": "719 # A company has NFS servers in an on-premises data center that need to periodically back up small amounts of data to Amazon S3. Which solution meets these requirements and is MOST cost-effective?", "options": ["A. Set up AWS Glue to copy the data from the on-premises servers to Amazon S3.", "B. Set up an AWS DataSync agent on the on-premises servers, and sync the data to Amazon S3.", "C. Set up an SFTP sync using AWS Transfer for SFTP to sync data from on premises to Amazon S3.", "D. Set up an AWS Direct Connect connection between the on-premises data center and a VPC, and copy the data to Amazon S3. 445"], "explain": "", "answers": [], "resources": []}, {"_id": 720, "question": "720 # An online video game company must maintain ultra-low latency for its game servers. The game servers run on Amazon EC2 instances. The company needs a solution that can handle millions of UDP internet traffic requests each second. Which solution will meet these requirements MOST cost-effectively?", "options": ["A. Configure an Application Load Balancer with the required protocol and ports for the internet traffic. Specify the EC2 instances as the targets.", "B. Configure a Gateway Load Balancer for the internet traffic. Specify the EC2 instances as the targets.", "C. Configure a Network Load Balancer with the required protocol and ports for the internet traffic. Specify the EC2 instances as the targets.", "D. Launch an identical set of game servers on EC2 instances in separate AWS Regions. Route internet traffic to both sets of EC2 instances."], "explain": "", "answers": [], "resources": []}, {"_id": 720, "question": "720 # An online video game company must maintain ultra-low latency for its game servers. The game servers run on Amazon EC2 instances. The company needs a solution that can handle millions of UDP internet traffic requests each second. Which solution will meet these requirements MOST cost-effectively?", "options": ["A. Configure an Application Load Balancer with the required protocol and ports for the internet traffic. Specify the EC2 instances as the targets.", "B. Configure a Gateway Load Balancer for the internet traffic. Specify the EC2 instances as the targets.", "C. Configure a Network Load Balancer with the required protocol and ports for the internet traffic. Specify the EC2 instances as the targets.", "D. Launch an identical set of game servers on EC2 instances in separate AWS Regions. Route internet traffic to both sets of EC2 instances. 446"], "explain": "", "answers": [], "resources": []}, {"_id": 721, "question": "721 # A company runs a three-tier application in a VPC. The database tier uses an Amazon RDS for MySQL DB instance. The company plans to migrate the RDS for MySQL DB instance to an Amazon Aurora PostgreSQL DB cluster. The company needs a solution that replicates the data changes that happen during the migration to the new database. Which combination of steps will meet these requirements? (Choose two.)", "options": ["A. Use AWS Database Migration Service (AWS DMS) Schema Conversion to transform the database objects.", "B. Use AWS Database Migration Service (AWS DMS) Schema Conversion to create an Aurora PostgreSQL read replica on the RDS for MySQL DB instance.", "C. Configure an Aurora MySQL read replica for the RDS for MySQL DB instance.", "D. Define an AWS Database Migration Service (AWS DMS) task with change data capture (CDC) to migrate the data.", "E. Promote the Aurora PostgreSQL read replica to a standalone Aurora PostgreSQL DB cluster when the replica lag is zero."], "explain": "", "answers": [], "resources": []}, {"_id": 721, "question": "721 # A company runs a three-tier application in a VPC. The database tier uses an Amazon RDS for MySQL DB instance. The company plans to migrate the RDS for MySQL DB instance to an Amazon Aurora PostgreSQL DB cluster. The company needs a solution that replicates the data changes that happen during the migration to the new database. Which combination of steps will meet these requirements? (Choose two.)", "options": ["A. Use AWS Database Migration Service (AWS DMS) Schema Conversion to transform the database objects.", "B. Use AWS Database Migration Service (AWS DMS) Schema Conversion to create an Aurora PostgreSQL read replica on the RDS for MySQL DB instance.", "C. Configure an Aurora MySQL read replica for the RDS for MySQL DB instance.", "D. Define an AWS Database Migration Service (AWS DMS) task with change data capture (CDC) to migrate the data.", "E. Promote the Aurora PostgreSQL read replica to a standalone Aurora PostgreSQL DB cluster when the replica lag is zero. 447"], "explain": "", "answers": [], "resources": []}, {"_id": 722, "question": "722 # A company hosts a database that runs on an Amazon RDS instance that is deployed to multiple Availability Zones. The company periodically runs a script against the database to report new entries that are added to the database. The script that runs against the database negatively affects the performance of a critical application. The company needs to improve application performance with minimal costs. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Add functionality to the script to identify the instance that has the fewest active connections. Configure the script to read from that instance to report the total new entries.", "B. Create a read replica of the database. Configure the script to query only the read replica to report the total new entries.", "C. Instruct the development team to manually export the new entries for the day in the database at the end of each day.", "D. Use Amazon ElastiCache to cache the common queries that the script runs against the database."], "explain": "", "answers": [], "resources": []}, {"_id": 722, "question": "722 # A company hosts a database that runs on an Amazon RDS instance that is deployed to multiple Availability Zones. The company periodically runs a script against the database to report new entries that are added to the database. The script that runs against the database negatively affects the performance of a critical application. The company needs to improve application performance with minimal costs. Which solution will meet these requirements with the LEAST operational overhead?", "options": ["A. Add functionality to the script to identify the instance that has the fewest active connections. Configure the script to read from that instance to report the total new entries.", "B. Create a read replica of the database. Configure the script to query only the read replica to report the total new entries.", "C. Instruct the development team to manually export the new entries for the day in the database at the end of each day.", "D. Use Amazon ElastiCache to cache the common queries that the script runs against the database. 448"], "explain": "", "answers": [], "resources": []}, {"_id": 723, "question": "723 # A company is using an Application Load Balancer (ALB) to present its application to the internet. The company finds abnormal traffic access patterns across the application. A solutions architect needs to improve visibility into the infrastructure to help the company understand these abnormalities better. What is the MOST operationally efficient solution that meets these requirements?", "options": ["A. Create a table in Amazon Athena for AWS CloudTrail logs. Create a query for the relevant information.", "B. Enable ALB access logging to Amazon S3. Create a table in Amazon Athena, and query the logs.", "C. Enable ALB access logging to Amazon S3. Open each file in a text editor, and search each line for the relevant information.", "D. Use Amazon EMR on a dedicated Amazon EC2 instance to directly query the ALB to acquire traffic access log information."], "explain": "", "answers": [], "resources": []}, {"_id": 723, "question": "723 # A company is using an Application Load Balancer (ALB) to present its application to the internet. The company finds abnormal traffic access patterns across the application. A solutions architect needs to improve visibility into the infrastructure to help the company understand these abnormalities better. What is the MOST operationally efficient solution that meets these requirements?", "options": ["A. Create a table in Amazon Athena for AWS CloudTrail logs. Create a query for the relevant information.", "B. Enable ALB access logging to Amazon S3. Create a table in Amazon Athena, and query the logs.", "C. Enable ALB access logging to Amazon S3. Open each file in a text editor, and search each line for the relevant information.", "D. Use Amazon EMR on a dedicated Amazon EC2 instance to directly query the ALB to acquire traffic access log information. 449"], "explain": "", "answers": [], "resources": []}, {"_id": 724, "question": "724 # A company wants to use NAT gateways in its AWS environment. The company's Amazon EC2 instances in private subnets must be able to connect to the public internet through the NAT gateways. Which solution will meet these requirements?", "options": ["A. Create public NAT gateways in the same private subnets as the EC2 instances.", "B. Create private NAT gateways in the same private subnets as the EC2 instances.", "C. Create public NAT gateways in public subnets in the same VPCs as the EC2 instances.", "D. Create private NAT gateways in public subnets in the same VPCs as the EC2 instances."], "explain": "", "answers": [], "resources": []}, {"_id": 724, "question": "724 # A company wants to use NAT gateways in its AWS environment. The company's Amazon EC2 instances in private subnets must be able to connect to the public internet through the NAT gateways. Which solution will meet these requirements?", "options": ["A. Create public NAT gateways in the same private subnets as the EC2 instances.", "B. Create private NAT gateways in the same private subnets as the EC2 instances.", "C. Create public NAT gateways in public subnets in the same VPCs as the EC2 instances.", "D. Create private NAT gateways in public subnets in the same VPCs as the EC2 instances. 450"], "explain": "", "answers": [], "resources": []}, {"_id": 725, "question": "725 # A company has an organization in AWS Organizations. The company runs Amazon EC2 instances across four AWS accounts in the root organizational unit (OU). There are three nonproduction accounts and one production account. The company wants to prohibit users from launching EC2 instances of a certain size in the nonproduction accounts. The company has created a service control policy (SCP) to deny access to launch instances that use the prohibited types. Which solutions to deploy the SCP will meet these requirements? (Choose two.)", "options": ["A. Attach the SCP to the root OU for the organization.", "B. Attach the SCP to the three nonproduction Organizations member accounts.", "C. Attach the SCP to the Organizations management account.", "D. Create an OU for the production account. Attach the SCP to the OU. Move the production member account into the new OU.", "E. Create an OU for the required accounts. Attach the SCP to the OU. Move the nonproduction member accounts into the new OU."], "explain": "", "answers": [], "resources": []}, {"_id": 725, "question": "725 # A company has an organization in AWS Organizations. The company runs Amazon EC2 instances across four AWS accounts in the root organizational unit (OU). There are three nonproduction accounts and one production account. The company wants to prohibit users from launching EC2 instances of a certain size in the nonproduction accounts. The company has created a service control policy (SCP) to deny access to launch instances that use the prohibited types. Which solutions to deploy the SCP will meet these requirements? (Choose two.)", "options": ["A. Attach the SCP to the root OU for the organization.", "B. Attach the SCP to the three nonproduction Organizations member accounts.", "C. Attach the SCP to the Organizations management account.", "D. Create an OU for the production account. Attach the SCP to the OU. Move the production member account into the new OU.", "E. Create an OU for the required accounts. Attach the SCP to the OU. Move the nonproduction member accounts into the new OU. 451"], "explain": "", "answers": [], "resources": []}, {"_id": 726, "question": "726 # A company\u2019s website hosted on Amazon EC2 instances processes classified data stored in Amazon S3. Due to security concerns, the company requires a private and secure connection between its EC2 resources and Amazon S3. Which solution meets these requirements?", "options": ["A. Set up S3 bucket policies to allow access from a VPC endpoint.", "B. Set up an IAM policy to grant read-write access to the S3 bucket.", "C. Set up a NAT gateway to access resources outside the private subnet.", "D. Set up an access key ID and a secret access key to access the S3 bucket."], "explain": "", "answers": [], "resources": []}, {"_id": 726, "question": "726 # A company\u2019s website hosted on Amazon EC2 instances processes classified data stored in Amazon S3. Due to security concerns, the company requires a private and secure connection between its EC2 resources and Amazon S3. Which solution meets these requirements?", "options": ["A. Set up S3 bucket policies to allow access from a VPC endpoint.", "B. Set up an IAM policy to grant read-write access to the S3 bucket.", "C. Set up a NAT gateway to access resources outside the private subnet.", "D. Set up an access key ID and a secret access key to access the S3 bucket. 452"], "explain": "", "answers": [], "resources": []}, {"_id": 727, "question": "727 # A company is designing a web application on AWS. The application will use a VPN connection between the company\u2019s existing data centers and the company's VPCs. The company uses Amazon Route 53 as its DNS service. The application must use private DNS records to communicate with the on-premises services from a VPC. Which solution will meet these requirements in the MOST secure manner?", "options": ["A. Create a Route 53 Resolver outbound endpoint. Create a resolver rule. Associate the resolver rule with the VPC.", "B. Create a Route 53 Resolver inbound endpoint. Create a resolver rule. Associate the resolver rule with the VPC.", "C. Create a Route 53 private hosted zone. Associate the private hosted zone with the VPC.", "D. Create a Route 53 public hosted zone. Create a record for each service to allow service communication"], "explain": "", "answers": [], "resources": []}, {"_id": 727, "question": "727 # A company is designing a web application on AWS. The application will use a VPN connection between the company\u2019s existing data centers and the company's VPCs. The company uses Amazon Route 53 as its DNS service. The application must use private DNS records to communicate with the on-premises services from a VPC. Which solution will meet these requirements in the MOST secure manner?", "options": ["A. Create a Route 53 Resolver outbound endpoint. Create a resolver rule. Associate the resolver rule with the VPC.", "B. Create a Route 53 Resolver inbound endpoint. Create a resolver rule. Associate the resolver rule with the VPC.", "C. Create a Route 53 private hosted zone. Associate the private hosted zone with the VPC.", "D. Create a Route 53 public hosted zone. Create a record for each service to allow service communication 453"], "explain": "", "answers": [], "resources": []}]